{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1641ee2",
   "metadata": {},
   "source": [
    "### Text Splitting from Documents-RecursiveCharacter Text Splitters\n",
    "\n",
    "This text splitter is the recommended one for generic text.It is parameterized by a list of characters.It tries to split on them in order unitl the chunks are small enough.The defailt list is [\"\\n\\n\",\"\\n\",\" \",\"\"].This has the effect of trying to keep all the paragraphs(and then sentences,and then words) together as long as possible as these would generically seem to be the strongest semantically related pieces of text.\n",
    "\n",
    "- How the text is split:List of Characters \n",
    "- How the chunk size is measured:by number of characters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a31f146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗ †\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗ ‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. We show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data.\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\\narXiv:1706.03762v7  [cs.CL]  2 Aug 2023'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='1 Introduction\\nRecurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks\\nin particular, have been firmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 35, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [38, 24, 15].\\nRecurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstates ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\\ncomputation [32], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2 Background\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[16], ByteNet [18] and ConvS2S [9], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difficult to learn dependencies between distant positions [ 12]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [34].\\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3 Model Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35].\\nHere, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\\nof continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\\nsequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive\\n[10], consuming the previously generated symbols as additional input when generating the next.\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='Figure 1: The Transformer - model architecture.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1 Encoder and Decoder Stacks\\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\\nwise fully connected feed-forward network. We employ a residual connection [11] around each of\\nthe two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.\\nDecoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position i can depend only on the known outputs at positions less than i.\\n3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='Scaled Dot-Product Attention\\n Multi-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1 Scaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\nquery with all keys, divide each by √dk, and apply a softmax function to obtain the weights on the\\nvalues.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices K and V . We compute\\nthe matrix of outputs as:\\nAttention(Q, K, V) = softmax(QKT\\n√dk\\n)V (1)\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof 1√dk\\n. Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\\nmuch faster and more space-efficient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code.\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk [3]. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\\nextremely small gradients 4. To counteract this effect, we scale the dot products by 1√dk\\n.\\n3.2.2 Multi-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\\nwe found it beneficial to linearly project the queries, keys and values h times with different, learned\\nlinear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\\nqueries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\\nvariables with mean 0 and variance 1. Then their dot product, q · k = Pdk\\ni=1 qiki, has mean 0 and variance dk.\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='output values. These are concatenated and once again projected, resulting in the final values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With a single attention head, averaging inhibits this.\\nMultiHead(Q, K, V) = Concat(head1, ...,headh)WO\\nwhere headi = Attention(QWQ\\ni , KWK\\ni , V WV\\ni )\\nWhere the projections are parameter matricesWQ\\ni ∈ Rdmodel×dk , WK\\ni ∈ Rdmodel×dk , WV\\ni ∈ Rdmodel×dv\\nand WO ∈ Rhdv×dmodel .\\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\\ndk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost\\nis similar to that of single-head attention with full dimensionality.\\n3.2.3 Applications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[38, 2, 9].\\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward\\ninformation flow in the decoder to preserve the auto-regressive property. We implement this\\ninside of scaled dot-product attention by masking out (setting to −∞) all values in the input\\nof the softmax which correspond to illegal connections. See Figure 2.\\n3.3 Position-wise Feed-Forward Networks\\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\\nconnected feed-forward network, which is applied to each position separately and identically. This\\nconsists of two linear transformations with a ReLU activation in between.\\nFFN(x) = max(0, xW1 + b1)W2 + b2 (2)\\nWhile the linear transformations are the same across different positions, they use different parameters\\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\\nThe dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\\ndff = 2048.\\n3.4 Embeddings and Softmax\\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\\nlinear transformation, similar to [30]. In the embedding layers, we multiply those weights by √dmodel.\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\\nfor different layer types. n is the sequence length, d is the representation dimension, k is the kernel\\nsize of convolutions and r the size of the neighborhood in restricted self-attention.\\nLayer Type Complexity per Layer Sequential Maximum Path Length\\nOperations\\nSelf-Attention O(n2 · d) O(1) O(1)\\nRecurrent O(n · d2) O(n) O(n)\\nConvolutional O(k · n · d2) O(1) O(logk(n))\\nSelf-Attention (restricted) O(r · n · d) O(1) O(n/r)\\n3.5 Positional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\\norder of the sequence, we must inject some information about the relative or absolute position of the\\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\\nlearned and fixed [9].\\nIn this work, we use sine and cosine functions of different frequencies:\\nP E(pos,2i) = sin(pos/100002i/dmodel )\\nP E(pos,2i+1) = cos(pos/100002i/dmodel )\\nwhere pos is the position and i is the dimension. That is, each dimension of the positional encoding\\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π. We\\nchose this function because we hypothesized it would allow the model to easily learn to attend by\\nrelative positions, since for any fixed offset k, P Epos+k can be represented as a linear function of\\nP Epos.\\nWe also experimented with using learned positional embeddings [9] instead, and found that the two\\nversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\\nduring training.\\n4 Why Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations\\n(x1, ..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi ∈ Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.\\nThe third is the path length between long-range dependencies in the network. Learning long-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to\\ntraverse in the network. The shorter these paths between any combination of positions in the input\\nand output sequences, the easier it is to learn long-range dependencies [12]. Hence we also compare\\nthe maximum path length between any two input and output positions in networks composed of the\\ndifferent layer types.\\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\\nexecuted operations, whereas a recurrent layer requires O(n) sequential operations. In terms of\\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\\n6'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='length n is smaller than the representation dimensionality d, which is most often the case with\\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\\n[38] and byte-pair [31] representations. To improve computational performance for tasks involving\\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size r in\\nthe input sequence centered around the respective output position. This would increase the maximum\\npath length to O(n/r). We plan to investigate this approach further in future work.\\nA single convolutional layer with kernel width k < ndoes not connect all pairs of input and output\\npositions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels,\\nor O(logk(n)) in the case of dilated convolutions [ 18], increasing the length of the longest paths\\nbetween any two positions in the network. Convolutional layers are generally more expensive than\\nrecurrent layers, by a factor of k. Separable convolutions [ 6], however, decrease the complexity\\nconsiderably, to O(k · n · d + n · d2). Even with k = n, however, the complexity of a separable\\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side benefit, self-attention could yield more interpretable models. We inspect attention distributions\\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5 Training\\nThis section describes the training regime for our models.\\n5.1 Training Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentence pairs. Sentences were encoded using byte-pair encoding [ 3], which has a shared source-\\ntarget vocabulary of about 37000 tokens. For English-French, we used the significantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\\nvocabulary [38]. Sentence pairs were batched together by approximate sequence length. Each training\\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\\ntarget tokens.\\n5.2 Hardware and Schedule\\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\\n(3.5 days).\\n5.3 Optimizer\\nWe used the Adam optimizer [20] with β1 = 0.9, β2 = 0.98 and ϵ = 10−9. We varied the learning\\nrate over the course of training, according to the formula:\\nlrate = d−0.5\\nmodel · min(step_num−0.5, step_num · warmup_steps−1.5) (3)\\nThis corresponds to increasing the learning rate linearly for the first warmup_steps training steps,\\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\\nwarmup_steps = 4000.\\n5.4 Regularization\\nWe employ three types of regularization during training:\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\\nModel\\nBLEU Training Cost (FLOPs)\\nEN-DE EN-FR EN-DE EN-FR\\nByteNet [18] 23.75\\nDeep-Att + PosUnk [39] 39.2 1.0 · 1020\\nGNMT + RL [38] 24.6 39.92 2.3 · 1019 1.4 · 1020\\nConvS2S [9] 25.16 40.46 9.6 · 1018 1.5 · 1020\\nMoE [32] 26.03 40.56 2.0 · 1019 1.2 · 1020\\nDeep-Att + PosUnk Ensemble [39] 40.4 8.0 · 1020\\nGNMT + RL Ensemble [38] 26.30 41.16 1.8 · 1020 1.1 · 1021\\nConvS2S Ensemble [9] 26.36 41.29 7.7 · 1019 1.2 · 1021\\nTransformer (base model) 27.3 38.1 3.3 · 1018\\nTransformer (big) 28.4 41.8 2.3 · 1019\\nResidual Dropout We apply dropout [33] to the output of each sub-layer, before it is added to the\\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the\\npositional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\\nPdrop = 0.1.\\nLabel Smoothing During training, we employed label smoothing of value ϵls = 0.1 [36]. This\\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\\n6 Results\\n6.1 Machine Translation\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model is\\nlisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model\\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\\nthe competitive models.\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\\noutperforming all of the previously published single models, at less than 1/4 the training cost of the\\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\\ndropout rate Pdrop = 0.1, instead of 0.3.\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\\nused beam search with a beam size of 4 and length penalty α = 0.6 [38]. These hyperparameters\\nwere chosen after experimentation on the development set. We set the maximum output length during\\ninference to input length + 50, but terminate early when possible [38].\\nTable 2 summarizes our results and compares our translation quality and training costs to other model\\narchitectures from the literature. We estimate the number of floating point operations used to train a\\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\\nsingle-precision floating-point capacity of each GPU 5.\\n6.2 Model Variations\\nTo evaluate the importance of different components of the Transformer, we varied our base model\\nin different ways, measuring the change in performance on English-to-German translation on the\\n5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\\nper-word perplexities.\\nN d model dff h d k dv Pdrop ϵls\\ntrain PPL BLEU params\\nsteps (dev) (dev) ×106\\nbase 6 512 2048 8 64 64 0.1 0.1 100K 4.92 25.8 65\\n(A)\\n1 512 512 5.29 24.9\\n4 128 128 5.00 25.5\\n16 32 32 4.91 25.8\\n32 16 16 5.01 25.4\\n(B) 16 5.16 25.1 58\\n32 5.01 25.4 60\\n(C)\\n2 6.11 23.7 36\\n4 5.19 25.3 50\\n8 4.88 25.5 80\\n256 32 32 5.75 24.5 28\\n1024 128 128 4.66 26.0 168\\n1024 5.12 25.4 53\\n4096 4.75 26.2 90\\n(D)\\n0.0 5.77 24.6\\n0.2 4.95 25.5\\n0.0 4.67 25.3\\n0.2 5.47 25.7\\n(E) positional embedding instead of sinusoids 4.92 25.7\\nbig 6 1024 4096 16 0.3 300K 4.33 26.4 213\\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\\ncheckpoint averaging. We present these results in Table 3.\\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunction than dot product may be beneficial. We further observe in rows (C) and (D) that, as expected,\\nbigger models are better, and dropout is very helpful in avoiding over-fitting. In row (E) we replace our\\nsinusoidal positional encoding with learned positional embeddings [9], and observe nearly identical\\nresults to the base model.\\n6.3 English Constituency Parsing\\nTo evaluate if the Transformer can generalize to other tasks we performed experiments on English\\nconstituency parsing. This task presents specific challenges: the output is subject to strong structural\\nconstraints and is significantly longer than the input. Furthermore, RNN sequence-to-sequence\\nmodels have not been able to attain state-of-the-art results in small-data regimes [37].\\nWe trained a 4-layer transformer with dmodel = 1024on the Wall Street Journal (WSJ) portion of the\\nPenn Treebank [25], about 40K training sentences. We also trained it in a semi-supervised setting,\\nusing the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences\\n[37]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens\\nfor the semi-supervised setting.\\nWe performed only a small number of experiments to select the dropout, both attention and residual\\n(section 5.4), learning rates and beam size on the Section 22 development set, all other parameters\\nremained unchanged from the English-to-German base translation model. During inference, we\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='Table 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\\nof WSJ)\\nParser Training WSJ 23 F1\\nVinyals & Kaiser el al. (2014) [37] WSJ only, discriminative 88.3\\nPetrov et al. (2006) [29] WSJ only, discriminative 90.4\\nZhu et al. (2013) [40] WSJ only, discriminative 90.4\\nDyer et al. (2016) [8] WSJ only, discriminative 91.7\\nTransformer (4 layers) WSJ only, discriminative 91.3\\nZhu et al. (2013) [40] semi-supervised 91.3\\nHuang & Harper (2009) [14] semi-supervised 91.3\\nMcClosky et al. (2006) [26] semi-supervised 92.1\\nVinyals & Kaiser el al. (2014) [37] semi-supervised 92.1\\nTransformer (4 layers) semi-supervised 92.7\\nLuong et al. (2015) [23] multi-task 93.0\\nDyer et al. (2016) [8] generative 93.3\\nincreased the maximum output length to input length + 300. We used a beam size of 21 and α = 0.3\\nfor both WSJ only and the semi-supervised setting.\\nOur results in Table 4 show that despite the lack of task-specific tuning our model performs sur-\\nprisingly well, yielding better results than all previously reported models with the exception of the\\nRecurrent Neural Network Grammar [8].\\nIn contrast to RNN sequence-to-sequence models [37], the Transformer outperforms the Berkeley-\\nParser [29] even when training only on the WSJ training set of 40K sentences.\\n7 Conclusion\\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs\\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\\nThe code we used to train and evaluate our models is available at https://github.com/\\ntensorflow/tensor2tensor.\\nAcknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\\ncomments, corrections and inspiration.\\nReferences\\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\\narXiv:1607.06450, 2016.\\n[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\\nlearning to align and translate. CoRR, abs/1409.0473, 2014.\\n[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V . Le. Massive exploration of neural\\nmachine translation architectures. CoRR, abs/1703.03906, 2017.\\n[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\\nreading. arXiv preprint arXiv:1601.06733, 2016.\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\\nmachine translation. CoRR, abs/1406.1078, 2014.\\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\\npreprint arXiv:1610.02357, 2016.\\n[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation\\nof gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\\n[8] Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural\\nnetwork grammars. In Proc. of NAACL, 2016.\\n[9] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\\n[10] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint\\narXiv:1308.0850, 2013.\\n[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition, pages 770–778, 2016.\\n[12] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient flow in\\nrecurrent nets: the difficulty of learning long-term dependencies, 2001.\\n[13] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation,\\n9(8):1735–1780, 1997.\\n[14] Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations\\nacross languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural\\nLanguage Processing, pages 832–841. ACL, August 2009.\\n[15] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\\nthe limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\\n[16] Łukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural\\nInformation Processing Systems, (NIPS), 2016.\\n[17] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\\non Learning Representations (ICLR), 2016.\\n[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\\nray Kavukcuoglu. Neural machine translation in linear time.arXiv preprint arXiv:1610.10099v2,\\n2017.\\n[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.\\n[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\\n[21] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\\narXiv:1703.10722, 2017.\\n[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017.\\n[23] Minh-Thang Luong, Quoc V . Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task\\nsequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015.\\n[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\\nbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated\\ncorpus of english: The penn treebank. Computational linguistics, 19(2):313–330, 1993.\\n[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In\\nProceedings of the Human Language Technology Conference of the NAACL, Main Conference,\\npages 152–159. ACL, June 2006.\\n[27] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\\nmodel. In Empirical Methods in Natural Language Processing, 2016.\\n[28] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\\nsummarization. arXiv preprint arXiv:1705.04304, 2017.\\n[29] Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact,\\nand interpretable tree annotation. In Proceedings of the 21st International Conference on\\nComputational Linguistics and 44th Annual Meeting of the ACL, pages 433–440. ACL, July\\n2006.\\n[30] Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXiv\\npreprint arXiv:1608.05859, 2016.\\n[31] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\\nwith subword units. arXiv preprint arXiv:1508.07909, 2015.\\n[32] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\\nlayer. arXiv preprint arXiv:1701.06538, 2017.\\n[33] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\\nnov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine\\nLearning Research, 15(1):1929–1958, 2014.\\n[34] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory\\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,\\nAdvances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates,\\nInc., 2015.\\n[35] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\\nnetworks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\\n[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\\n[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In\\nAdvances in Neural Information Processing Systems, 2015.\\n[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine\\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\\narXiv:1609.08144, 2016.\\n[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\\nfast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\\n[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate\\nshift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume\\n1: Long Papers), pages 434–443. ACL, August 2013.\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13'}, page_content='Attention Visualizations\\nInput-Input Layer5\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nFigure 3: An example of the attention mechanism following long-distance dependencies in the\\nencoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\\nthe verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for\\nthe word ‘making’. Different colors represent different heads. Best viewed in color.\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content='Input-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nInput-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\\nFull attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5\\nand 6. Note that the attentions are very sharp for this word.\\n14'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='Input-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nInput-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\\nsentence. We give two such examples above, from two different heads from the encoder self-attention\\nat layer 5 of 6. The heads clearly learned to perform different tasks.\\n15')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Reading a pdf file \n",
    "from langchain_community.document_loaders import PyPDFLoader \n",
    "loader=PyPDFLoader('attention.pdf')\n",
    "docs=loader.load() \n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "232bc695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0923f349",
   "metadata": {},
   "source": [
    "How to Recursively Split Text by Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b1bb671f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗ †\\nUniversity of Toronto\\naidan@cs.toronto.edu'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='University of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗ ‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='based solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='our model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. We show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data.\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='tensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\\narXiv:1706.03762v7  [cs.CL]  2 Aug 2023'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='1 Introduction\\nRecurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks\\nin particular, have been firmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 35, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [38, 24, 15].'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='architectures [38, 24, 15].\\nRecurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstates ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='sequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\\ncomputation [32], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='tion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='The Transformer allows for significantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2 Background\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[16], ByteNet [18] and ConvS2S [9], all of which use convolutional neural networks as basic building'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='block, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difficult to learn dependencies between distant positions [ 12]. In the Transformer this is'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='reduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='used successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [34].'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='language modeling tasks [34].\\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3 Model Architecture'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='3 Model Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35].\\nHere, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\\nof continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\\nsequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='[10], consuming the previously generated symbols as additional input when generating the next.\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='Figure 1: The Transformer - model architecture.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1 Encoder and Decoder Stacks\\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='wise fully connected feed-forward network. We employ a residual connection [11] around each of\\nthe two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='Decoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='masking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position i can depend only on the known outputs at positions less than i.\\n3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='Scaled Dot-Product Attention\\n Multi-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1 Scaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='queries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\nquery with all keys, divide each by √dk, and apply a softmax function to obtain the weights on the\\nvalues.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices K and V . We compute\\nthe matrix of outputs as:\\nAttention(Q, K, V) = softmax(QKT\\n√dk\\n)V (1)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='Attention(Q, K, V) = softmax(QKT\\n√dk\\n)V (1)\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof 1√dk\\n. Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='much faster and more space-efficient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code.\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk [3]. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='extremely small gradients 4. To counteract this effect, we scale the dot products by 1√dk\\n.\\n3.2.2 Multi-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\\nwe found it beneficial to linearly project the queries, keys and values h times with different, learned\\nlinear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='queries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\\nvariables with mean 0 and variance 1. Then their dot product, q · k = Pdk\\ni=1 qiki, has mean 0 and variance dk.\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='output values. These are concatenated and once again projected, resulting in the final values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With a single attention head, averaging inhibits this.\\nMultiHead(Q, K, V) = Concat(head1, ...,headh)WO\\nwhere headi = Attention(QWQ\\ni , KWK\\ni , V WV\\ni )\\nWhere the projections are parameter matricesWQ\\ni ∈ Rdmodel×dk , WK\\ni ∈ Rdmodel×dk , WV'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='i ∈ Rdmodel×dk , WK\\ni ∈ Rdmodel×dk , WV\\ni ∈ Rdmodel×dv\\nand WO ∈ Rhdv×dmodel .\\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\\ndk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost\\nis similar to that of single-head attention with full dimensionality.\\n3.2.3 Applications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[38, 2, 9].\\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='and queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward\\ninformation flow in the decoder to preserve the auto-regressive property. We implement this'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='inside of scaled dot-product attention by masking out (setting to −∞) all values in the input\\nof the softmax which correspond to illegal connections. See Figure 2.\\n3.3 Position-wise Feed-Forward Networks\\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\\nconnected feed-forward network, which is applied to each position separately and identically. This\\nconsists of two linear transformations with a ReLU activation in between.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='FFN(x) = max(0, xW1 + b1)W2 + b2 (2)\\nWhile the linear transformations are the same across different positions, they use different parameters\\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\\nThe dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\\ndff = 2048.\\n3.4 Embeddings and Softmax\\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='tokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\\nlinear transformation, similar to [30]. In the embedding layers, we multiply those weights by √dmodel.\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\\nfor different layer types. n is the sequence length, d is the representation dimension, k is the kernel\\nsize of convolutions and r the size of the neighborhood in restricted self-attention.\\nLayer Type Complexity per Layer Sequential Maximum Path Length\\nOperations\\nSelf-Attention O(n2 · d) O(1) O(1)\\nRecurrent O(n · d2) O(n) O(n)\\nConvolutional O(k · n · d2) O(1) O(logk(n))'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='Convolutional O(k · n · d2) O(1) O(logk(n))\\nSelf-Attention (restricted) O(r · n · d) O(1) O(n/r)\\n3.5 Positional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\\norder of the sequence, we must inject some information about the relative or absolute position of the\\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='bottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\\nlearned and fixed [9].\\nIn this work, we use sine and cosine functions of different frequencies:\\nP E(pos,2i) = sin(pos/100002i/dmodel )\\nP E(pos,2i+1) = cos(pos/100002i/dmodel )\\nwhere pos is the position and i is the dimension. That is, each dimension of the positional encoding'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='corresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π. We\\nchose this function because we hypothesized it would allow the model to easily learn to attend by\\nrelative positions, since for any fixed offset k, P Epos+k can be represented as a linear function of\\nP Epos.\\nWe also experimented with using learned positional embeddings [9] instead, and found that the two'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='versions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\\nduring training.\\n4 Why Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='(x1, ..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi ∈ Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='The third is the path length between long-range dependencies in the network. Learning long-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to\\ntraverse in the network. The shorter these paths between any combination of positions in the input\\nand output sequences, the easier it is to learn long-range dependencies [12]. Hence we also compare'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='the maximum path length between any two input and output positions in networks composed of the\\ndifferent layer types.\\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\\nexecuted operations, whereas a recurrent layer requires O(n) sequential operations. In terms of\\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\\n6'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='length n is smaller than the representation dimensionality d, which is most often the case with\\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\\n[38] and byte-pair [31] representations. To improve computational performance for tasks involving\\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size r in\\nthe input sequence centered around the respective output position. This would increase the maximum'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='path length to O(n/r). We plan to investigate this approach further in future work.\\nA single convolutional layer with kernel width k < ndoes not connect all pairs of input and output\\npositions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels,\\nor O(logk(n)) in the case of dilated convolutions [ 18], increasing the length of the longest paths\\nbetween any two positions in the network. Convolutional layers are generally more expensive than'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='recurrent layers, by a factor of k. Separable convolutions [ 6], however, decrease the complexity\\nconsiderably, to O(k · n · d + n · d2). Even with k = n, however, the complexity of a separable\\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side benefit, self-attention could yield more interpretable models. We inspect attention distributions'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='from our models and present and discuss examples in the appendix. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5 Training\\nThis section describes the training regime for our models.\\n5.1 Training Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='sentence pairs. Sentences were encoded using byte-pair encoding [ 3], which has a shared source-\\ntarget vocabulary of about 37000 tokens. For English-French, we used the significantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\\nvocabulary [38]. Sentence pairs were batched together by approximate sequence length. Each training\\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='target tokens.\\n5.2 Hardware and Schedule\\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\\n(3.5 days).\\n5.3 Optimizer'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='(3.5 days).\\n5.3 Optimizer\\nWe used the Adam optimizer [20] with β1 = 0.9, β2 = 0.98 and ϵ = 10−9. We varied the learning\\nrate over the course of training, according to the formula:\\nlrate = d−0.5\\nmodel · min(step_num−0.5, step_num · warmup_steps−1.5) (3)\\nThis corresponds to increasing the learning rate linearly for the first warmup_steps training steps,\\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\\nwarmup_steps = 4000.\\n5.4 Regularization'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='warmup_steps = 4000.\\n5.4 Regularization\\nWe employ three types of regularization during training:\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\\nModel\\nBLEU Training Cost (FLOPs)\\nEN-DE EN-FR EN-DE EN-FR\\nByteNet [18] 23.75\\nDeep-Att + PosUnk [39] 39.2 1.0 · 1020\\nGNMT + RL [38] 24.6 39.92 2.3 · 1019 1.4 · 1020\\nConvS2S [9] 25.16 40.46 9.6 · 1018 1.5 · 1020\\nMoE [32] 26.03 40.56 2.0 · 1019 1.2 · 1020\\nDeep-Att + PosUnk Ensemble [39] 40.4 8.0 · 1020'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='Deep-Att + PosUnk Ensemble [39] 40.4 8.0 · 1020\\nGNMT + RL Ensemble [38] 26.30 41.16 1.8 · 1020 1.1 · 1021\\nConvS2S Ensemble [9] 26.36 41.29 7.7 · 1019 1.2 · 1021\\nTransformer (base model) 27.3 38.1 3.3 · 1018\\nTransformer (big) 28.4 41.8 2.3 · 1019\\nResidual Dropout We apply dropout [33] to the output of each sub-layer, before it is added to the\\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='positional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\\nPdrop = 0.1.\\nLabel Smoothing During training, we employed label smoothing of value ϵls = 0.1 [36]. This\\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\\n6 Results\\n6.1 Machine Translation\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='in Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model is\\nlisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model\\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\\nthe competitive models.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='the competitive models.\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\\noutperforming all of the previously published single models, at less than 1/4 the training cost of the\\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\\ndropout rate Pdrop = 0.1, instead of 0.3.\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='were written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\\nused beam search with a beam size of 4 and length penalty α = 0.6 [38]. These hyperparameters\\nwere chosen after experimentation on the development set. We set the maximum output length during\\ninference to input length + 50, but terminate early when possible [38].\\nTable 2 summarizes our results and compares our translation quality and training costs to other model'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='architectures from the literature. We estimate the number of floating point operations used to train a\\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\\nsingle-precision floating-point capacity of each GPU 5.\\n6.2 Model Variations\\nTo evaluate the importance of different components of the Transformer, we varied our base model\\nin different ways, measuring the change in performance on English-to-German translation on the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\\nper-word perplexities.\\nN d model dff h d k dv Pdrop ϵls\\ntrain PPL BLEU params\\nsteps (dev) (dev) ×106\\nbase 6 512 2048 8 64 64 0.1 0.1 100K 4.92 25.8 65\\n(A)\\n1 512 512 5.29 24.9\\n4 128 128 5.00 25.5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='(A)\\n1 512 512 5.29 24.9\\n4 128 128 5.00 25.5\\n16 32 32 4.91 25.8\\n32 16 16 5.01 25.4\\n(B) 16 5.16 25.1 58\\n32 5.01 25.4 60\\n(C)\\n2 6.11 23.7 36\\n4 5.19 25.3 50\\n8 4.88 25.5 80\\n256 32 32 5.75 24.5 28\\n1024 128 128 4.66 26.0 168\\n1024 5.12 25.4 53\\n4096 4.75 26.2 90\\n(D)\\n0.0 5.77 24.6\\n0.2 4.95 25.5\\n0.0 4.67 25.3\\n0.2 5.47 25.7\\n(E) positional embedding instead of sinusoids 4.92 25.7\\nbig 6 1024 4096 16 0.3 300K 4.33 26.4 213'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='big 6 1024 4096 16 0.3 300K 4.33 26.4 213\\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\\ncheckpoint averaging. We present these results in Table 3.\\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='In Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunction than dot product may be beneficial. We further observe in rows (C) and (D) that, as expected,\\nbigger models are better, and dropout is very helpful in avoiding over-fitting. In row (E) we replace our'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='sinusoidal positional encoding with learned positional embeddings [9], and observe nearly identical\\nresults to the base model.\\n6.3 English Constituency Parsing\\nTo evaluate if the Transformer can generalize to other tasks we performed experiments on English\\nconstituency parsing. This task presents specific challenges: the output is subject to strong structural\\nconstraints and is significantly longer than the input. Furthermore, RNN sequence-to-sequence'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='models have not been able to attain state-of-the-art results in small-data regimes [37].\\nWe trained a 4-layer transformer with dmodel = 1024on the Wall Street Journal (WSJ) portion of the\\nPenn Treebank [25], about 40K training sentences. We also trained it in a semi-supervised setting,\\nusing the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences\\n[37]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='for the semi-supervised setting.\\nWe performed only a small number of experiments to select the dropout, both attention and residual\\n(section 5.4), learning rates and beam size on the Section 22 development set, all other parameters\\nremained unchanged from the English-to-German base translation model. During inference, we\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='Table 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\\nof WSJ)\\nParser Training WSJ 23 F1\\nVinyals & Kaiser el al. (2014) [37] WSJ only, discriminative 88.3\\nPetrov et al. (2006) [29] WSJ only, discriminative 90.4\\nZhu et al. (2013) [40] WSJ only, discriminative 90.4\\nDyer et al. (2016) [8] WSJ only, discriminative 91.7\\nTransformer (4 layers) WSJ only, discriminative 91.3\\nZhu et al. (2013) [40] semi-supervised 91.3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='Zhu et al. (2013) [40] semi-supervised 91.3\\nHuang & Harper (2009) [14] semi-supervised 91.3\\nMcClosky et al. (2006) [26] semi-supervised 92.1\\nVinyals & Kaiser el al. (2014) [37] semi-supervised 92.1\\nTransformer (4 layers) semi-supervised 92.7\\nLuong et al. (2015) [23] multi-task 93.0\\nDyer et al. (2016) [8] generative 93.3\\nincreased the maximum output length to input length + 300. We used a beam size of 21 and α = 0.3\\nfor both WSJ only and the semi-supervised setting.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='Our results in Table 4 show that despite the lack of task-specific tuning our model performs sur-\\nprisingly well, yielding better results than all previously reported models with the exception of the\\nRecurrent Neural Network Grammar [8].\\nIn contrast to RNN sequence-to-sequence models [37], the Transformer outperforms the Berkeley-\\nParser [29] even when training only on the WSJ training set of 40K sentences.\\n7 Conclusion'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='7 Conclusion\\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='English-to-French translation tasks, we achieve a new state of the art. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='such as images, audio and video. Making generation less sequential is another research goals of ours.\\nThe code we used to train and evaluate our models is available at https://github.com/\\ntensorflow/tensor2tensor.\\nAcknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\\ncomments, corrections and inspiration.\\nReferences\\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\\narXiv:1607.06450, 2016.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='arXiv:1607.06450, 2016.\\n[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\\nlearning to align and translate. CoRR, abs/1409.0473, 2014.\\n[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V . Le. Massive exploration of neural\\nmachine translation architectures. CoRR, abs/1703.03906, 2017.\\n[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\\nreading. arXiv preprint arXiv:1601.06733, 2016.\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\\nmachine translation. CoRR, abs/1406.1078, 2014.\\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\\npreprint arXiv:1610.02357, 2016.\\n[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='of gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\\n[8] Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural\\nnetwork grammars. In Proc. of NAACL, 2016.\\n[9] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\\n[10] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint\\narXiv:1308.0850, 2013.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='arXiv:1308.0850, 2013.\\n[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition, pages 770–778, 2016.\\n[12] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient flow in\\nrecurrent nets: the difficulty of learning long-term dependencies, 2001.\\n[13] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='9(8):1735–1780, 1997.\\n[14] Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations\\nacross languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural\\nLanguage Processing, pages 832–841. ACL, August 2009.\\n[15] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\\nthe limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='[16] Łukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural\\nInformation Processing Systems, (NIPS), 2016.\\n[17] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\\non Learning Representations (ICLR), 2016.\\n[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\\nray Kavukcuoglu. Neural machine translation in linear time.arXiv preprint arXiv:1610.10099v2,\\n2017.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='2017.\\n[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.\\n[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\\n[21] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\\narXiv:1703.10722, 2017.\\n[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='Zhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017.\\n[23] Minh-Thang Luong, Quoc V . Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task\\nsequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015.\\n[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\\nbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated\\ncorpus of english: The penn treebank. Computational linguistics, 19(2):313–330, 1993.\\n[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In\\nProceedings of the Human Language Technology Conference of the NAACL, Main Conference,\\npages 152–159. ACL, June 2006.\\n[27] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='model. In Empirical Methods in Natural Language Processing, 2016.\\n[28] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\\nsummarization. arXiv preprint arXiv:1705.04304, 2017.\\n[29] Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact,\\nand interpretable tree annotation. In Proceedings of the 21st International Conference on\\nComputational Linguistics and 44th Annual Meeting of the ACL, pages 433–440. ACL, July\\n2006.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='2006.\\n[30] Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXiv\\npreprint arXiv:1608.05859, 2016.\\n[31] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\\nwith subword units. arXiv preprint arXiv:1508.07909, 2015.\\n[32] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='layer. arXiv preprint arXiv:1701.06538, 2017.\\n[33] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\\nnov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine\\nLearning Research, 15(1):1929–1958, 2014.\\n[34] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory\\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='Advances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates,\\nInc., 2015.\\n[35] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\\nnetworks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\\n[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In\\nAdvances in Neural Information Processing Systems, 2015.\\n[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine\\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\\narXiv:1609.08144, 2016.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='arXiv:1609.08144, 2016.\\n[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\\nfast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\\n[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate\\nshift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume\\n1: Long Papers), pages 434–443. ACL, August 2013.\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13'}, page_content='Attention Visualizations\\nInput-Input Layer5\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13'}, page_content='.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nFigure 3: An example of the attention mechanism following long-distance dependencies in the\\nencoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\\nthe verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for\\nthe word ‘making’. Different colors represent different heads. Best viewed in color.\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content='Input-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nInput-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content='but\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\\nFull attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5\\nand 6. Note that the attentions are very sharp for this word.\\n14'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='Input-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nInput-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='but\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\\nsentence. We give two such examples above, from two different heads from the encoder self-attention\\nat layer 5 of 6. The heads clearly learned to perform different tasks.\\n15')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter \n",
    " \n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50)\n",
    "final_documents=text_splitter.split_documents(docs) \n",
    "final_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "894a3dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswani∗\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeer∗\n",
      "Google Brain\n",
      "noam@google.com\n",
      "Niki Parmar∗\n",
      "Google Research\n",
      "nikip@google.com\n",
      "Jakob Uszkoreit∗\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jones∗\n",
      "Google Research\n",
      "llion@google.com\n",
      "Aidan N. Gomez∗ †\n",
      "University of Toronto\n",
      "aidan@cs.toronto.edu' metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n",
      "page_content='University of Toronto\n",
      "aidan@cs.toronto.edu\n",
      "Łukasz Kaiser∗\n",
      "Google Brain\n",
      "lukaszkaiser@google.com\n",
      "Illia Polosukhin∗ ‡\n",
      "illia.polosukhin@gmail.com\n",
      "Abstract\n",
      "The dominant sequence transduction models are based on complex recurrent or\n",
      "convolutional neural networks that include an encoder and a decoder. The best\n",
      "performing models also connect the encoder and decoder through an attention\n",
      "mechanism. We propose a new simple network architecture, the Transformer,' metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(final_documents[0])\n",
    "print(final_documents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "575cb234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'speech.txt'}, page_content='\"Your time is limited, so don’t waste it living someone else’s life.\\n\\nDon’t be trapped by dogma — which is living with the results of other people’s thinking. Don’t let the noise of others’ opinions drown out your own inner voice. And most important, have the courage to follow your heart and intuition.\\n\\nThey somehow already know what you truly want to become. Everything else is secondary.\\n\\nWhen I was 17, I read a quote that went something like:\\nIf you live each day as if it was your last, someday you’ll most certainly be right.\"')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader \n",
    "\n",
    "loader=TextLoader('speech.txt') \n",
    "docs=loader.load() \n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "404911d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='\"Your time is limited, so don’t waste it living'\n",
      "page_content='it living someone else’s life.'\n"
     ]
    }
   ],
   "source": [
    "speech=\"\" \n",
    "with open(\"speech.txt\")as f:\n",
    "    speech=f.read() \n",
    "speech \n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=50,chunk_overlap=10) \n",
    "text=text_splitter.create_documents([speech])\n",
    "print(text[0]) \n",
    "print(text[1]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "642b7529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d427cf",
   "metadata": {},
   "source": [
    "### Character Text Splitter \n",
    "\n",
    "This is the simplest method.This splits based on given character sequence,which defaults to \"\\n\\n\".Chunk length is measured by number of characters.\n",
    "\n",
    "- How the text is split:by single character separator\n",
    "- How the chunk size is measured:by number of characters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f230b211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content='\"Your time is limited, so don’t waste it living someone else’s life.\\n\\nDon’t be trapped by dogma — which is living with the results of other people’s thinking. Don’t let the noise of others’ opinions drown out your own inner voice. And most important, have the courage to follow your heart and intuition.\\n\\nThey somehow already know what you truly want to become. Everything else is secondary.\\n\\nWhen I was 17, I read a quote that went something like:\\nIf you live each day as if it was your last, someday you’ll most certainly be right.\"')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader \n",
    "\n",
    "loader=TextLoader('speech.txt') \n",
    "docs=loader.load() \n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14131221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 233, which is longer than the specified 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content='\"Your time is limited, so don’t waste it living someone else’s life.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='Don’t be trapped by dogma — which is living with the results of other people’s thinking. Don’t let the noise of others’ opinions drown out your own inner voice. And most important, have the courage to follow your heart and intuition.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='They somehow already know what you truly want to become. Everything else is secondary.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='When I was 17, I read a quote that went something like:\\nIf you live each day as if it was your last, someday you’ll most certainly be right.\"')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "text_splitter=CharacterTextSplitter(separator=\"\\n\\n\",chunk_size=100,chunk_overlap=20)\n",
    "text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921a78cf",
   "metadata": {},
   "source": [
    "Created a chunk of size 233, which is longer than the specified 100 --> Because it is now able to find the seperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4a761467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 233, which is longer than the specified 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='\"Your time is limited, so don’t waste it living someone else’s life.'\n",
      "page_content='Don’t be trapped by dogma — which is living with the results of other people’s thinking. Don’t let the noise of others’ opinions drown out your own inner voice. And most important, have the courage to follow your heart and intuition.'\n"
     ]
    }
   ],
   "source": [
    "speech=\"\" \n",
    "with open(\"speech.txt\") as f: \n",
    "    speech=f.read() \n",
    "\n",
    "text_splitter=CharacterTextSplitter(chunk_size=100,chunk_overlap=20) \n",
    "text=text_splitter.create_documents([speech]) \n",
    "print(text[0]) \n",
    "print(text[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45e4880",
   "metadata": {},
   "source": [
    "### How to Split by HTML header \n",
    "\n",
    "HTMLHeaderTextSPlitter is a structure-aware chunker that splits text at the HTML element level and adds metadata for each header \"relavant\" to any given chunk.It can return chunks element by element or combine elements with the same metadata,with the objectives of \n",
    "- Keeping related text grouped(more or less) semantically \n",
    "- Preserving context-rich information encoded in document structures.it can be used with other text splitters as part of a chunking pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5158943c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': 'Welcome to HTMLTextSplitter'}, page_content='Welcome to HTMLTextSplitter'),\n",
       " Document(metadata={'Header 1': 'Welcome to HTMLTextSplitter'}, page_content='This tool helps you split HTML content intelligently for LLM-based applications.'),\n",
       " Document(metadata={'Header 1': 'Welcome to HTMLTextSplitter', 'Header 2': 'Why Use HTMLTextSplitter?'}, page_content='Why Use HTMLTextSplitter?'),\n",
       " Document(metadata={'Header 1': 'Welcome to HTMLTextSplitter', 'Header 2': 'Why Use HTMLTextSplitter?'}, page_content=\"Because plain text splitters don't preserve HTML structure, which can lead to context loss.  \\nHTMLTextSplitter keeps the logical flow intact.\"),\n",
       " Document(metadata={'Header 1': 'Welcome to HTMLTextSplitter', 'Header 2': 'Features'}, page_content='Features'),\n",
       " Document(metadata={'Header 1': 'Welcome to HTMLTextSplitter', 'Header 2': 'Features'}, page_content='Preserves semantic blocks like headings and paragraphs  \\nSupports recursive chunking with overlap  \\nWorks well with web scraping pipelines'),\n",
       " Document(metadata={'Header 1': 'Welcome to HTMLTextSplitter', 'Header 2': 'Resources'}, page_content='Resources'),\n",
       " Document(metadata={'Header 1': 'Welcome to HTMLTextSplitter', 'Header 2': 'Resources'}, page_content='Check out the for more info.  \\nLangChain documentation'),\n",
       " Document(metadata={'Header 1': 'Welcome to HTMLTextSplitter', 'Header 2': 'Conclusion'}, page_content='Conclusion'),\n",
       " Document(metadata={'Header 1': 'Welcome to HTMLTextSplitter', 'Header 2': 'Conclusion'}, page_content='Use this tool when dealing with rich HTML to improve retrieval and comprehension in LLM workflows.')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter \n",
    "\n",
    "html_string=html_content = \"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title>Learn HTMLTextSplitter</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>Welcome to HTMLTextSplitter</h1>\n",
    "    <p>This tool helps you split HTML content intelligently for LLM-based applications.</p>\n",
    "\n",
    "    <h2>Why Use HTMLTextSplitter?</h2>\n",
    "    <p>Because plain text splitters don't preserve HTML structure, which can lead to context loss.</p>\n",
    "    <p>HTMLTextSplitter keeps the logical flow intact.</p>\n",
    "\n",
    "    <h2>Features</h2>\n",
    "    <ul>\n",
    "      <li>Preserves semantic blocks like headings and paragraphs</li>\n",
    "      <li>Supports recursive chunking with overlap</li>\n",
    "      <li>Works well with web scraping pipelines</li>\n",
    "    </ul>\n",
    "\n",
    "    <h2>Resources</h2>\n",
    "    <p>Check out the <a href=\"https://docs.langchain.com\">LangChain documentation</a> for more info.</p>\n",
    "\n",
    "    <h2>Conclusion</h2>\n",
    "    <p>Use this tool when dealing with rich HTML to improve retrieval and comprehension in LLM workflows.</p>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "headers_to_split_on=[(\"h1\",\"Header 1\"), \n",
    "                     (\"h2\",\"Header 2\"), \n",
    "                     (\"h3\",\"Header 3\")]\n",
    "html_splitter=HTMLHeaderTextSplitter(headers_to_split_on)\n",
    "html_header_splits=html_splitter.split_text(html_string) \n",
    "html_header_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "676269aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='End container NOTE: Script required for drop-down button to work (mirrors).  \\nEnd header wrapper End content End footer  \\nEnd header  \\nEnd navigation End search  \\nStanford Encyclopedia of Philosophy  \\nMenu  \\nBrowse  \\nTable of Contents  \\nWhat\\'s New  \\nRandom Entry  \\nChronological  \\nArchives  \\nAbout  \\nEditorial Information  \\nAbout the SEP  \\nEditorial Board  \\nHow to Cite the SEP  \\nSpecial Characters  \\nAdvanced Tools  \\nContact  \\nSupport SEP  \\nSupport the SEP  \\nPDFs for SEP Friends  \\nMake a Donation  \\nSEPIA for Libraries  \\nBegin article sidebar End article sidebar NOTE: Article content must have two wrapper divs: id=\"article\" and id=\"article-content\" End article NOTE: article banner is outside of the id=\"article\" div. End article-banner  \\nEntry Navigation  \\nEntry Contents  \\nBibliography  \\nAcademic Tools  \\nFriends PDF Preview  \\nAuthor and Citation Info  \\nBack to Top  \\nEnd article-content  \\nBEGIN ARTICLE HTML #aueditable DO NOT MODIFY THIS LINE AND BELOW END ARTICLE HTML  \\nDO NOT MODIFY THIS LINE AND ABOVE'),\n",
       " Document(metadata={'Header 1': 'Plato’s Ethics: An Overview'}, page_content='Plato’s Ethics: An Overview'),\n",
       " Document(metadata={'Header 1': 'Plato’s Ethics: An Overview'}, page_content='First published Tue Sep 16, 2003; substantive revision Wed Feb 1, 2023  \\nLike most other ancient philosophers, Plato maintains a virtue-based\\r\\neudaemonistic conception of ethics. That is to say, happiness or\\r\\nwell-being ( ) is the highest aim of moral thought\\r\\nand conduct, and the virtues ( :\\r\\n‘excellence’) are the dispositions/skills needed to attain\\r\\nit. If Plato’s conception of happiness is elusive and his\\r\\nsupport for a morality of happiness seems somewhat subdued, there are\\r\\nseveral reasons. First, he nowhere defines the concept of happiness\\r\\nnor makes it the direct target of investigation but introduces it in\\r\\nan oblique way in the pursuit of other questions. Second, the\\r\\ntreatment of the human good varies in the different dialogues, so that\\r\\nreaders find themselves confronted with the problem of what to make of\\r\\nthe discrepancies between different works. This touches on a\\r\\nfundamental problem with Plato’s work – namely, whether to\\r\\nfollow a ‘unitarian’, ‘revisionist’, or\\r\\n‘developmentalist’ approach to his writings. Whereas\\r\\nunitarians regard the dialogues as pieces of one mosaic and take the\\r\\nview that Plato, in essence, maintains a unified doctrine from his\\r\\nearliest to his latest works, revisionists maintain that Plato’s\\r\\nthought underwent a fundamental transformation later in his life,\\r\\nwhile ‘developmentalists’ hold that Plato’s views\\r\\nevolved significantly throughout his career. While revisionism has\\r\\nlost its impact in recent years, developmentalism has gained in\\r\\ninfluence. Although there is no unanimity, few unitarians nowadays\\r\\ndeny that the character of Plato’s early, middle, and late works\\r\\ndiffers in style, language, scope, and content, as is to be expected\\r\\nin a philosopher who was at work for more than fifty years. Most\\r\\ndevelopmentalists, in turn, agree that it is impossible to line up\\r\\nPlato’s works like pearls on a string and to reconstruct his\\r\\nprogress from dialogue to dialogue; where the views expressed in\\r\\ndifferent dialogues seem to disagree, there may be complementation or\\r\\nsupplementation at work, rather than divergence. Given that Plato\\r\\nnever speaks in his own voice, it is important to take note of who the\\r\\ninterlocutors are and what role is assigned to Socrates, if he is the\\r\\nmain speaker. Plato’s dialogues should never be treated in\\r\\nisolation when it comes to the reconstruction of his doctrine; but\\r\\neven the comparison and contrasting of ideas presented in different\\r\\ndialogues is not a safe recipe for interpreting this elusive\\r\\nthinker’s views (for a more detailed discussion see the entry on ).  \\neudaimonia  \\naretê  \\nPlato  \\nPlato’s so-called ‘Socratic’ dialogues share certain\\r\\ncharacteristics as a group. They are short interrogations by Socrates\\r\\nof the kind indicated in his explanation of his divine mission in the . They seem designed, inter alia, to undermine\\r\\nunquestioned traditional views and values rather than to develop\\r\\npositive accounts. The positive accounts contained in the middle, the\\r\\nso-called ‘Platonic’, dialogues – that are grouped\\r\\naround the – treat happiness in different ways\\r\\nas a state of perfection in a moral as well as in an intellectual\\r\\nsense. The exact nature of this state of mind is not easy to pinpoint,\\r\\nhowever, because it is based on metaphysical presuppositions that are,\\r\\nat least prima facie, both hazy and out of the realm of ordinary\\r\\nunderstanding. There is not, as there is in Aristotle, an explicit\\r\\ndetermination of happiness as the actualization of one’s best\\r\\npotential in a well-organized community. Instead, at least in some\\r\\ntexts, Plato’s moral ideals appear both austere and\\r\\nself-abnegating: The soul is to remain aloof from the pleasures of the\\r\\nbody in the pursuit of higher knowledge, while communal life demands\\r\\nthe subordination of individual wishes and aims to the common\\r\\ngood.  \\nApology  \\nRepublic  \\nThe difficulties of assessing Plato’s ethical thought are\\r\\ncompounded by the fact that the metaphysical underpinnings seem to\\r\\nchange during his long life. In the Socratic dialogues, there are no\\r\\nindications that the search for virtue and the human good goes beyond\\r\\nthe human realm. This changes in the middle dialogues that show a\\r\\ngrowing interest in an all-encompassing metaphysical grounding of\\r\\nknowledge, a development that leads to the positing of the\\r\\n‘Forms’ as the determinants of the true nature of all\\r\\nthings, culminating in the Form of the Good as the transcendent\\r\\nprinciple of all goodness. Though the theory of the Forms is not\\r\\nconfined to human values but encompasses the whole of nature, Plato, in\\r\\nthe middle dialogues, seems to assume no more than an analogy between\\r\\nhuman affairs and cosmic harmony. The late dialogues, by contrast,\\r\\ndisplay an increasing tendency to assume a unity of the microcosm of\\r\\nhuman life and the macrocosmic order of the entire universe, a\\r\\ntendency that is displayed most fully in the and the . While these holistic tendencies appeal to the\\r\\nimagination because they rely on harmonic relations expressed in\\r\\nmathematical proportions, the metaphysical status of the Forms is even\\r\\nharder to make out in the late dialogues than in the middle dialogues.\\r\\nThough Plato’s late works do not show any willingness to lower\\r\\nthe standards of knowledge as such, Plato indicates that his design of\\r\\na rational cosmic order is based on conjecture and speculation, an\\r\\nacknowledgment that finds its counterpart in his more pragmatic\\r\\ntreatment of ethical standards and political institutions in his last\\r\\npolitical work, the .  \\nPhilebus  \\nTimaeus  \\nLaws  \\nEntry Contents Entry Contents  \\n1. Preliminaries  \\n2. The early dialogues: Examining life  \\n2.1 The aporetic procedure  \\n2.2 The quest for definition  \\n3. The middle dialogues: Justice and other virtues  \\n3.1 Human nature and its needs  \\n3.2 Virtues of state and soul  \\n3.3 The desire for self-perfection  \\n3.4 The quest for method  \\n4. The late dialogues: Ethics and cosmology  \\n4  \\n.1 Harmony and cosmic goodness  \\n4  \\n.2 Measure for measure  \\nGlossary  \\nBibliography  \\nTranslations  \\nSingle-Authored Overviews  \\nAnthologies  \\nProblems of chronology  \\nStudies on Plato’s dialogues  \\nAcademic Tools  \\nOther Internet Resources  \\nRelated Entries  \\n1. Preliminaries  \\nIf ethics is widely regarded as the most accessible branch of\\r\\nphilosophy, it is so because many of its presuppositions are,\\r\\nseemingly, self-evident or trivial truths: All human actions, for\\r\\nexample, serve some end or purpose; whether they are right or wrong\\r\\ndepends on the agent’s overall aims. At least for secularists,\\r\\nthe attainment of these overall aims is regarded as a major condition\\r\\nof the good life. What we regard as a life worth living also depends\\r\\non the notion we have of our own nature and of the conditions of its\\r\\nfulfillment. This, in turn, is determined, at least in part, by the\\r\\nvalues and standards of the society we live in. Personal ends and\\r\\npurposes depend in each case not only on reason, but also on the\\r\\nindividual agents’ dispositions (i.e., their ingrained likes and\\r\\ndislikes, which determine their personal character). The attainment of\\r\\nthese ends can also depend at least in part on external factors, such\\r\\nas health, material prosperity, social status, and even on good looks\\r\\nor sheer luck.  \\nAlthough these presuppositions may seem self-evident, most of the time,\\r\\nhuman beings are aware of them only implicitly because they lead\\r\\ntheir lives in accordance with pre-established standards and values\\r\\nthat are, under normal circumstances, not objects of reflection. It is\\r\\nonly in times of crisis that a society’s traditions and precepts\\r\\nare challenged by someone like Socrates, who sees the need to disturb\\r\\nhis fellows’ complacency. The historical Socrates was, of\\r\\ncourse, not the first to question the Greek way of life. Presocratic\\r\\nphilosophers such as Xenophanes, Heraclitus, or Empedocles had been\\r\\ncritics of their times, and the sophists had argued provocatively\\r\\nthat, contrary to the naïve view, it is custom and convention,\\r\\nrather than nature that set the standards for what is deemed right or\\r\\nwrong, good or bad, in every society. But if other thinkers preceded\\r\\nSocrates with moral and social criticism, he was certainly the first\\r\\nto challenge his fellows on an individual basis on the ground that\\r\\n‘the unexamined life is not worth living’ ( .\\r\\n38a). Whatever position one may take in the controversy concerning the\\r\\ndegree to which Plato’s early dialogues are true to the\\r\\nhistorical Socrates’ discussions, the independent testimony of\\r\\nXenophon leaves little doubt that Socrates’ cross-examinations\\r\\n( ) provoked the kind of enmity against him that led\\r\\nto his conviction and execution. In the eyes of conservative\\r\\nAthenians, Socrates’ questioning undermined the traditional\\r\\nvalues of their society. As Socrates saw it, the ‘virtues’\\r\\n– which is to say the social skills, attitudes, and\\r\\ncharacter-traits possessed by most Athenian citizens of his time\\r\\n– were all too often geared towards their possessors’\\r\\nwealth, power, and capacities for self-indulgence, to the detriment of\\r\\npublic morality and the community’s well-being (see the entry on ).  \\nAp  \\nelenchos  \\nSocrates  \\nThe Socratic legacy prompted Plato to engage in a thorough examination\\r\\nof the nature of knowledge and reality, an examination that gradually\\r\\ntook him far beyond the scope of the historical Socrates’\\r\\ndiscussions. Nevertheless, Plato continued to present most of his\\r\\ninvestigations as dialogues between Socrates and some partner or\\r\\npartners. And Plato preserved the dialogical form even in those of his\\r\\nlate works where Socrates is replaced by a stand-in and where the\\r\\ndidactic nature of the presentations is hard to reconcile with the\\r\\npretense of live discussion. But these didactic discourses continue to\\r\\ncombine questions of ethical, political, social, or psychological\\r\\nimportance with metaphysical, methodological, and epistemological\\r\\nconsiderations. And it can be hard to assess the extent to which Plato\\r\\nagrees with the pronouncements of his speakers, whether that speaker\\r\\nis Socrates or anyone else. Furthermore, the fact that a certain\\r\\nethical problem or its solution is not mentioned in a certain dialogue\\r\\ndoes not mean that Plato was unaware of it. There is, therefore, no\\r\\ncertainty concerning the question: “What did Plato see and when\\r\\ndid he first see it?” The lack of information about the order in\\r\\nwhich Plato wrote his works adds to this difficulty. It stands to\\r\\nreason, however, that he started with the short dialogues that\\r\\nquestion traditional virtues – wisdom, courage, justice,\\r\\nmoderation, piety. It also stands to reason that Plato gradually\\r\\nwidened the scope of his investigations by reflecting not only on the\\r\\nsocial and political conditions of morality but also on the logical,\\r\\nepistemological, and metaphysical presuppositions of a successful\\r\\nmoral theory. These theoretical reflections often take on a life of\\r\\ntheir own. Several of Plato’s later works address ethical\\r\\nproblems only marginally or not at all. The , the , and the deal primarily or\\r\\nexclusively with epistemological and metaphysical problems of a quite\\r\\ngeneral nature. Nevertheless, as witnessed by the ,\\r\\nthe , the , and the ,\\r\\nPlato never lost interest in the question of the conditions of the\\r\\ngood human life.  \\nParmenides  \\nTheaetetus  \\nSophist  \\nPhilebus  \\nStatesman  \\nTimaeus  \\nLaws  \\n2. The early dialogues: Examining life  \\n2.1 The aporetic procedure  \\nThe early ‘Socratic’ dialogues are not concerned with the\\r\\nquestion of the good life and its conditions in general but rather\\r\\nwith particular virtues. Socrates explores these virtues through\\r\\ndiscussions with persons who are regarded either as representatives\\r\\nof, or claim to be experts on, that virtue. Socrates’\\r\\njustification for this procedure is that a paragon or expert must know\\r\\nthe property that characterizes his particular virtue and must,\\r\\ntherefore, be able to give an account or definition of it (cf. Xenophon I, 10; 16). Thus, in the ,\\r\\nSocrates discusses piety/holiness with an alleged ‘expert’\\r\\non religious affairs. In the , he discusses courage\\r\\nwith two renowned generals in the Peloponnesian war, Laches and\\r\\nNicias. Similarly, in the , Socrates\\r\\naddresses – somewhat ironically – the nature of moderation\\r\\nwith two of the later Thirty Tyrants, namely with the then very young\\r\\nCharmides, an alleged model of modesty, and his guardian and\\r\\nintellectual mentor, Critias. In the , Socrates\\r\\nraises the question of the nature of the beautiful with a producer of\\r\\n‘beautiful things’, the sophist and polymath Hippias. In\\r\\nthe , Socrates focuses on the question of the unity\\r\\nof virtue in a discussion with Protagoras, the most famous teacher of\\r\\n‘civic virtues’ among the sophists. And in the , Socrates discusses the nature of rhetoric and its\\r\\nrelation to virtue with the most prominent teacher of rhetoric among\\r\\nthe sophists. Finally, in the , the question of how virtue\\r\\nas such is acquired is raised by Meno, a disciple of Gorgias and an\\r\\nambitious seeker of power, wealth, and fame, who later met a gruesome\\r\\ndeath in Persia in the pursuit of those very values.  \\nMemorabilia  \\nEuthyphro  \\nLaches  \\nCharmides  \\nGreater Hippias  \\nProtagoras  \\nGorgias  \\nMeno  \\nSocrates’ interlocutors are usually, at first, quite confident\\r\\nabout their own competence in the discussion. And such confidence\\r\\nis not unreasonable. If virtue is a kind of ‘skill’ or a special\\r\\nproperty that enjoys general recognition, its possessor should know\\r\\nand be able to give an account of that skill or proficiency. As\\r\\nSocrates’ examinations demonstrate, however, such\\r\\nself-confidence is usually unfounded, and the ‘knowledge’\\r\\nprofessed by Socrates’ partners is revealed to be, at best, an\\r\\nimplicit familiarity. When they are confronted with their inability to\\r\\nexplain the nature of their cherished virtue or expertise, they end up\\r\\nadmitting their ignorance, but often with considerable chagrin or\\r\\nanger (on the ‘Socratic’ dialogues, see the entry in ’ by\\r\\nPaul Woodruff). Socrates’ purpose in conducting these sometimes\\r\\ncruel-looking games is not just to undermine the false confidence of\\r\\nhis interlocutors but also to pave the way towards general\\r\\ndefinitions and standards concerning the virtues. There were no widely\\r\\nacknowledged standards of definition in Socrates’ time, but by\\r\\nexposing the flaws in his partners’ abortive arguments in his\\r\\ninvestigations, Socrates contributed significantly to the development\\r\\nof such standards. The respective flaws vary greatly in kind and\\r\\ngravity: Socrates shows that enumerations of examples are not\\r\\nsufficient to capture the nature or essence of the virtue in question.\\r\\nDefinitions that consist in the replacement of the concept in question\\r\\nwith a synonym are open to the same objections as the original\\r\\ndefinition. Definitions may be hopelessly vague or miss the mark\\r\\nentirely, which is to say that they may be either too wide and include\\r\\nunwanted characteristics or subsets, or too narrow so that they\\r\\nexclude essential characteristics. Moreover, definitions may be\\r\\nincomplete because the object in question does not constitute a\\r\\nunitary phenomenon. If generally accepted ‘social\\r\\nexcellences’ are not simple conditions, they may be subject to\\r\\nconflicting convictions. Examples of all these problems are provided\\r\\nin Plato’s early dialogues, where Socrates exposes the exact\\r\\nnature of the underlying deficiencies with more or less diagnostic\\r\\ntransparency.  \\nSEP  \\nPlato  \\ns Shorter Ethical Works  \\nGiven that the focus in the early dialogues is almost entirely on the\\r\\nexposure of flaws and inconsistencies, one cannot help wondering\\r\\nwhether Plato himself knew the to his queries and\\r\\nhad some cards up his sleeve that he chose not to play for the time\\r\\nbeing. This would presuppose that Plato had not only a clear notion of\\r\\nthe nature of the different virtues but also a definitive conception\\r\\nof the good life as such. Since Plato was neither a moral nihilist nor\\r\\na sceptic, he cannot have regarded moral perplexity ( )\\r\\nas the ultimate end, nor regarded continued mutual examination, , as a way of life for everyone. Perplexity, as\\r\\nis argued in the , is just a wholesome intermediary stage\\r\\non the way to knowledge ( . 84a–b). But if Plato\\r\\nassumes that the convictions that survive Socratic questioning will\\r\\neventually coalesce into a coherent account of the good life, then he\\r\\nkeeps this expectation to himself. Nor would such optimism seem\\r\\nwarranted, given Socrates’ disavowal of knowledge. There is no\\r\\nguarantee that only false convictions are refuted in a Socratic\\r\\ncross-examination, while true ones are retained – for promising\\r\\nsuggestions are often as mercilessly discarded as their less promising\\r\\nbrethren. Perhaps Plato counted on his readers’ intelligence to\\r\\nstraighten out what is skewed in Socratic refutations, as well as to\\r\\ndetect unfair moves and to supplement what is missing. It is, in\\r\\nfact, often not difficult to make out problematic or fallacious moves\\r\\nin Socrates’ argument and to correct them, but such corrections\\r\\nmust remain incomplete without sufficient information about\\r\\nPlato’s overall conception of the good life and its moral\\r\\npresuppositions at that point in time. It is, therefore, a matter of\\r\\nconjecture whether Plato himself held any positive views while he\\r\\ncomposed one aporetic dialogue after the other. He may have regarded\\r\\nhis investigations as experimental stages or have seen each dialogue\\r\\nas an element in a network of approaches that he hoped to integrate\\r\\neventually.  \\nanswers  \\naporia  \\nSocratico more  \\nMeno  \\nMe  \\nIf there is a general lesson to be drawn from the many failed accounts\\r\\nof the virtues by Socrates’ different partners, beyond the\\r\\nparticular shortcomings of individual definitions and assertions, it\\r\\nis that isolated definitions of single virtues, summed up in one\\r\\nsentence, will not do. The evidence that Plato wanted his readers to\\r\\ndraw this very conclusion already in his early dialogues is somewhat\\r\\ncontradictory, however. He famously pleads for the unity of the\\r\\nvirtues in the and seems intent to reduce them\\r\\nall to knowledge. Scholars are, therefore, wont to speak of the\\r\\n‘intellectualistic’ character of the so-called\\r\\n‘Socratic ethics’ because it leaves no room for other\\r\\nmotivational forces, such as desires and emotions. Socrates’\\r\\nproof in the that reason cannot be overcome by the\\r\\npassions has, from Aristotle on, been treated as a denial of , of the phenomenon that was later somewhat\\r\\nmisleadingly dubbed as ‘weakness of the will’. This\\r\\nintellectualizing tendency does not tell us, however, what kind of\\r\\nmaster-science would fulfill all of the requirements for defining\\r\\nvirtues, nor what its content should be. Moreover, the emphasis on\\r\\nknowledge does not rule out an awareness on Plato’s part of the\\r\\nimportance of other factors, even in his early dialogues. Though Plato\\r\\noften compares the virtues with technical skills, such as those of a\\r\\ndoctor or a pilot, he may have realized that virtues also involve\\r\\nemotional attitudes, desires, and preferences but not yet have seen a\\r\\nclear way to coordinate or combine the rational and the affective\\r\\nelements that constitute the virtues. In the , for\\r\\ninstance, Socrates’ partners struggle when they try to define\\r\\ncourage, invoking two different elements. In his attempt to define\\r\\ncourage as ‘steadfastness in battle’, Laches, one of the\\r\\ntwo generals and ‘experts’ on courage, is faced with the\\r\\ndilemma that steadfastness seems not to be a satisfactory definition\\r\\nof courage either in itself or in combination with knowledge\\r\\n( . 192a–194c). His comrade Nicias, on the other hand,\\r\\nfails when he tries to identify courage exclusively as a certain type\\r\\nof knowledge (197e–200a). The investigation of moderation in the , likewise, points up that there are two disparate\\r\\nelements commonly associated with that virtue – namely, a\\r\\ncertain calmness of temper on the one hand ( .\\r\\n158e–160d) and self-knowledge on the other (166e–175a). It\\r\\nis clear that a complex account would be needed to combine these two\\r\\ndisparate features, for moral skills not only presuppose sufficient\\r\\n‘operative’ rationality but also require appropriate\\r\\nevaluative and emotional attitudes towards the ends to be attained and\\r\\ntowards the means to be employed. Such an insight is at least\\r\\nindicated in Socrates’ long and passionate argument in the against Polus and Callicles that the just life is\\r\\nbetter for the soul of its possessor than the unjust life, an argument\\r\\nthat he fortifies with a mythical depiction of the soul’s reward\\r\\nand punishment after death (523a–527e). But the nature of\\r\\njustice, and what is required for the proper care of one’s soul,\\r\\nis thereby illuminated only indirectly. For the most part,\\r\\nSocrates’ interrogations focus on the incompatibility of his\\r\\ninterlocutors’ selfish aims with their more selfless and noble\\r\\ntendencies. In his earlier dialogues, Plato may or may not already be\\r\\nenvisaging the kind of solution that he is going to present in the to the problem of the relationship between the\\r\\ndifferent virtues, with wisdom, the only purely intellectual virtue,\\r\\nas their basis. Courage, moderation, and justice presuppose a certain\\r\\nsteadfastness of character as well as a harmony of purpose between the\\r\\ndisparate parts of the soul, but their goodness depends entirely on\\r\\nthe intellectual part of the soul, just as the virtue of the citizens\\r\\nin the just state depends on the wisdom of the philosopher kings\\r\\n( . 428a–444e). The existence of ‘demotic’\\r\\nvirtues of character is thus acknowledged, but they are relegated to\\r\\nsecond place (500d; 522a–b).  \\nProtagoras  \\nProtagoras  \\nakrasia  \\nLaches  \\nLa  \\nCharmides  \\nChrm  \\nGorgias  \\nRepublic  \\nR  \\nThere are at least some indications that Plato already saw the need\\r\\nfor a holistic conception of the good life when he composed his\\r\\n‘Socratic’ dialogues. At the end of the ,\\r\\nhe lets Nicias founder in his attempt to define courage as the\\r\\n‘knowledge of what is to be feared and what should inspire\\r\\nconfidence’. Nicias is forced to admit that such knowledge\\r\\npresupposes the knowledge of good and bad ( . 199c–e). In a different but related way, Socrates\\r\\nalludes to a comprehensive knowledge at the end of the . In his final refutation of Critias’\\r\\ndefinition of moderation as ‘knowledge of knowledge’, he\\r\\nurges that this type of knowledge is insufficient for the happy life\\r\\nwithout the knowledge of good and bad ( . 174b–e).\\r\\nPointing out what is wrong or missing in particular arguments is a far\\r\\ncry from a philosophical conception of the ultimate good in human\\r\\nlife. But the fact that Plato insists on the shortcomings of a purely\\r\\n‘technical’ conception of virtue suggests that he was at\\r\\nleast facing up to these problems. The discussion of the ‘unity\\r\\nof the virtues’ in the – regardless of\\r\\nthe probably intentionally unsatisfactory structure of its proofs\\r\\n– confirms that Plato realized that a critique of the\\r\\ninconsistencies implied in conventional values is insufficient to\\r\\njustify such a unitary point of view. Nevertheless, the evidence that\\r\\nPlato already had a unified conception of the good life in mind when\\r\\nhe wrote his earlier dialogues remains, at most, indirect.  \\nLaches  \\ntout court  \\nLa  \\nCharmides  \\nChrm  \\nProtagoras  \\n2.2 The quest for definition  \\nIt may be helpful to begin with a consideration of the method of\\r\\nethical inquiry that Socrates is portrayed as using in the early\\r\\ndialogues. A reflection on the meaning of Socrates’ quest for\\r\\ndefinitions in the early dialogues suggests that Plato cannot have\\r\\nbeen blind to the sterility of a purely negative way of argument, or\\r\\nif he was blind at first, his blindness cannot have lasted long, for\\r\\nSocrates’ quest for definitions has important consequences.\\r\\nFirst and foremost, definitions presuppose that there is a definable\\r\\nobject; that is to say, it must have a stable nature. Nothing can be\\r\\ndefined that is of a variable nature. In addition, the object in\\r\\nquestion must be a unitary phenomenon, even if its unity may be\\r\\ncomplex. If definitions are to provide the basis of knowledge, they\\r\\nrequire some kind of essentialism. This presupposition is indeed made\\r\\nexplicit in the , where Plato employs, for the first\\r\\ntime, the terminology that will be characteristic of his full-fledged\\r\\ntheory of Forms. In response to Euthyphro’s enumeration of\\r\\nvarious examples of pious behavior, Socrates demands an account of ( . 5d: ; 6d: ; 6e: ) that is\\r\\ncommon to all cases of what is holy or pious. Despite this pregnant\\r\\nterminology, few scholars nowadays hold that the already presupposes transcendent Forms, in a realm of their own\\r\\n– models that are only incompletely represented by their\\r\\nrepresentatives under material conditions. The terms and had preserved their original meaning of\\r\\n‘look’ or ‘shape’ into the classical age, but\\r\\nthey were also often used in the more abstract sense of\\r\\n‘form’, ‘sort’, ‘type’, or\\r\\n‘kind’. No more than piety or holiness in the abstract\\r\\nsense seems to be presupposed in the discussion of the . There is, at any rate, no mention of any\\r\\nseparation of a sensible and an intelligible realm, let alone of an\\r\\nexistence of ‘the holy itself’, as a transcendent\\r\\nentity.  \\nEuthyphro  \\nthe one  \\nfeature  \\nEuthphr  \\nidea  \\neidos  \\nparadeigma  \\nEuthyphro  \\neidos  \\nidea  \\nEuthyphro  \\nThe passage in the where Socrates asks Euthyphro to\\r\\nidentify the feature that is common to all that is holy\\r\\nor pious makes intelligible, however, the reason why Plato felt\\r\\nencouraged to develop the conception of transcendent Forms. The\\r\\nrequisite unity and invariance of entities such as ‘the\\r\\nholy’, ‘the beautiful’, ‘the just’, or\\r\\n‘the equal’, necessarily prompts reflections on their\\r\\nontological status and on the appropriate means of access to them.\\r\\nGiven that they are the objects of definition and the models of their\\r\\nordinary representatives, there is every reason not only to treat them\\r\\nas real but also to assign to them a higher kind of unity and\\r\\nperfection. And once this step has been taken, it is only natural to\\r\\nmake certain epistemological adjustments, for access to paradigmatic\\r\\nentities is not to be expected through ordinary experience but\\r\\npresupposes some special kind of intellectual insight. It seems, then,\\r\\nthat once Plato had accepted invariant and unitary objects of thought\\r\\nas the subject of definition, he was predestined to follow the path\\r\\nthat led him to adopt a metaphysics and epistemology of transcendent\\r\\nForms. The very fact that mathematics was already an established\\r\\nscience with rigorous standards and unitary and invariant objects\\r\\nseems to have greatly enhanced Plato’s confidence in applying\\r\\nthe same standards in moral philosophy. It led him to search for\\r\\nmodels of morality beyond the limits of everyday experience. This, in\\r\\nturn, explains the development of his theory of recollection and the\\r\\npostulate of Forms as transcendent, immaterial objects as the basis of\\r\\nboth reality and thought that he refers to in the and\\r\\nthat he presents more fully in the .  \\nEuthyphro  \\none  \\nMeno  \\nPhaedo  \\nWe do not know when, precisely, Plato adopted this mode of thought,\\r\\nbut it stands to reason that his contact with the Pythagorean school\\r\\non his first voyage to Southern Italy and Sicily around 390 BC played\\r\\na major role in that development. Mathematics as a model-science has\\r\\nseveral advantages. It deals with unchangeable entities that have\\r\\nprecise definitions. It also makes plausible the claim that the\\r\\nessence of these entities cannot be comprehended in isolation but only\\r\\nin a network of interconnections that have to be worked out at the\\r\\nsame time as each particular entity is defined. Thus, to understand\\r\\nwhat it is to be a triangle, it is necessary – – to have a clear notion of the nature of points,\\r\\nlines, planes, and their interrelations. That Plato was aware of that\\r\\nfact is indicated in his introduction of the theory of recollection in\\r\\nthe , 81d: “As the whole of nature is akin, and the\\r\\nsoul has learned everything, nothing prevents a man, after recalling\\r\\none thing only – a process men call learning – discovering\\r\\neverything else for himself, if he is brave and does not tire of the\\r\\nsearch; for searching and learning, are, as a whole, recollection\\r\\n( ).” The somewhat mystifying claim of an\\r\\n‘overall kinship’ is then illuminated by the famous\\r\\n‘mathematical experiment’ ( . 82b–85c).\\r\\nThe slave manages, with some pushing and pulling by Socrates, and\\r\\nthanks to some illustrations drawn in the sand, to double the area of\\r\\na given square. In the course of this interrogation, the disciple\\r\\ngradually discovers the relations between the different lines,\\r\\ntriangles, and squares. That Plato regards these interconnections as\\r\\ncrucial features of knowledge is subsequently confirmed by the\\r\\ndistinction that Socrates draws between knowledge and true belief\\r\\n(97b–98b). As he argues, true beliefs are unreliable because\\r\\nthey behave like ‘the statues of Daedalus that easily run away\\r\\nas long as they are not tied down’. The requisite ‘tying\\r\\ndown’ happens (98a) “by giving an account of the reason\\r\\nwhy. And that, Meno my friend, is recollection, as we previously\\r\\nagreed. After they are tied down, in the first place, they become\\r\\nknowledge, and then they remain in place.” This explanation\\r\\nindicates that, according to Plato, knowledge does not consist in a\\r\\nmere mental ‘gazing’ at isolated models but rather in\\r\\nuncovering the invariant relations and interrelations that constitute\\r\\nthe objects in question.  \\ninter\\r\\nalia  \\nMeno  \\nanamnesis  \\nMe  \\nThe complexity underlying Plato’s theory of the Forms as it\\r\\nsurfaces in the is easily overlooked because its\\r\\ndiscussion initially suggests that recollection is no more than the\\r\\ngrasping of concepts. Thus, the concept of ‘exact equality in\\r\\nsize’ is prompted by the perception of more or less\\r\\nequal-seeming sticks and stones (74a–e). The same condition\\r\\napplies to the other examples of Forms, 65d–e: “Do we say\\r\\nthat there is such a thing as the Just itself or not? And the\\r\\nBeautiful, and the Good? […] I am speaking of all things such\\r\\nas Tallness, Health, Strength, and in a word, the reality of all other\\r\\nthings, that which each of them essentially is.” But Plato does\\r\\nnot employ his newly established metaphysical entities as the basis\\r\\nfor working out a definitive conception of the human soul and the\\r\\nappropriate way of life in the . Rather, he confines\\r\\nhimself to warnings against the contamination of the soul by the\\r\\nsenses and their pleasures, and quite generally against corruption by\\r\\nworldly values. He gives no advice concerning human conduct beyond\\r\\nthe recommendation of a general abstemiousness from worldly\\r\\ntemptations. This seems a rather austere picture of human life, and an\\r\\negocentric one, to boot, for nothing is said about relations between\\r\\nhuman beings beyond Socrates’ exhortations that his friends\\r\\nshould likewise take care of their souls as best they can. It is\\r\\nunclear whether this otherworldly and ascetic attitude is the sign of\\r\\na particularly pessimistic period in Plato’s life or whether it\\r\\nmerely reflects the circumstances of the discussion –\\r\\nSocrates’ impending death. But as long as this negative or\\r\\notherworldly attitude towards the physical side of human nature\\r\\nprevails, no interest is to be expected on the part of Plato in nature\\r\\nas a whole – let alone in the principles of the cosmic order\\r\\n(but cf. 5.1 below). But it is not only the apparent asceticism that\\r\\nstands in the way of a wider perspective. Socrates himself seems to\\r\\nhave been quite indifferent to the study of nature. While in the Socrates confesses his inability to deal with the\\r\\ncauses of natural processes, the contains an\\r\\nenergetic denial of any concern with natural philosophy on\\r\\nSocrates’ side. The accusations that depict him as “a\\r\\nstudent of all things in the sky and below the earth” are quite\\r\\nunfounded (18c); he has never conversed on such issues at all, and the\\r\\nattribution to him of the Anaxagorean tenet that the sun is a stone\\r\\nand the moon consists of earth is a sign of his accusers’\\r\\nrecklessness (26d–e). Similarly, in the ,\\r\\nSocrates explains his preference for the city and his avoidance of\\r\\nnature (230d): “Landscapes and trees have nothing to teach me\\r\\n– only the people in the city can do that.” That Plato is\\r\\nnot distorting the facts here is confirmed by the testimony of\\r\\nXenophon, who is equally emphatic about Socrates’ repudiation of\\r\\nthe study of heavenly phenomena and his concentration on human affairs\\r\\n( I 1.15–16). If Plato later takes a much\\r\\nmore positive attitude towards nature in general, this is a\\r\\nconsiderable change of focus. In the , he quite\\r\\ndeliberately confines his account of the nature of heaven and earth,\\r\\nwith its heavenly order and hellish geography, to the myth about the\\r\\nsoul’s afterlife (108d–114c). As he states in conclusion,\\r\\nthis mythical depiction is not to be taken literally but as an\\r\\nencouragement to heed its moral message and to take care of\\r\\none’s soul (114d–e). This is as constructive as Plato gets\\r\\nin his earlier treatment of the principles of ethics.  \\nPhaedo  \\nPhaedo  \\nPhaedo  \\nApology  \\nPhaedrus  \\nMemorabilia  \\nPhaedo  \\n3. The middle dialogues: Justice and other virtues  \\n3.1 Human nature and its deficiencies  \\nIf Plato went through a period of open-ended experimentation and\\r\\ntentative suggestions, this stage was definitely over by the time he\\r\\nwrote the , the central work of his middle years.\\r\\nBecause of the ’s importance, a more detailed\\r\\naccount will be provided here in order to explain the ethical\\r\\nprinciples set forth in that work, for these principles are closely\\r\\nintertwined with Plato’s political, psychological, and\\r\\nmetaphysical conceptions. That the work represents a major change in\\r\\nPlato’s thinking is indicated already by the dialogue’s\\r\\nsetting. The aporetic controversy about justice in the ’s first book is set off quite sharply against\\r\\nthe constructive discussion that ensues in its remaining nine books.\\r\\nLike the , the first book presents three interlocutors\\r\\nwho defend, with increasing vigor and contentiousness, their notion of\\r\\njustice against Socrates’ . Of these disputes,\\r\\nthe altercation with the sophist Thrasymachus has received the most\\r\\nattention because he defends the provocative thesis that natural\\r\\njustice is the right of the stronger and that conventional justice is,\\r\\nat best, high-minded foolishness. The counter-arguments employed by\\r\\nSocrates at the various turns of the discussion will not be presented\\r\\nhere. Though they reduce Thrasymachus to angry silence, they are not\\r\\nabove criticism. Socrates himself expresses dissatisfaction with the\\r\\nresult of this discussion . 354c: “As far as I am\\r\\nconcerned, the result is that I know nothing, for when I don’t\\r\\nknow what justice is, I’ll hardly know whether it is a kind of\\r\\nvirtue or not, or whether a person who has it is happy or\\r\\nunhappy.” But for once, the speakers’ confession of is not the end of the discussion. At the beginning of\\r\\nthe next book, two members of the audience, Plato’s brothers\\r\\nGlaucon and Adeimantus, challenge Socrates: Perhaps Thrasymachus has\\r\\ndefended his case badly, but if Socrates wants to convince his\\r\\naudience, he must do better than that. The brothers demand a positive\\r\\naccount both of what justice is and of what it does to the soul of its\\r\\npossessor.  \\nRepublic  \\nRepublic  \\nRepublic  \\nGorgias  \\nelenchos  \\nR  \\naporia  \\nThe change of character in the subsequent discussion is remarkable.\\r\\nNot only are the two brothers not subjected to , they\\r\\nget ample time to elaborate on their objections (357a–367e).\\r\\nThough they profess not to be convinced that injustice is better than\\r\\njustice, they argue that, in the present state of society, injustice\\r\\npays – with the gods as well as with humans – as long as\\r\\nthe semblance of respectability is preserved. To prove this claim, the\\r\\nbrothers play devil’s advocate by unfolding a scathing picture\\r\\nof their society’s attitude towards justice. As the story of the\\r\\nRing of Gyges and its gift of invisibility proves, everyone who does\\r\\nnot have a god-like character will eventually succumb to such a\\r\\nring’s temptations (359c–360d). Instead of the wolf of\\r\\nThrasymachus’ account, it is the wily fox who is the paragon of\\r\\ninjustice (365a-d). He will succeed at every level because he knows\\r\\nhow to play the power-game with cunning. The just man, by contrast,\\r\\npays no heed to the mere semblance of goodness but rather to its\\r\\nsubstance and, therefore, must suffer a Christ-like fate because he\\r\\ndoes not comply with the demands of favoritism and blandishment\\r\\n(361e). Even the gods, as the poets confirm, are on the side of the\\r\\nsuccessful scoundrel since they can be propitiated by honors and\\r\\nsacrifices. Given this state of affairs, a logic-chopping argument\\r\\nthat justice is better than injustice is quite insufficient\\r\\n(367b–e: ). Instead, Socrates must show what\\r\\neffect each of them has on the souls of their possessors. As this\\r\\ncritique indicates, Plato, at this point, clearly regards refutation as\\r\\nan insufficient way of making true converts. Whether he ever had such\\r\\nconfidence in the power of refutation must remain a moot point. But\\r\\nthe shows that the time had come for a positive\\r\\naccount of morality and of the good life. If is used\\r\\nin Plato’s later dialogues, it is never again used in the\\r\\nknock-down fashion of the early dialogues. But in his treatment of\\r\\njustice, Plato does not directly resort to the theory of Forms.\\r\\nInstead, he develops a political and psychological model as a solution\\r\\nto the problem of the nature of justice. That there is also a\\r\\nmetaphysical way to determine the nature of justice is indicated only\\r\\nbriefly and enigmatically when Plato speaks of a ‘longer\\r\\nway’ that would also have been possible for him to take (435d;\\r\\n504b)  \\nelenchos  \\nlogôi  \\nRepublic  \\nelenchos  \\nA brief sketch of Plato’s inquiry into the nature of justice\\r\\nmust suffice here to make intelligible his distinction of justice\\r\\nfrom the other kinds of virtue and of their role in the good life (for\\r\\na more penetrating analysis, see the entry ’ by Eric Brown). This question is addressed in\\r\\na quite circuitous way. Justice is first to be studied in the\\r\\n‘larger text’ of the state rather than in the\\r\\nhard-to-decipher ‘small text’ of the individual soul. A\\r\\nstudy of how a city comes to be will supposedly reveal the origin of\\r\\njustice and injustice (369a). Its founding principle is – at\\r\\nleast at first – no high-minded concern of humankind, but mutual\\r\\neconomic : “A city comes to be because none of us\\r\\nis self-sufficient ( ), but we all need many\\r\\nthings. … And because people need many things, and because one\\r\\nperson calls on a second out of one need ( ) and on a\\r\\nthird out of a different need, many people gather in a single place to\\r\\nlive together as partners and helpers.” The ‘need’\\r\\nis, at least at this point, purely economic. The minimal city is based\\r\\non the need for food, clothing, shelter, and for the requisite tools.\\r\\nIt is economic efficiency that dictates the adoption of the principle\\r\\nof the ‘division of functions’: It is best if everyone\\r\\nperforms the task s/he is naturally most fit for. This principle\\r\\ndetermines not only the structure of the minimal, self-subsistent\\r\\nstate of farmers and craftsmen but also the subsequent division of\\r\\nthe city’s inhabitants into three classes in the ‘fevered\\r\\nstate’ that caters to higher demands, for a more luxurious city\\r\\nneeds protection by a professional army as well as the leadership of a\\r\\nclass of philosopher-kings and -queens. Beyond the claim that the\\r\\ndivision of functions is more economical, Plato gives no justification\\r\\nfor this fateful decision that determines the social order in the\\r\\nstate, as well as the nature of the virtues. Human beings are not born\\r\\nalike but with different abilities that predestine them for different\\r\\ntasks in a well-ordered state. This leads to Plato’s principle:\\r\\n‘one person – one job’ ( . 370a–c;\\r\\n423d).  \\nPlato  \\ns\\r\\nEthics and Politics  \\nneed  \\nautarkês  \\nchreia  \\nR  \\nBecause the division of functions paves the way for the definition of\\r\\njustice as ‘doing your own thing and not meddling with that of\\r\\nothers’ in Book IV (432d–433b), it is necessary to briefly\\r\\nreview the kind of social order Plato has in mind, the psychological\\r\\nprinciples he assumes, and the political institutions by which that\\r\\norder is to be secured, for this explains not only the establishment\\r\\nof a three-class society and the explanation of the corresponding\\r\\nstructure of the soul but also Plato’s theory of education and\\r\\nthe metaphysical underpinnings. That economic needs are the basis of\\r\\nthe political structure does not, of course, mean that they are the\\r\\nonly human needs Plato recognizes. It indicates, however, that the\\r\\nemphasis here is on the unity and self-sufficiency of a\\r\\nwell-structured city, not on the well-being of the individual\\r\\n(423c–e; 425c). This focus should be kept in mind when assessing\\r\\nthe ‘totalitarianism’ and the rigorous cultural\\r\\nconservatism of the political philosophy of Plato’s middle\\r\\nyears.  \\nThe need for a professionally trained army leads to the discussion of\\r\\neducation and moral psychology because the preservation of internal\\r\\npeace and external security presupposes the combination of two quite\\r\\ndifferent character-traits among the ‘guardians’\\r\\n(‘the philosophical watchdogs’, 375d–376c):\\r\\nfriendliness towards their fellow-citizens and fierceness towards\\r\\ntheir enemies. The injunctions concerning the citizens’\\r\\neducation are very detailed because it must combine the right kind of\\r\\n‘muses’ (poetry, music, and other fine arts) with the\\r\\nappropriate physical training in order to develop the right\\r\\ntemperament and attitude in the soldiers (376d–403d). The\\r\\norganisation and supervision of education is the special task of the\\r\\nthird class, that of the rulers of the city (412b–417b). They\\r\\nare to be selected through tests of both intelligence and character\\r\\nfrom among the soldiers – individuals who are unshakable in\\r\\ntheir conviction that their own well-being is intimately tied to that\\r\\nof the city. To ensure that members of the military and the ruling\\r\\nclass retain the proper attitude towards their civic duties, members\\r\\nof both classes must lead a communal life without private homes,\\r\\nfamilies, or property. When Socrates’ interlocutors object that\\r\\nsuch a life is not apt to make these citizens happy, the topic of\\r\\nhappiness is addressed for the first time, but Socrates quickly\\r\\nbrushes it aside at this point on the ground that the political order\\r\\nis designed to make the entire city happy, rather than any one\\r\\nparticular group (419a-e).  \\n3.2 Virtues of state and soul  \\nThe division of functions that leads to the separation of the three\\r\\nclasses for the purpose of achieving the social conditions for justice\\r\\nconcludes the discussion of the social order (427d–434c). The\\r\\npeculiar manner in which Socrates further develops his explanation of\\r\\nthe nature of justice can best be understood with reference to the\\r\\nupshot of this discussion. The catalogue of what in later tradition\\r\\nhas been dubbed ‘the four cardinal Platonic virtues’\\r\\n– wisdom, courage, moderation, and justice – is first\\r\\npresented without comment. Piety, as the text indicates, is\\r\\nnοt treated as a virtue; religious practices should, rather,\\r\\nbe left to tradition and to the oracle of Apollo at Delphi on the\\r\\nground that: “We have no knowledge of these things”\\r\\n(427b–c). The definition of justice is to be discovered\\r\\nby a process of elimination. If there are four virtues in the city,\\r\\nthen justice must be the one that is left over after the other three\\r\\nhave been identified. There is no proof offered that there are\\r\\nexactly four virtues in a state, nor that they are items that can be\\r\\nlifted up, singly, for inspection, like objects from a basket.\\r\\nInstead, Socrates points out the role they play in the maintenance of\\r\\nthe social order. About wisdom ( ) – the only purely\\r\\nintellectual virtue and the exclusive possession of the rulers – little\\r\\nmore is said at this point than that it is ‘good council’\\r\\n( ) in decisions about the internal and external\\r\\naffairs of the city. Courage ( ) is the soldiers’\\r\\nspecific virtue. Socrates takes some trouble explaining its nature\\r\\nbecause it is a mixture of belief ( ) and steadfastness of\\r\\ncharacter ( ). It is compared to colorfast\\r\\nwool: Through thick and thin, the guardians must be dyed-in-the-wool\\r\\nadherents to the laws’ decrees about what is to be feared and\\r\\nwhat is to be faced with confidence. Moderation\\r\\n( ) is not an intellectual excellence\\r\\neither, but rather a combination of belief with a certain disposition\\r\\nto support order. It is a conviction ( , 431e) shared by\\r\\nall classes about who should rule – a conviction based on a\\r\\nstate of ‘order’ ( ),\\r\\n‘consonance’ ( ), and\\r\\n‘harmony’ ( ). The state’s third\\r\\nclass, then, has no specific virtue of its own. Finally, the\\r\\nidentification of justice is due to the sudden insight on\\r\\nSocrates’ part that justice is the principle that has been at\\r\\nwork all along in the founding of the model state – namely, that\\r\\neveryone is to “do their own thing and not meddle with that of\\r\\nanother” (433a).  \\nsophia  \\neuboulia  \\nandreia  \\ndoxa  \\nsôtêria  \\nsôphrosunê  \\ndoxa  \\nkosmos  \\nsumphônia  \\nharmonia  \\nThe promise to establish the isomorphic structure of the city and soul\\r\\nhas not been forgotten. After the definition and assignment of the\\r\\nfour virtues to the three classes of the city, the investigation turns\\r\\nto the role and function of the soul’s virtues. The soul is held\\r\\nto consist of three parts corresponding to the three classes in the\\r\\ncity. The lengthy argument for the tri-partition of the soul into a\\r\\nrational ( ), a spirited ( ), and\\r\\nan appetitive ( ) part (434d–441c)\\r\\ncan here be neither reproduced nor subjected to a critical evaluation.\\r\\nThat Plato lets Socrates express reservations concerning the adequacy\\r\\nof his own procedure, despite his unusually circumspect way of\\r\\njustifying the division of the soul’s faculties, indicates that\\r\\nhe regards it as an important innovation. Indeed, there is no\\r\\nindication of separate parts of the soul in any of the earlier\\r\\ndialogues; irrational desires have been attributed there to the\\r\\ninfluence of the body. In the , by contrast, the soul\\r\\nitself becomes the source of the appetites and desires. The difference\\r\\nbetween the rational and the appetitive part is easily justified\\r\\nbecause the opposition between the decrees of reason and the various\\r\\nkinds of unreasonable desires is familiar to everyone. The existence\\r\\nof a third, a ‘spirited’ or courageous part –\\r\\ndifferent from both reason and appetite – is harder to prove.\\r\\nBut the phenomenon of moral indignation is treated as evidence for a\\r\\npsychic force that is reducible neither to reason nor to any of the\\r\\nappetites; it is rather an ally of reason in a well-ordered soul, a\\r\\nforce opposed to the unruly appetites. This concludes the proof that\\r\\nthere are three parts in the soul, corresponding to the three classes\\r\\nin the city – namely, the rational part representing the wisdom\\r\\nof the rulers, the spirited part, manifest in the courage of the\\r\\nsoldiers, and the appetitive part that motivates the rest of the\\r\\npopulation in its quest for material gain.  \\nlogistikon  \\nthumoeides  \\nepithumêtikon  \\nRepublic  \\nThe discussion of the division of the soul sets the stage for the\\r\\nfinal determination of the contrast between justice and injustice\\r\\n(441c-445e): There will be justice in the city if the members of all\\r\\nthree classes mind their own business; similarly, in the individual\\r\\nsoul, there will be justice if each part of the soul fulfills its\\r\\nown function properly. This presupposes that the soul’s two\\r\\nupper parts have been given the right kind of training and education\\r\\nin order to control the appetitive part. The three other virtues are\\r\\nthen assigned to the respective parts of the soul. Courage is the\\r\\nexcellence of the spirited part, wisdom belongs to the rational part,\\r\\nand moderation is the consent of all three parts about who should rule\\r\\nand who should obey. Justice turns out to be the overall unifying\\r\\nquality of the soul, for the just person not only refrains from\\r\\nmeddling with what is not his externally but also harmonizes the\\r\\nthree parts of the soul internally. While justice is order and\\r\\nharmony, injustice is its opposite: It is a rebellion of one part of\\r\\nthe city or soul against the others, and it results in the\\r\\ninappropriate rule of their inferior parts. Justice and injustice in\\r\\nthe soul are, then, analogous to health and illness in the body. This\\r\\ncomparison suffices to bring the investigation to its desired result:\\r\\nIf justice is health and harmony of the soul, then injustice must be\\r\\ndisease and disorder. Hence, it is clear that justice is a good state\\r\\nof the soul that makes its possessor happy, and injustice is its\\r\\nopposite. As no one in his right mind would prefer to live with a\\r\\nruined body, similarly no one would prefer to live with a diseased soul. In\\r\\nprinciple, the discussion of justice has, therefore, reached its\\r\\npromised goal already at the end of Book IV. Socrates has met\\r\\nGlaucon’s and Adeimantus’ challenge to prove that justice\\r\\nis a good, in and by itself, for the soul of its possessor, and\\r\\nthat it is preferable to injustice.  \\nThat the ’s discussion does not end here but\\r\\noccupies six more books is due most of all to several loose ends that\\r\\nneed to be tied up. Apart from the fact that reason and order are to\\r\\nreign supreme, little has been said about the citizens’ way of\\r\\nlife. This gap will be filled, at least in part, by the description of\\r\\nthe communal life of the upper classes without private property and\\r\\nfamily in Book V. More importantly, nothing has been said about the\\r\\nrulers and their particular kind of knowledge. This is a crucial point\\r\\nbecause, as the definitions of the three ‘inferior’\\r\\nvirtues show, their quality is contingent on the rulers’ wisdom.\\r\\nSocrates addresses this problem with the provocative thesis\\r\\n(473c–d): “Until philosophers rule as kings or those who\\r\\nare now called kings and leaders genuinely and adequately philosophize\\r\\n... cities will have no rest from evils, nor will the human\\r\\nrace.” This thesis starts the discussion of the\\r\\nphilosophers’ knowledge and of their upbringing and education,\\r\\nwhich will continue through Books VI and VII. Because they also\\r\\nintroduce the special objects of the philosophers’ knowledge,\\r\\nthese books provide the metaphysical underpinning of the entire\\r\\nconception of the good soul and the good state, for the ‘Form of\\r\\nthe Good’ turns out to be the ultimate source of all being and\\r\\nknowledge. A short summary of the upshot of the educational program\\r\\nmust suffice here. The future philosophers, both women and men, are\\r\\nselected from the group of guardians whose general cultural training\\r\\nthey share. If they combine moral firmness with quickness of mind,\\r\\nthey are subject to a rigorous curriculum of higher learning that will\\r\\nprepare them for the ascent from the world of the senses to the world\\r\\nof intelligence and truth, an ascent whose stages are summed up in the\\r\\nsimiles of the Sun, the Line, and the Cave (508a–518b). To\\r\\nachieve this ascent, the students have to undergo, first, a\\r\\npreparatory schooling of ten years’ duration in the\\r\\n‘liberal arts’: arithmetic, geometry, astronomy, and\\r\\ntheoretical harmonics (518c–531c). Afterwards, they are admitted\\r\\nto the training in the master-science of ‘dialectic’, a\\r\\nscience that supposedly enables its possessor to deal in a systematic\\r\\nway with the objects of real knowledge – the Forms in general\\r\\n– and with the Form of the Good in particular – the\\r\\nprinciple of the goodness of all else (531c–535a). This study is\\r\\nto last for another five years. Successful candidates are then sent\\r\\nback into the Cave as administrators of ordinary political life for 15\\r\\nyears. At the age of fifty, the rulers are granted leave to pursue\\r\\nphilosophy, but even that pursuit is interrupted by periods of service\\r\\nas overseers over the order of the state. This completes, in a\\r\\nnutshell, the description of the philosopher-kings’ and\\r\\n-queens’ education and activities (539d–541b).  \\nRepublic  \\nPlato’s design of an autocratic rule by an aristocracy of the\\r\\nmind has received a lot of flak. But our assessment of his politics\\r\\nmust here be limited to an assessment of the kind of happiness it supposedly\\r\\nprovides. Regardless of whether or not we find plausible Plato’s\\r\\nassumption of an overall principle of the good as the basis of the\\r\\npolitical order, his model state has, at least in theory, the\\r\\nadvantage that it guarantees both internal and external peace. That is\\r\\nno mean feat in a society where interstate and civil wars were a\\r\\nconstant threat and often enough ended in the destruction of the\\r\\nentire city. In addition, the division of functions guarantees a high\\r\\ndegree of efficiency if every citizen does what he/she is naturally\\r\\nsuited to do. But what about the citizens’ needs beyond those\\r\\nfor security and material goods? Are they to find their life’s\\r\\nfulfillment only in the pursuit of their jobs? Plato seems to think\\r\\nso when he characterizes each class by its specific kind of desire\\r\\nand its respective good (581c): The philosophers are lovers of wisdom\\r\\n( ), the soldiers lovers of honor\\r\\n( ), and the workers are lovers of material goods\\r\\n( ). That human beings find, or at least\\r\\ntry to find, satisfaction in the kinds of goods they cherish is a\\r\\npoint that is further pursued in the depiction of the decay of the\\r\\ncity and its ruling citizens, from the best (the aristocracy of\\r\\nthe mind) down to the worst (the tyranny of lust) in\\r\\nBooks VIII and IX. A discussion of the tenability of this explanation\\r\\nof political and psychological decadence will not be attempted here.\\r\\nIt is supposed to show that all inferior forms of government of city\\r\\nand soul are doomed to fail because of the inherent tensions between\\r\\nthe goods that the different citizens aim for.  \\nphilosophoi  \\nphilotimoi  \\nphilochrêmatoi  \\nSome brief comments on Plato’s conception of happiness are in\\r\\norder at this point. He clearly goes on the assumption that human\\r\\nbeings are happy insofar as they achieve the goals they cherish.\\r\\nThough this notion seems to come close to the ‘preference\\r\\nsatisfaction’ for all citizens that is nowadays regarded as the\\r\\nprimary aim of every liberal state, Plato’s restriction of each\\r\\nclass to type of good must seem objectionable, most\\r\\nobviously in the case of the citizens of the third class who\\r\\nsupposedly covet nothing but material goods. This\\r\\n‘reductive’ view of their human nature militates not only\\r\\nagainst present-day intuitions – it should also militate against\\r\\nPlato’s own moral psychology, in that all human souls consist of\\r\\nthree parts – a rational, a spirited, and an appetitive part\\r\\n– whose health and harmony constitute the soul’s and the\\r\\nstate’s happiness. Why, then, reduce the third class to\\r\\nanimal-like creatures with low appetites, as suggested by the\\r\\ncomparison of the people to a strong beast that must be placated\\r\\n(493a–c)? This comparison is echoed later in the comparison of\\r\\nthe soul to a multiform beast, where reason just barely controls the\\r\\nhydra-like heads of the appetites and manages to do so only thanks to\\r\\nthe aid of a lion-like spirit (588c–590d). Is Plato thereby\\r\\ngiving vent to anti-democratic sentiments, showing contempt for the\\r\\nrabble, as has often been claimed? He can at least be cleared of the\\r\\nsuspicion that the workers are mere serfs of the upper classes\\r\\nbecause he explicitly grants them the free enjoyment of all the\\r\\ncustomary goods that he denies to the upper classes (419a):\\r\\n“Others own land, build fine big houses, acquire furnishings to\\r\\ngo along with them, make their own private sacrifices to the gods,\\r\\nentertain guests, and also, of course, possess what you were talking\\r\\nabout just now, gold and silver and all the things that are thought to\\r\\nbelong to people who are blessedly happy.”\\r\\n‘Appetite’ is clearly not confined to food, drink, and\\r\\nsex. But apart from the granting of material largesse, the members of\\r\\nthe third class are quite neglected in Plato’s ideal city.\\r\\nApparently, no education is provided for them, for there is no\\r\\nsuggestion that they participate in the guardians’ musical and\\r\\nathletic training, and there is no mention that obedience to the\\r\\nrulers’ commands is not the only source of happiness for the\\r\\nthird class. Plato seems to sidestep his own insight that all human\\r\\nbeings have an immortal soul and have to take care of it as best they\\r\\ncan, as he not only demands in the but is going to\\r\\nconfirm in a fanciful way in the Myth of Er at the end of Book X.  \\none  \\nPhaedo  \\nRepublic  \\nThe lifestyle designated for the upper classes also seems open to\\r\\nobjections. The soldiers’ musical and physical training is\\r\\nstrictly regimented; they must take satisfaction in obedience to\\r\\nthe laws for the sake of preserving the city’s inner and outer\\r\\npeace, and in the deeds of valor in war. Theirs is an austere\\r\\ncamp-life; not all of them will be selected for higher education. But\\r\\neven the philosophers’ lives leave a lot to be desired, and not\\r\\nonly because they have to starve their common human appetites and\\r\\ndevote many years to administrative duties back in the\\r\\n‘Cave’. Their intellectual pursuits are also not\\r\\naltogether enviable, as a closer inspection would show. Not only do\\r\\nthe philosophers have two jobs – in violation of the rule\\r\\n‘one person – one function’ – in that they are\\r\\nresponsible for both administrative work and philosophical thought.\\r\\nThey are also not to enjoy open-ended research but are, rather, subject\\r\\nto a mental training that is explicitly designed to turn their minds\\r\\naway from the enjoyment of all worldly beauty in order to focus\\r\\nexclusively on the contemplation of the Forms. This is indicated by\\r\\nthe injunctions concerning the study of astronomy and harmonics\\r\\n(529a–531d): The students are not to crane their necks to watch\\r\\nthe beauty of the “embroidery in the heavens” but rather\\r\\nto concern themselves with the ideal motions of ideal moving bodies\\r\\nin a purely geometrical fashion, and they are not to listen to audible\\r\\nsounds, but to attend to the mathematics of harmonics. The universe is\\r\\nnot treated as an admirable cosmos – with the explicit purpose of\\r\\nproviding moral and intellectual support to the citizens – in the way\\r\\nPlato is going to explain in the , the , and in the . Given these limitations of\\r\\nthe philosophers’ mental exercises in the , the\\r\\nclaim that their lives are 729 times more pleasant than the\\r\\ntyrants’ (IX 587e) seems like a gross exaggeration, even if they\\r\\nenjoy the pleasures of being filled with pure and unadulterated truths\\r\\nwhile everyone else enjoys only semblances of the really real\\r\\n(581e–588a).  \\nPhilebus  \\nTimaeus  \\nLaws  \\nRepublic  \\nFor all the advances that the represents in certain\\r\\nrespects, Plato’s ideal city must seem to us far from ideal. The\\r\\nsystem resembles a well-oiled machine where everyone has their\\r\\neconomic niche and function, but its machine-like character must seem\\r\\nrepellent to us, given that no deviations are permitted from the\\r\\nprescribed pattern. If innovations are forbidden, no room is left for\\r\\ncreativity and personal development. Plato seems to presuppose that\\r\\nthe fulfillment of a person’s function is sufficient to secure\\r\\nher happiness, or at least that is suggested by the\\r\\n‘functional’ argument that defeats Thrasymachus\\r\\n(352d–354a). It states that every object, animal, and person has\\r\\na specific function or work ( ). If it performs its\\r\\nfunction well, it does well: For a living thing, ‘doing\\r\\nwell’ means ‘living well’ and living well is\\r\\ntantamount to ‘living happily’. Though Socrates’\\r\\nrefutation of Thrasymachus is found wanting as a proof of\\r\\njustice’s superiority, the -argument is nowhere\\r\\nrevoked. On the contrary, it is affirmed by the principle of\\r\\n‘one person – one job’ that is the very basis of\\r\\nPlato’s ideal city. But the confinement of everyone’s\\r\\nactivities to just kind of work seems rather a narrow one\\r\\nin the case of the citizens of the third class, given that they are\\r\\nnot permitted to engage in politics, even if it may be economically\\r\\nmost efficient. These features suffice to make the ideal life in\\r\\nPlato’s city unattractive to us, not to speak of certain other\\r\\nfeatures that have not been explored here, such as the communal life\\r\\nenvisaged for the upper classes and the assignment of sexual\\r\\npartnerships by a lottery that is rigged for the purposes of eugenics.\\r\\nBut the feature that must strike us as strangest about Plato’s\\r\\ndepiction of his citizens’ lives is that he does not acknowledge\\r\\nthe factor that could throw a more favorable light on the\\r\\nlife of the third class, the life of tailors, carpenters, doctors,\\r\\narchitects, sailors, i.e., that they will take pride and joy in their\\r\\nown work and in what they produce, given that they each in their own\\r\\nway make valuable contributions to the community’s well-being,\\r\\nwithout which the city could not function. Plato does not seem to\\r\\nacknowledge this when he addresses them, rather ungraciously, as\\r\\n‘money-lovers’, indicating that he regards material gain\\r\\nas the only motivating factor in their lives.  \\nRepublic  \\nergon  \\nergon  \\none  \\none  \\nHave these deficiencies escaped Plato’s notice? Justified as\\r\\nthis critique must seem, it should be pointed out that Plato is\\r\\nclearly not concerned with the conditions that would make his city\\r\\nattractive to all citizens. His aim is rather more limited: He wants\\r\\nto present a and work out its essential features.\\r\\nThe same explanation applies to his depiction of the city’s and\\r\\nits citizens’ decay in Books VIII and IX. Contrary to certain\\r\\ncritics’ assumptions, Plato is not there trying to predict and\\r\\nexplain the course of history. Rather, he wants to explain the\\r\\ngeneration and decay typical of each political system and the\\r\\npsychopathology of its leaders. Plato finds the basis of both in the\\r\\nspecific values – be they honor, money, freedom, or lust –\\r\\nthat are embedded in the constitutions of the different types of\\r\\nstate. It is unlikely that Plato presupposes that there are, in reality,\\r\\npure representatives of these types, though some historical states may\\r\\nhave been better representatives of those types than others. But the\\r\\nquestion remains whether he had a notion of the fact that his\\r\\nblack-and-white picture of civic life in the model-state disregards\\r\\nthe claim of individuals to have their own aims and ends and not to\\r\\nbe treated like automata, with no thoughts and wishes of their own.\\r\\nThough the contains some suggestions that would\\r\\nmitigate this bleak picture, for the sake of balancing this picture, it\\r\\nis more fruitful to look at other works of Plato’s middle period\\r\\nthat concentrate on and prioritize the conditions of the soul rather than focus on the demands of the\\r\\ncommunity. These works are the and the , for though each dialogue should be studied as a\\r\\nunity of its own, it is also necessary to treat the different\\r\\ndialogues as part of a wider picture.  \\nmodel  \\nRepublic  \\nindividual  \\nSymposium  \\nPhaedrus  \\n3.3 The desire for self-perfection  \\nThe and the are two dialogues\\r\\nthat focus on the individual soul and pay no attention to communal\\r\\nlife at all. Instead, they concentrate on self-preservation,\\r\\nself-improvement, and self-completion. The is often\\r\\ntreated as a dialogue that predates the , most of all\\r\\nbecause it mentions neither the immortality nor the tripartition of\\r\\nthe soul. But its dramatic staging – the praise of Eros by a\\r\\ncompany of symposiasts – is not germane to the otherworldly and\\r\\nascetic tendencies of the and the . In\\r\\naddition, Plato has good reasons for leaving aside a discussion of the\\r\\nsoul’s separability from the body in the (a\\r\\nfeature it shares with the much later ). He aims to\\r\\nshow in the that love is an incentive, not only for all humans but\\r\\nfor all other living beings as well. Contrary to all previous\\r\\nspeakers, Socrates denies that Eros is a god because the gods are in\\r\\na state of perfection. Love, by contrast, is a desire by needy\\r\\ncreatures ( ) for the beautiful and the good\\r\\n(199c–201c). Socrates thereby corrects the previous\\r\\nspeakers’ confusion of love itself with the beloved object. This\\r\\nimportant insight is presented not as Socrates’ own but as the\\r\\nupshot of a ‘lecture on the nature of love by the wise priestess\\r\\nDiotima’ (201d–212b): Eros is a powerful demon, a being\\r\\nbetween ( ) what is mortal and what is immortal, an ever\\r\\nneedy hunter of the beautiful. Human beings share that demonic\\r\\ncondition, for they are neither good nor bad but desire the good and\\r\\nthe beautiful, the possession of which would constitute happiness for\\r\\nthem. Because all people want happiness, they pursue the good as well\\r\\nas they can (205a–206b). In each case, they desire the particular\\r\\nkinds of objects that they hope will fulfill their needs. Such\\r\\nfulfillment is not a passive possession; it is, rather, the\\r\\nappropriation of the objects of love that are deemed to be essential\\r\\nin the struggle for self-preservation, self-completion, and\\r\\nself-fulfillment (207d): “For among animals the principle is the\\r\\nsame as with us, and mortal nature seeks so far as possible to live\\r\\nforever and be immortal. And this is possible in one way only: by\\r\\nreproduction, because it leaves behind a new young one in place of the\\r\\nold.” There is, then, a constant need for self-restoration and\\r\\nself-improvement by procreation in the quest for an ‘earthly\\r\\nimmortality’ manifest in all living things (206e .). This need is explained by Diotima with an impressive\\r\\ndepiction of the constant flux that all organisms undergo, which, in the\\r\\ncase of human beings, not only affects their physical constitution but\\r\\ntheir moral and intellectual condition as well. Without constant\\r\\nreplenishment, none of them even stays the same over time\\r\\n(207c-208b).  \\nSymposium  \\nPhaedrus  \\nSymposium  \\nRepublic  \\nGorgias  \\nPhaedo  \\nSymposium  \\nPhilebus  \\nSymposium  \\nendeeis  \\nmetaxu  \\net\\r\\npass  \\nIn the case of human beings, these needs express themselves in\\r\\ndifferent ways. The search for ‘self-eternalization’ may\\r\\nresult in, or even be fulfilled by, the production of biological\\r\\nchildren or of so-called ‘children of the mind’ (e.g.,\\r\\nworks of art), or even by the creation of order in the city that is\\r\\nthen guided by the virtues of justice and moderation (209a–e).\\r\\nDiotima’s lecture is finally crowned by a depiction of the\\r\\nfamous – the explanation of the refinement\\r\\nand sublimation that a person experiences when recognizing higher and\\r\\nhigher kinds of beauty (210a–212a). Starting with the love of\\r\\none beautiful body, the individual gradually learns to appreciate not\\r\\nonly all physical beauty but also the beauty of the mind, and in the\\r\\nend, she gets a glimpse of the supreme kind of beauty; namely, the\\r\\nvision of the Form of the Beautiful itself – a beauty that is\\r\\nneither relative, nor changeable, nor a matter of degree.  \\nscala amoris  \\nBecause beauty of the higher kind is tied to virtue and is attained\\r\\nby the comprehension of what is common in laws and public\\r\\ninstitutions, it is clear that Plato does not have purely aesthetic\\r\\nvalues in mind but the principles of good order that are ultimately\\r\\ntied to the Form of the Beautiful/Good. The difference between the ’s and the ’s accounts\\r\\nlies in the fact that the treats physical beauty\\r\\nas an incentive to the higher and better, an incentive that, in\\r\\nprinciple, affects every human being. There is no talk of a painful\\r\\nliberation from the bonds of the senses or of a turn-around of the\\r\\nentire soul that is reserved only for the better educated. Brief as\\r\\nthe ’s explanation of happiness is, it shows\\r\\nthree things: First, all human beings aim for their own\\r\\nself-preservation and -perfection. Second, this drive finds its\\r\\nexpression in the products of their work, in creativity. Third, their\\r\\nrespective activities are instigated by each person’s own\\r\\nparticular desire for the beautiful. There is no indication that\\r\\nindividuals must act as part of a community. Though the communitarian\\r\\naspect of the good and beautiful comes to the fore in the high praise\\r\\nof the products of the legendary legislators (209e–210a), the\\r\\nultimate assent to the Beautiful itself is up to the individual. That\\r\\nmessage of the is not unique in Plato’s\\r\\nworks. The shares its basic assumption concerning the\\r\\nintermediary state of human nature between good and bad, and it\\r\\nregards ( ) as the basis of friendship.\\r\\nDue to the aporetic character of that dialogue, its lesson remains\\r\\nsomewhat obscure, but it is obvious enough that it shares the general anthropological\\r\\npresuppositions.  \\nRepublic  \\nSymposium  \\nscala amoris  \\nSymposium  \\nSymposium  \\nLysis  \\nneed  \\nendeia  \\nSymposium’s  \\nThe idea that is the incentive to sublimation and\\r\\nself-completion is further pursued in the . Although\\r\\nthe close relationship between the two dialogues is generally\\r\\nacknowledged, the is commonly regarded as a much\\r\\nlater work. Not only does it accept the psychological doctrine of a tri-partite soul, it also advocates the\\r\\nimmortality of the soul – doctrines that are conspicuously\\r\\nabsent in the . But this difference seems due to a\\r\\ndifference in rather than to a change of mind.\\r\\nThe discussion in the is deliberately confined to\\r\\nthe conditions of self-immortalization this life, while\\r\\nthe takes the discussion the\\r\\nconfines of this life. If it shares the doctrine of a division of the soul into three parts, it does so for\\r\\nreasons of its own: The three parts of the soul in the are not supposed to justify the separation of people\\r\\ninto three classes. They explain, rather, the different routes taken\\r\\nby individuals in their search for beauty and their levels of success.\\r\\nIf the goes beyond the , it does\\r\\nso in order to show how the enchantment by beauty can be combined with\\r\\nan element of Plato’s philosophy that seems quite alien to the\\r\\nnotions of self-improvement and sublimation through the love of\\r\\nbeauty. That element is abruptly identified as , the\\r\\nsystematic method of collection and division that is characteristic of\\r\\nPlato’s later work. At first sight, it might seem that the\\r\\ndialogue’s topic, Eros, is hardly the right tie to keep together\\r\\nthe dialogue’s two disparate parts – i.e., the highly\\r\\npoetical depiction of the enchantment by beauty and the ensuing\\r\\nheavenly voyage to a hyperouraneous place, and Plato’s\\r\\nsubsequent, quite pedestrian, methodological explanations of the\\r\\npresuppositions of rhetoric (249b–c). But although the coherence\\r\\nof the cannot be argued for in full here, the notion\\r\\nthat the is disjointed does not do justice to the\\r\\ndialogue’s careful composition and overall aim.  \\neros  \\nPhaedrus  \\nPhaedrus  \\nRepublic’s  \\nSymposium  \\nperspective  \\nSymposium  \\nin  \\nPhaedrus  \\nbeyond  \\nRepublic’s  \\nPhaedrus  \\nPhaedrus  \\nSymposium  \\ndialectic  \\nPhaedrus  \\nPhaedrus  \\nRhetoric, its purpose and value, is, in fact, the dialogue’s topic\\r\\nright from the start. The misuse of rhetoric is exemplified by the\\r\\nspeech attributed to the orator Lysias, a somewhat contrived plea to\\r\\nfavor a non-lover rather than a lover. Socrates’ retort points\\r\\nup Lysias’ presuppositions: that love is a kind of sickness, an\\r\\nirrational craving for the pleasures of the body; that a lover tries\\r\\nto dominate and enslave the beloved physically, materially and\\r\\nmentally; and, most importantly, that the lover tries to deprive the\\r\\nbeloved of philosophy. Once restored to his senses, the lover will shun\\r\\nhis former beloved and break all his promises. This one-sided view of\\r\\nEros is corrected in Socrates’ second speech: Eros, properly\\r\\nunderstood, is not a diseased state of mind but a kind of\\r\\n‘divine madness’ ( ). To explain the\\r\\nnature of this madness, Socrates employs the comparison of the\\r\\ntripartite soul to a charioteer with a pair of winged horses, an\\r\\nobedient white one and an unruly black one. The crucial difference\\r\\nbetween the ’ tripartition and that in the lies in this: Instead of a long and arduous\\r\\nliberation through education, the envisages a\\r\\nliberation through the uplifting force of love, a love that is –\\r\\njust as it is in the – instigated by physical\\r\\nbeauty. That is what first makes the soul grow wings and soar in the\\r\\npursuit of a corresponding deity, to the point where it will attain\\r\\ngodlike insights. The best-conditioned souls – those where the\\r\\ncharioteer has full control over his horses – get a glimpse of\\r\\ntrue being, including the nature of the virtues and of the good\\r\\n(247c–e). Depending on the quality of each soul, the quality of\\r\\nthe beauty pursued will also determine the cycle of reincarnations\\r\\nthat is in store for each soul after death (248c–249c).  \\ntheia mania  \\nPhaedrus  \\nRepublic  \\nPhaedrus  \\nSymposium  \\n3.4 The quest for method  \\nWhat is remarkable in the ’ depiction of the\\r\\nuplifting effect of beauty is not only its exuberant tone and imagery,\\r\\nwhich goes far beyond the unadorned , but also its intricate interweaving of mythical\\r\\nand philosophical elements. For, in the midst of his fanciful depiction\\r\\nof the different fates that are in store for different kinds of souls,\\r\\nPlato specifies, in quite technical terms, that the capacity “to\\r\\nunderstand speech in terms of general Forms, proceeding to bring many\\r\\nperceptions together into a reasoned unity” (249b–c: ’ ), is the condition for the\\r\\nreincarnation of individual souls as human beings. It is this capacity\\r\\nfor abstract thought that he then calls “recollection of what\\r\\nthe soul saw when it was travelling with god, when it disregarded the\\r\\nthings we now call real and lifted up its head to what is truly real\\r\\ninstead.” The heavenly adventure now seems to amount to no more\\r\\nthan the employment of the dialectical method that Socrates is going\\r\\nto describe, without further mythical camouflage, in the\\r\\ndialogue’s second part. The ability to work out a taxonomy,\\r\\nestablishing the unity in a given subject-matter and dividing it up\\r\\naccording to its natural kinds, is the art that characterizes the\\r\\n‘scientific rhetorician’ (265d–266b). Socrates\\r\\nprofesses the greatest veneration for such a master: “If I\\r\\nbelieve that someone is capable of discerning a single thing that is\\r\\nalso by nature capable of encompassing many, I follow ‘straight\\r\\nbehind, in his tracks, as if he were a god’.” So the\\r\\nheavenly voyage has a quite down-to-earth counterpart in the\\r\\ndialectical method – a method that Plato regards as a\\r\\n‘gift of the gods’, as he is going to confirm in the (16c). At the same time, Plato’s esteem for\\r\\ntaxonomy explains the inner unity of the ’\\r\\nseemingly incongruous two parts as two sides of one coin, and it also\\r\\nshows why Plato no longer treats the sensory as a mere distraction and\\r\\ndisturbance of the mind. Instead, the properly conditioned\\r\\nsouls’ sensory impressions are its first incentives to seek the\\r\\nhigher and better.  \\nPhaedrus  \\nSymposium’s  \\nscala amoris  \\nsynienai kat  \\neidos legomenon, ...eis hen\\r\\nlogismôi synairoumenon  \\nPhilebus  \\nPhaedrus  \\nWhat concept of happiness is suggested by this ‘divinely\\r\\ninspired’ view of human life? Individuals do not, here, find\\r\\ntheir fulfillment in peaceful interactions in a harmonious community.\\r\\nInstead, life is spent in the perennial pursuit of the higher and\\r\\nbetter. But, in that task, the individual is not alone; she shares it\\r\\nwith kindred spirits. The message of both the and\\r\\nthe is, therefore, two-pronged. On the one hand, there\\r\\nis no permanent attainment of happiness as a stable state of\\r\\ncompletion in this life. In the ups and downs of life (and of the\\r\\nafterlife), humans are in constant need of beauty as an incentive to\\r\\naim for self-perfection. Humans are neither god-like nor wise; at\\r\\nbest, they are god-lovers and philosophers, demonic hunters for truth\\r\\nand goodness. To know is not to have, and to have once is not to have\\r\\nforever. In the , Diotima states in no uncertain\\r\\nterms that humans have a perennial need to replenish what they\\r\\nconstantly lose, both in body and soul, because they are mortal and\\r\\nchangeable creatures, and the confirms the need for\\r\\ncontinued efforts because the heavenly voyage is not a one-time\\r\\naffair. On the other hand, there is also the message conveyed that the\\r\\npursuit of the good and the beautiful is not a lonely enterprise. As\\r\\nindicated in the and further elaborated in the , love for a beautiful human being is an incentive to\\r\\nsearch for a higher form of life, a sacred joint journey of two\\r\\nfriends in communion (255a–256e). The need for, and also the\\r\\npossibility of, constant self-repletion and -perfection is a motive\\r\\nthat will reappear in the ethical thought of Plato’s late works,\\r\\na motif he sometimes presents as the maxim that humans should aim at\\r\\nthe ‘likening of oneself to god’ ( in 176b; 90c).  \\nSymposium  \\nPhaedrus  \\nSymposium  \\nPhaedrus  \\nSymposium  \\nPhaedrus  \\nhomoiôsis\\r\\ntheôi  \\nTheaetetus  \\nTimaeus  \\nSober philosophers have a tendency to ignore such visionary talk as a\\r\\nkind of that lacks the substance to be worth\\r\\nserious thought. That Plato, appearances notwithstanding, is not\\r\\nindulging in a god-besotted in the is indicated by his interweaving of the mythical\\r\\ndepiction in the dialogue’s first part with his specification\\r\\nand exploration of the dialectical method in the later part\\r\\n(259e-279c), where Socrates attempts to determine the requirements of\\r\\n‘scientific rhetoric’ (259e–279c). Artful speaking,\\r\\nas well as artful deception, presupposes knowledge of the truth,\\r\\nespecially where the identity of the phenomena is difficult to grasp,\\r\\nbecause similarities can be misleading. This applies in particular to\\r\\nconcepts like the good and the just, as witnessed by the wide\\r\\ndisagreement about their nature (263a–c). The development of the\\r\\n‘sharp eye’ that is needed to assign each object to the\\r\\nright class is the aim of Plato’s method of collection and\\r\\ndivision, a method on which he expounds at some length in the . He discusses the care that is needed in order to\\r\\n“see together things that are scattered about everywhere, and to\\r\\ncollect them into one kind ( )”, as well as\\r\\n“to cut the unity up again according to its species along its\\r\\nnatural joints, and to try not to splinter any part, as a bad butcher\\r\\nmight do (265d–e).” That this method is supposed to serve\\r\\nan overall ethical purpose is confirmed by the fact that rhetoric\\r\\nbased on truth must reflect the speaker’s knowledge not only of\\r\\nthe different types of souls and the types of speech that fit them\\r\\n(271d) but also of the truth about just and good things (272d).  \\nSchwärmerei  \\nrêverie  \\nPhaedrus  \\nPhaedrus  \\nmia idea  \\nThat dialectic is geared to this end is somewhat obscured in the\\r\\nsubsequent discussion in the . First of all, Plato\\r\\nturns away from this issue in his long depiction of the iniquities of\\r\\ncontemporary rhetoricians when he contrasts their efforts with that\\r\\nof the scientific rhetorician. And Plato continues this excursion with\\r\\na discussion of speaking and writing, culminating in his famous\\r\\n‘critique of writing’. Second, although Plato makes ample\\r\\nuse of the method of collection and division in later dialogues such\\r\\nas the and the , he seems to pay\\r\\nlittle heed there to problems of ethics, with the exception of the . But the aptness of the dialectical method in\\r\\ndiscerning the nature of the good has already been emphasized in the (534b–c): “Unless someone can\\r\\ndistinguish in an account the Form of the Good from everything else,\\r\\ncan survive all refutation as if in battle... you will say that he\\r\\ndoes not know the good itself or any other good.” Brief as these\\r\\nremarks are, they show that the application of dialectic is of central\\r\\nimportance to the understanding and pursuit of the good. That the good\\r\\nis nowhere subjected to such treatment must be due to the enormity of\\r\\nthe task involved in undertaking a systematic identification of all\\r\\nthat is good and in working out the criteria of distinction. Although\\r\\nit is unclear whether Plato in the had already\\r\\nrefined the dialectical method in the systematic way indicated in the , the hints contained about a ‘longer\\r\\nway’ (435d; 504b) to determine the nature of justice and that of\\r\\nthe other virtues suggest that the development of a systematic method\\r\\nof collection and division was at least ‘in the works’. As\\r\\na closer look at the much later will show, the\\r\\ndetermination of what is good about each kind of thing presupposes\\r\\nmore than a classification by collection and division: the internal\\r\\nstructure of each kind of entity has also to be determined. Knowledge\\r\\nis not confined to the comprehension of the objects’ being,\\r\\nidentity, difference and other interrelations that exist in a given\\r\\nfield. It also presupposes the knowledge of what constitutes the\\r\\nobjects’ internal unity and complexity. It would, of course, be\\r\\nrather presumptuous to claim that Plato had not seen the need to\\r\\ninvestigate the ontological ‘anatomy’, as well as the\\r\\ntaxonomy, of the Forms from early on. But as the late dialogues show,\\r\\nit took him quite some effort to develop the requisite conceptual\\r\\ntools for such analyses.  \\nPhaedrus  \\nSophist  \\nStatesman  \\nPhilebus  \\nRepublic  \\nRepublic  \\nPhaedrus  \\nPhilebus  \\nBefore we turn to the late dialogues, a final review is in order of\\r\\nthe kind of that Plato envisages in the dialogues\\r\\nunder discussion here. In the , the emphasis is on\\r\\nthe individual’s creative work, which involves others at least\\r\\nas catalysts in one’s efforts to attain self-perpetuation and\\r\\nself-perfection. The quality of life attainable by each person\\r\\ndiffers depending on the kind of ‘work’ each individual\\r\\nis able to produce. This is what the is all\\r\\nabout. In the , the emphasis is on the ‘joint\\r\\nventure’ of two kindred souls. True friends will get to the\\r\\nhighest point of self-fulfillment through the joint insights that they\\r\\nattain. Just as in the , the philosophical life is\\r\\ndeemed the best. But then, this preference is found everywhere in\\r\\nPlato, and it is not unique to him: All ancient philosophers regard\\r\\ntheir own occupation as the true fulfillment of human nature –\\r\\nas they saw it. If there are differences between them, they concern\\r\\nthe kinds of study and occupation that they deemed appropriate for the\\r\\nphilosopher. The more individualistic view of happiness espoused in\\r\\nthe and in the need, however, not\\r\\nbe seen as a later stage in Plato’s development than the communitarian conception. They may present\\r\\ncomplementary, rather than rival, points of view, and no fixed\\r\\nchronology need be assumed in order to accommodate both.  \\ngood life  \\nSymposium  \\nscala amoris  \\nPhaedrus  \\nSymposium  \\nSymposium  \\nPhaedrus  \\nRepublic’s  \\n4. The late dialogues: Ethics and Cosmology  \\n4.1 Harmony and cosmic goodness  \\nMost modern readers of Plato tend to ignore the significance of\\r\\nPlato’s late dialogues for his ethical views, for late dialogues\\r\\nsuch as the appear to concentrate on nature and\\r\\nmetaphysics — and, for the most part, drop questions such as the\\r\\nnature of the virtues and the moral psychology of the soul. This\\r\\nappears to be a shift in emphasis since nature and natural things are\\r\\nnot among the objects that concern Plato in his earlier and middle\\r\\nphilosophical investigations. Thus, in the , he\\r\\ndismisses the study of the visible heaven from the curriculum of\\r\\nhigher learning, along with the study of audible music. But, such\\r\\ngeneralizations about Plato’s intentions may be misleading. What\\r\\nhe denigrates is not the study of the heavenly order as such or that\\r\\nof harmonics; it is, rather, the extent to which humans must necessarily\\r\\nrely on their eyes and ears in those concerns. Students of philosophy\\r\\nare, rather, encouraged to work out the true intelligible order\\r\\nunderlying the visible heaven and audible music. Not only that: The\\r\\nascent out of the Cave does include recognition of objects outside,\\r\\nespecially “the things in the sky” ( 516a–b). If Plato is critical of natural science, it is because\\r\\nof its empirical approach. This echoes the ’s\\r\\ncomplaint that one ruins one’s eyes by looking directly at\\r\\nthings, most of all at the sun ( . 99d–e), while\\r\\nignoring the ‘binding force’ of the good. But what kind of\\r\\n‘binding force’ does Plato attribute to ‘the\\r\\nGood’? His reticence about this concept, despite its centrality\\r\\nin his metaphysics and ethics, is largely responsible for the\\r\\nobscurity of his concept of happiness and of what it is to lead a good\\r\\nlife. The philosophers’ knowledge supposedly provides a solid\\r\\nbasis for the good life of the entire community, as well as for that\\r\\nof the – perhaps uncomprehending – majority, because all\\r\\nbenefit from the good order of the state. But what is ‘the\\r\\nGood’ that is responsible for the goodness of all other things?\\r\\nA lot of ink has been spilt over the following passage in book VI, 509b: “Not only do the objects of\\r\\nknowledge owe their being to the Good, but their ( ) is also due to it, although the Good\\r\\nis not being, but beyond it ( ) in rank and\\r\\npower.” The analogy with the sun’s maintenance of all that\\r\\nis alive suggests that the Good is the intelligent inner principle\\r\\nthat determines the nature of every object that is capable of\\r\\ngoodness, in the sense that these objects fulfill their respective\\r\\nfunctions in the appropriate way. Plato does not attempt to state how\\r\\nsuch a principle of goodness works in all things in the , nor does he indicate whether he has in mind a\\r\\nunifying principle in a strong sense. That he is indeed thinking of an\\r\\ninternal ‘binding force’ for all kinds of things is\\r\\nindicated, however, in Book X, in his elucidation of the ontological\\r\\ndifferences that exist, respectively, between the Forms as the\\r\\nproducts of a divine maker, their earthly copies, and the imitation of\\r\\nthese copies by an artist ( . 596a ff.). According to Plato,\\r\\nin each case, it is the or that\\r\\ndetermines what it is to be good (601d): “Aren’t the\\r\\nvirtue or excellence, the beauty and correctness of each manufactured\\r\\nitem, living creature, and action related to nothing but the use\\r\\n( ) for which each is made or naturally adapted?”\\r\\nGiven that Plato does not limit this account to tools or instruments\\r\\nbut explicitly includes living things and human actions, he seems to\\r\\nhave a specific criterion in mind for what constitutes each\\r\\nthing’s excellence. But what determines the ‘use’ of\\r\\na human being, and to what extent can there be a common principle that\\r\\naccounts for all good things? In the , this question\\r\\nis answered only indirectly through the isomorphism of the just state\\r\\nand the just soul, based on a harmonious internal order. The postulate\\r\\nof such an orderly structure is not explicitly extended beyond the\\r\\nstate and the soul. In the later dialogues, by contrast, the Good\\r\\nclearly operates on a cosmic scale. That such is Plato’s view\\r\\ncomes to the fore in his excursus on the philosopher’s nature in\\r\\nthe (173c–177c). Contrary to Socrates’\\r\\ndenial in the , Socrates in the affirms that the philosopher is to pursue both “what lies below\\r\\nthe earth and the heights above the heaven” (173e):\\r\\n“tracking down by every path the entire nature of each whole\\r\\namong the things that are.” And Socrates also concerns himself\\r\\nthere with the question of “What is man? What actions and\\r\\npassions properly belong to human nature and distinguish it from all\\r\\nother beings?” In that connection, he compares the discovery of\\r\\ntruth with ‘likening oneself to God’ ( ) and indicates that there is a unitary principle of\\r\\ngoodness. The ability to achieve this superhuman state depends on\\r\\none’s readiness to engage in strenuous philosophical discourse\\r\\n(177b).  \\nTimaeus  \\nRepublic  \\nR.  \\nPhaedo  \\nPhdo  \\nRepublic  \\nknown  \\nbeing  \\nousia  \\nepekeina  \\nRepublic  \\nR  \\nuse  \\nfunction  \\nchreia  \\nRepublic  \\nTheaetetus  \\nApology  \\nTheaetetus  \\nhomoiôsis\\r\\ntheôi  \\nIf, in the , the goodness of the individual soul is\\r\\nexplained in terms of its being a smaller copy of a harmonious\\r\\nsociety, in the , Plato goes for an even larger model.\\r\\nThe universe and its soul now supply the ‘large text’ for\\r\\ndeciphering the nature of the human soul. The structure of the\\r\\nworld-soul is replicated in the nature of the human soul. That there\\r\\nis, nevertheless, a close affinity between the and\\r\\nthe cosmological project that Plato means to pursue in the and its intended sequel is clearly indicated in the\\r\\npreface to the . The tale of the origin of the\\r\\nuniverse, including human nature, is presented as the first step\\r\\ntowards fulfilling Socrates’ wish to see his own best city\\r\\n‘in action’ ( . 19b–c). From antiquity on,\\r\\nthis introduction has created the impression that the is the direct continuation of the , an impression\\r\\nthat explains its juxtaposition in the .\\r\\nStrong indications speak, however, for a much later date of the . If Plato establishes a link between these two works,\\r\\nhis intent is to compare as well as to contrast. The continuity\\r\\nconsists solely in the fact that Socrates reaffirms his adherence to\\r\\nhis ideal city’s order – at least in principle\\r\\n( . 17c–19b). It is this order that Critias promises\\r\\nto illustrate by a narration of the tale of two cities, of the war\\r\\nbetween pre-historic Athens, a city that exemplifies the ideal order,\\r\\nand Atlantis, a powerful tyrannical superpower ( .\\r\\n20d–26e). However, Plato never completed this project: The breaks off after some 15 Stephanus-pages, in\\r\\nmid-sentence, and the third dialogue in the series, , whatever was to have been its content, was never\\r\\nwritten at all. So, the story of Socrates’ ideal city and of the life of its citizens remains untold. All we\\r\\nhave is Plato’s cosmic model for such a state and the soul of\\r\\nits inhabitants (on Plato’s cosmology, see the entry by Donald Zeyl and Barbara Sattler in ).  \\nRepublic  \\nTimaeus  \\nRepublic  \\nTimaeus  \\nTimaeus  \\nTi  \\nTimaeus  \\nRepublic  \\nCorpus Platonicum  \\nTimaeus  \\nTi  \\nTi  \\nCritias  \\nHermocrates  \\nin\\r\\naction  \\nPlato’s Timaeus  \\nSEP  \\nA crucial difference between the philosophical approach in the and that in the lies in the fact\\r\\nthat, in the latter dialogue, Plato concerns himself with the structure\\r\\nof the visible heaven as a model for the human soul and also with the\\r\\nmaterial conditions of human physiology. What is confined to mythology\\r\\nin Plato’s earlier works is here worked out – though not\\r\\nwithout a to the effect that Plato is merely offering\\r\\na rather than a scientific explanation of the\\r\\nstructure of the universe, of the human soul, and of human physiology.\\r\\nPlato’s choice of presenting his explanation of the order of the\\r\\nuniverse as a story of creation by a so-called demiurge or\\r\\n‘divine workman’ is certainly no accident. It can be\\r\\nunderstood as a kind of ‘retractation’ of his deprecatory\\r\\ndepiction of the divine workman’s heavenly embroidery in VII 528e-530d, where such a product is depreciated\\r\\nbecause of its inferiority to a model conceivable in theory. To be\\r\\nsure, the presupposes the Forms as the divine\\r\\nworkman’s unchanging models, and he resorts to mathematical\\r\\nprinciples to explain the cosmic order (27d–29d; 30c–31b),\\r\\nbut the focus is almost exclusively on the construction of the visible\\r\\nheavens. Plato now seems to have convinced himself that in order to\\r\\nexplain the nature of a living being, it is necessary to show what\\r\\nfactors constitute such a live organism.  \\nRepublic  \\nTimaeus  \\ncaveat  \\nlikely story  \\nRepublic  \\nTimaeus  \\nThis intention explains certain peculiarities of the that make the dialogue hard to penetrate, for it falls into three\\r\\nrather disparate parts. The first part describes the structure of the\\r\\nworld-soul and its replication in the human soul in a way that\\r\\ncombines the general principles with those of mathematics and\\r\\nharmonics and illustrates it with fantastic imagery (29d–47e).\\r\\nThe second part consists of a rather meticulous account of the\\r\\nelementary corporeal constituents of nature, which are supposedly\\r\\nformed out of geometrically constructed atoms (47e–69a). The\\r\\nthird part combines elements from the first and second parts in a\\r\\nlengthy explanation of human physiology and psychology\\r\\n(69b–92c). The first, cosmological, part of the greatly taxes one’s ability to relate the notion of a divinely\\r\\ncreated world-soul to the motions of the visible heavens because\\r\\nPlato offers only the barest hints concerning the intelligible,\\r\\nmathematical, and harmonic structure that is to explain these motions.\\r\\nBy contrast, the explanations in the second and third parts are hard to\\r\\nfollow because of Plato’s quite unique concern with the\\r\\nstructure and the dynamics of the basic elements of the physical world\\r\\nin general and with that of human physiology in particular.  \\nTimaeus  \\nTimaeus  \\nBut why does Plato burden himself and his readers with such a complex\\r\\nmachinery, and what does this heavenly instrument have to do with\\r\\nethics? Since the human soul is formed out of the same ingredients as\\r\\nthe world soul (albeit of a less pure kind) and displays the same\\r\\nstructure (41d–e), Plato is clearly not just concerned with the\\r\\norder of the universe but with that of the human soul as well. He\\r\\nattributes to it the possession of the kinds of concepts that are\\r\\nnecessary for the understanding of the nature of all things, both\\r\\neternal and temporal. The soul’s ingredients are here limited to\\r\\nthe purely general concepts and to mathematical proportions. There is\\r\\nno reference to a theory of recollection of the nature of all things.\\r\\nRather, Plato is concerned to ascertain that the soul has all the\\r\\ntools for dealing with all objects: (1) the most important concepts\\r\\nnecessary for the identification and the differentiations in the way\\r\\nrequired for dialectical procedure; (2) the numbers and proportions\\r\\nneeded to understand numerical relations and harmonic structures of\\r\\nall sorts; (3) the capacity of the soul to perform and comprehend\\r\\nharmoniously coordinated motions. This, it seems, is all the soul\\r\\nneeds and all it gets so that it can perform its various tasks. The\\r\\nunusual depiction of the soul’s elements and composition makes\\r\\nit hard, at first, to penetrate to the rationale of its construction,\\r\\nand it must remain an open question to what extent Plato expects his\\r\\nmodel to be taken in a literal rather than in a figurative sense. His\\r\\noverall message should be clear, however: The soul a\\r\\nharmoniously structured entity that can, in principle, function\\r\\nforever, and it also the corresponding structures\\r\\nof other entities and, therefore, has access to all that is good and\\r\\nharmonious. This last point has consequences for his ethical thought\\r\\nthat are not developed in the itself, but that can be\\r\\ndetected in some of the other late dialogues.  \\nis  \\ncomprehends  \\nTimaeus  \\n4.2 Measure for Measure  \\nPlato’s concern with ‘right measure’ in a sense that\\r\\nis relevant for ethics is, of course, not confined to his late work.\\r\\nIt shows up rather early. Already in the , Socrates\\r\\nblames Callicles for the undisciplined state of his soul and\\r\\nattributes it to his neglect of geometry (508a): “You’ve\\r\\nfailed to notice that proportionate equality ( ) has great power among both gods and men.” But\\r\\nit is unclear whether this expression is to be taken in a more than\\r\\nmetaphorical sense; it is, at any rate, not repeated anywhere else in\\r\\nPlato’s earlier work. There is also no indication that Plato\\r\\ntakes seriously the idea of a ‘quantification’ of the\\r\\nnature of the virtues in his middle dialogues. If mathematics looms\\r\\nlarge, then, it is as a model science on account of its exactness, the\\r\\nstability of its objects, and their accessibility to reason. A\\r\\nsystematic exploration of the notion that measure and proportion are\\r\\nthe fundamental conditions of goodness is confined to the late\\r\\ndialogues. Apart from the ’ emphasis on a\\r\\nprecise cosmic and mental order, there is a crucial passage in the (283d–285c), where the Eleatic Stranger\\r\\ndistinguishes two kinds of ‘art of measurement’. The first\\r\\nkind is the ordinary measuring of quantities relative to each other\\r\\n(‘the great and small’). The second kind has a normative\\r\\ncomponent: It is concerned with the determination of ‘due\\r\\nmeasure’ ( ). The latter is treated with great\\r\\nconcern, for the Eleatic Stranger claims that it is the basis of all\\r\\nexpertise, including statesmanship, the very art that is the subject\\r\\nof that dialogue (284a–b): “It is by preserving measure in\\r\\nthis way that they produce all the good and fine things they do\\r\\nproduce.” His point is that all good productions and all\\r\\nprocesses of generation that come to a good end presuppose\\r\\n‘right measure’, while arbitrary quantities (‘the\\r\\nmore and less’) have no such results. The Eleatic Stranger\\r\\ntherefore suggests a separation of the simple arts of measuring from\\r\\nthe arts concerned with due measure (284e): “Positing as one\\r\\npart all those sorts of expertise that measure the numbers, lengths,\\r\\ndepths, breadths and speeds of things in relation to what is opposed\\r\\nto them, and as the other, all those that measure in relation to what\\r\\nis in due measure ( ), what is fitting ( ), the right moment ( ), what is as it\\r\\nought to be ( ) – everything that is removed from\\r\\nthe extremes to the middle ( ).” This distinction\\r\\nfinds no application in the itself, except that due\\r\\nmeasure must be presupposed in the final definition of the statesman\\r\\nas a ‘kingly weaver’, weaving together the fabric of the\\r\\nstate by combining the aggressive and the moderate temperaments in the\\r\\npopulation so as to produce a harmonious citizenry (305e– 311c).\\r\\nBut no mathematic procedure is specified as the condition of such a\\r\\n‘mixing together of the citizens’ characters’ in due\\r\\nmeasure.  \\nGorgias  \\ngeometrikê\\r\\nisotês  \\nTimaeus  \\nStatesman  \\nto metrion  \\nto metrion  \\nto\\r\\nprepon  \\nto kairion  \\nto deon  \\nmeson  \\nStatesman  \\nThe importance of ‘measure’ in a seemingly literal sense\\r\\nis made explicit; however, in the , the dialogue that\\r\\nis concerned with the question of whether pleasure or knowledge is the\\r\\nstate of mind that constitutes happiness. In that dialogue, number\\r\\n( ), limit ( ), and measure\\r\\n( ) play a crucial role at various points of the\\r\\ndiscussion, and the is also the dialogue where Plato\\r\\nrequires that numerical precision must be observed in the application\\r\\nof the ‘divine gift’ of the dialectical procedure of\\r\\ncollection and division (16c–17a). The dialectician must know\\r\\nprecisely how many species and subspecies a certain genus contains;\\r\\notherwise, he has no claim to any kind of expertise. Despite this\\r\\nemphasis on precision and on the need to determine the numerical\\r\\n‘limit’ in every science, Socrates does not provide the\\r\\nenvisaged kind of collection and division of pleasure and knowledge.\\r\\nHe avoids that task with the pretense that he suddenly remembers that\\r\\nneither of the two contenders suffices in itself for the happy life\\r\\nand that a mixture of the two is preferable. To explain the nature of\\r\\nthis mixture, Socrates introduces a fourfold division of all beings\\r\\n(23c–27c), a division that uses the categories of\\r\\n‘limit’ and ‘measure’ in a different way than\\r\\nthe one suggested earlier for the ‘divine method of\\r\\ndialectic’. Limit now concerns the objects’ internal\\r\\nstructure. As Socrates states, all beings belong in one of four\\r\\nclasses – namely (1) limit ( ), (2) the unlimited\\r\\n( ), (3) the mixture ( ) of limit and the\\r\\nunlimited, or (4) the cause ( ) of such a mixture. As the\\r\\nsubsequent explications concerning the four classes show, the\\r\\nunlimited comprises all those things that have no exact measure or\\r\\ngrade in themselves, such as what is hotter and colder, faster and\\r\\nslower. Although at first the examples are confined to relative terms,\\r\\nthe class of the unlimited is then extended to things like hot and\\r\\ncold, dry and moist, fast and slow, and even heat and frost, i.e., to\\r\\nall that has no fixed limit or degree. Mixture takes place when such\\r\\nqualities take on a definite quantity ( ) or due measure\\r\\n( ) that puts a definite limit on their variety. That\\r\\nonly measured entities qualify as mixtures is not only suggested by\\r\\nthe examples Socrates refers to (health, strength, beauty, music, and\\r\\nthe seasons) but by his assertion, later in the dialogue, that a\\r\\nmixture without due measure or proportion does not deserve its name\\r\\n(64d–e): “it will necessarily corrupt its ingredients and\\r\\nmost of all itself. For there would be no blending in such cases at\\r\\nall but only an unconnected medley, the ruin of whatever happens to be\\r\\ncontained in it.” The upshot of this discussion is that all\\r\\nstable entities represent a harmonious equilibrium of their otherwise\\r\\nlimitless ingredients. Since indeterminate elements usually turn up in\\r\\npairs of opposites, the right limit in each case must be the right\\r\\nproportion necessary for their balance. In the case of health, there\\r\\nwill be the right balance between the hot and the cold, the dry and\\r\\nthe moist. The cause of the proper proportion for each mixture turns\\r\\nout to be ; it is the only member of the fourth class.\\r\\nAs Socrates indicates, divine reason is the ultimate source of all\\r\\nthat is good and harmonious in the universe, while human reason\\r\\nconstitutes order down here (26e–27c; 28a–30e).  \\nPhilebus  \\narithmos  \\nperas  \\nmetron  \\nPhilebus  \\nperas  \\napeiron  \\nmeixis  \\naitia  \\nposon  \\nmetrion  \\nreason  \\nThe adoption of this fourfold ontology allows Socrates to assign\\r\\npleasure and knowledge to two of the four classes of being: Pleasure\\r\\nturns out to be unlimited because it admits of the ‘more and\\r\\nless’. Reason, by contrast, belongs to the fourth class, to the\\r\\ncauses of good mixtures. On the basis of this classification, Socrates\\r\\nprovides the criteria for a critical assessment of the different kinds\\r\\nof pleasure and knowledge (31b–59d) and presents happiness as a\\r\\nmixture of all kinds of knowledge with true and pure kinds of pleasure\\r\\n(59d-64b). In a final ‘ranking of goods’, measure and due\\r\\nproportion, unsurprisingly, get the first rank among the possessions\\r\\nof the soul, things in proper proportion come in second, reason is\\r\\nranked third, the arts and sciences obtain fourth place, whereas the\\r\\ntrue and pure pleasures get fifth and last place on the scale of goods\\r\\n(64c–67b). If Plato in the is more favorably\\r\\ndisposed towards a hedonist stance than in some of his earlier works,\\r\\nhe is so only to a quite limited degree: He regards pleasure as a\\r\\nnecessary ingredient in human life because both the physical and the\\r\\npsychic equilibria that constitute human nature are unstable. In a\\r\\nsense that recalls the , Plato presupposes that\\r\\nthere is always some or that needs\\r\\nsupplementation. Because the range of such ‘supplements’\\r\\nincludes learning and the pursuit of the virtues, there are some\\r\\npleasures that are rightly cherished. But even they are deemed goods\\r\\nonly insofar as they are a compensation for human imperfection.  \\nPhilebus  \\nSymposium  \\ndeficiency  \\nlack  \\nGiven the importance of ‘measure’, there is the question\\r\\nof how serious Plato is about such a ‘mathematization’ of\\r\\nhis principles, quite generally. Though harmony and order have been\\r\\ntreated as important principles in Plato’s metaphysics and\\r\\nethics from early on, in his late dialogues, he seems to envisage right\\r\\nmeasure in a literal sense. This explains his confidence that even\\r\\nphysical entities can attain a relatively stable state. As he suggests\\r\\nboth in the and in the , not\\r\\neverything is in a constant flux. On the contrary, those things that\\r\\npossess the measures that are right for their type are stable entities\\r\\nand can be the objects of ‘firm and true beliefs and\\r\\nconvictions’ ( . 37b–c). This applies not only\\r\\nto the nature of the visible universe but also to the human body and\\r\\nmind. Plato seems to have felt encouraged to embrace such theories by\\r\\nthe advances of astronomy and harmonics in his own lifetime so that\\r\\nhe postulates ‘due proportion’ in an arithmetical sense as\\r\\nthe cause of all harmony and stability.  \\nTimaeus  \\nPhilebus  \\nTi  \\nPlato’s confidence seems to have extended not only to the\\r\\nphysical but also to the moral state of human nature. That assumption\\r\\nis confirmed not only by the emphasis on right mixture in the but also by the discussion in the about how the laws are to achieve peace in the state and harmony in\\r\\nthe souls of the citizens. Plato no longer treats the emotions as a\\r\\nmenace to the virtues; rather, he assigns to the legislators the task\\r\\nof providing for an adequate balance of pleasure and pain by\\r\\nhabituating the citizens in the right way (632a–643a). This\\r\\nbalance, through , is crucial for maintaining a truly\\r\\nliberal soul (I 636e): “Pleasure and pain flow like two springs\\r\\nreleased by nature. If a man draws the right amount from the right\\r\\nspring at the right time, he lives a happy life.” Suffice it to\\r\\nnote that the comments concerning the right measure of pleasure and\\r\\npain form the preface to the entire project. That there is a\\r\\nconsiderable re-evaluation of the emotions in the ,\\r\\ncompared to that in the , is confirmed by the fact\\r\\nthat, according to II, education is supposed to provide\\r\\nthe citizens with the right habituation ( )\\r\\nconcerning the measure of pleasure and pain. The function assigned,\\r\\nthere, to the right measure of pleasure and pain in the\\r\\ncitizens’ sentimental education clearly anticipates the\\r\\nAristotelian conception of the moral virtues as the right mean between\\r\\nexcess and deficiency (II 653b–c): “Virtue is this general\\r\\nconcord of reason and emotion. But there is one element you could\\r\\nisolate in any account you give, and this is the correct formation of\\r\\nour feelings of pleasure and pain, which makes us hate what we ought\\r\\nto hate from first to last, and love what we ought to love.” The\\r\\nconfidence expressed in the in the power of due measure\\r\\nculminates in the famous maxim that God (rather than Protagoras’\\r\\nMan) is the measure of all things (IV 716c–d): “In our\\r\\nview, it is God who is preeminently the ‘measure of all\\r\\nthings’, much more so than any man, as they say. So if you want\\r\\nto recommend yourself to someone of this character, you must do your\\r\\nlevel best to make your own character reflect his, and on this\\r\\nprinciple the moderate man is God’s friend, being like him,\\r\\nwhereas the immoderate and unjust man is not like him and is his\\r\\nenemy; and the same reasoning applies to the other vices too.”\\r\\nBut because Plato, like Aristotle after him, carefully refrains from\\r\\nany kind of specifications of concrete right measures, we should treat\\r\\nthe ‘arithmetic’ of the good life with a pinch of salt.\\r\\nThat individuals differ in their internal and external conditions is\\r\\nas clear to Plato as it is to Aristotle. This does not shake\\r\\nPlato’s faith in the that right habituation\\r\\nthrough the right kind of education, most of all in the arts, will\\r\\nprovide the necessary inner equilibrium in the soul of the good\\r\\ncitizen.  \\nPhilebus  \\nLaws  \\npaideia  \\nLaws  \\nRepublic  \\nLaws  \\nĕthos  \\nLaws  \\nLaws  \\nAre Plato’s views of human nature and the human good more\\r\\nsympathetic to democratic standards in his last works? If we look at\\r\\nthe requirements in the concerning the good state of\\r\\nthe human soul in ‘orderly circles’, Plato seems to remain\\r\\nas demanding and elitist as ever. But he no longer puts so much\\r\\nemphasis on the distance between the best and the ordinary. As he\\r\\nremarks in the , statesmen don’t stick out\\r\\nfrom the rest of humankind in mind and body like the queen-bees do in\\r\\nthe hive (301d-e). Further, even the best of the souls of human beings\\r\\nare far inferior to the world-soul, because, in the case of human souls,\\r\\ntheir ‘incorporation’ means disorder that subsides only\\r\\ngradually ( . 42e-44c). That this applies to all human\\r\\nbeings suggests that Plato has become more democratic in the sense\\r\\nthat he regards the ‘human herd’ as a more uniform flock\\r\\nthan he did in his earlier days. He retains the conviction, however,\\r\\nthat a well-ordered soul is the prerequisite of the good life and that\\r\\nhuman beings stand in need not only of a careful moral education but\\r\\nalso of a well-regulated life. Whether a life in Plato’s\\r\\nnomocracy would better please modern minds than a life ruled by\\r\\nphilosopher-kings is a question that would require a careful perusal\\r\\nof that enormous compendium of regulations and laws, which makes the\\r\\ntask of reading and understanding the very hard work.\\r\\nBut that compendium is at the same time a valuable sourcebook for all\\r\\nthose interested in Plato’s late moral thought (for a more\\r\\ndetailed evaluation of the , see the entry in by Chris Bobonich and Katherine\\r\\nMeadows).  \\nTimaeus  \\nStatesman  \\nTi  \\nLaws  \\nLaws  \\nPlato on\\r\\nUtopia  \\nSEP  \\nGlossary  \\naccount:  \\nlogos  \\nappetitive part:  \\népithumetikon  \\nart:  \\ntechnê  \\nbeing:  \\nousia  \\ncause:  \\naitia  \\nconsonance:  \\nsumphonia  \\ncourage:  \\nandreia  \\ndifference:  \\nheteron  \\neducation:  \\npaideia  \\nenthusiasm:  \\nenthusiasmos  \\nexcellence:  \\naretê  \\nform:  \\neidos, idea  \\nfunction:  \\nergon  \\nhabit:  \\nethos  \\nhappiness:  \\neudaimonia  \\nharmony:  \\nharmonia  \\nkind:  \\neidos, idea  \\njustice:  \\ndikaiosunê  \\nlikening to god:  \\nhomoiôsis theô  \\nlimit:  \\nperas  \\nlook:  \\nidea  \\nlove:  \\nerôs  \\nmadness, divine:  \\ntheia mania  \\nmeasure: ;  \\nmetron  \\nmetrion  \\nmixture:  \\nmeixis  \\nmodel:  \\nparadeigma  \\nmoderation:  \\nsôphrosunê  \\nneed: ;  \\nendeia  \\nchreia  \\nnumber:  \\narithmos  \\norder:  \\nkosmos  \\nperplexity:  \\naporia  \\nquantity:  \\nposon  \\nrational part:  \\nlogistikon  \\nreason:  \\nnous  \\nreasoning:  \\nlogos  \\nrecollection:  \\nanamnêsis  \\nrefutation:  \\nelenchos  \\nsameness:  \\ntauton  \\nself-mastery:  \\negkrateia  \\nself-sufficiency:  \\nautarkeia  \\nsoul:  \\npsuchê  \\nsort:  \\neidos, idea  \\nspirited part:  \\nthumoeides  \\nsteadfastness:  \\nsôtêria  \\nunlimited:  \\napeiron  \\nvirtue:  \\naretê  \\nweakness of the will:  \\nakrasia  \\nwisdom:  \\nsophia  \\nBibliography  \\nTranslations  \\n, J.M. Cooper & D.S. Hutchinson\\r\\n(eds.), Indianapolis: Hackett, 1997.  \\nPlato: Complete Works  \\nSingle-Authored Overviews  \\nAnnas, J., 1993, , Oxford:\\r\\nOxford University Press.  \\nThe Morality of Happiness  \\n–––, 1999, , Ithaca: Cornell University Press.  \\nPlatonic Ethics, Old and\\r\\nNew  \\nBrickhouse, T. and Smith, N., 2020, , Cambridge: Cambridge University Press.  \\nSocratic Moral\\r\\nPsychology  \\nCooper, J.M., 2012, , Princeton:\\r\\nPrinceton University Press.  \\nPursuits of Wisdom: Six Ways of Life in\\r\\nAncient Philosophy from Socrates to Plotinus  \\nCrombie, I. M., 1963, , 2 vols.,\\r\\nLondon: Routledge & Kegan Paul.  \\nPlato’s Doctrines  \\nDover, K., 1974, , Berkeley: University of California Press.  \\nGreek Popular Morality in the Time of Plato\\r\\nand Aristotle  \\nIrwin, T., 1977, , Oxford: Clarendon Press.  \\nPlato’s Moral Theory: The Early and\\r\\nMiddle Dialogues  \\n–––, 1995, ,\\r\\nOxford: Oxford University Press.  \\nPlato’s Ethics  \\n–––, 2008, (Volume I: ), Oxford: Oxford\\r\\nUniversity Press.  \\nThe Development of Ethics  \\nFrom Socrates to the Reformation  \\nKahn, C., 1996, ,\\r\\nCambridge: Cambridge University Press.  \\nPlato and the Socratic Dialogue  \\nKamtekar, R., 2017, ,\\r\\nOxford: Oxford University Press.  \\nPlato’s moral psychology:\\r\\nintellectualism, the divided soul, and the desire for good  \\nLorenz, H., 2006, , Oxford: Clarendon Press.  \\nThe brute within: appetitive desires in\\r\\nPlato and Aristotle  \\nMann, W., 2006, “Plato in Tübingen: A Discussion of\\r\\nKonrad Gaiser, Gesammelte Schriften,” , 31: 349–400.  \\nOxford Studies in\\r\\nAncient Philosophy  \\nMcCabe, M.M., 1994, , Princeton:\\r\\nPrinceton University Press.  \\nPlato’s Individuals  \\n–––, 2000, , Oxford: Oxford University Press.  \\nPlato and His Predecessors: the\\r\\ndramatisation of reason  \\nMeinwald, C. 2016, , London: Routlege.  \\nPlato  \\nMenn, S., 1995, , Carbondale:\\r\\nSouthern Illinois University Press.  \\nPlato and God as Noûs  \\nNails, D., 2002, , Indianapolis: Hackett.  \\nThe People of Plato. A Prosography of Plato\\r\\nand Other Socratics  \\nNehamas, A., 1999, , Princeton: Princeton University Press.  \\nVirtues of Authenticity. Essays on Plato\\r\\nand Socrates  \\nPopper, K., 1956, (Vol.\\r\\n1), revised edition, London: Routledge & Kegan Paul.  \\nThe Open Society and Its Enemies  \\nPrice, A., 1989, , Oxford: Clarendon Press.  \\nLove and Friendship in Plato and\\r\\nAristotle  \\nPrior, W. J. 2019, , Cambridge: Polity\\r\\nPress.  \\nSocrates  \\nRist, J., 2012, , Washington, DC: Catholic\\r\\nUniversity of America Press.  \\nPlato’s moral realism: the discovery of\\r\\nthe presuppositions of ethics  \\nRowe, C., 2007, ,Cambridge: Cambridge University Press.  \\nPlato and the Art of Philosophical\\r\\nWriting  \\nRussell, D., 2005, ,\\r\\nOxford: Oxford University Press.  \\nPlato on Pleasure and the Good Life  \\nSchofield, M., 2006, , Oxford:\\r\\nOxford University Press.  \\nPlato: Political Philosophy  \\nScott, D., 2015, ,\\r\\nOxford: Oxford University Press.  \\nLevels of Argument. A Comparative Study of\\r\\nPlato’s Republic and Aristotle’s Nicomachean Ethics  \\nVasiliou, I., 2008, , Cambridge:\\r\\nCambridge University Press.  \\nAiming at Virtue in Plato  \\nVlastos, G., 1981, , Princeton: Princeton\\r\\nUniversity Press, second edition.  \\nPlatonic Studies  \\n–––, 1994, , Cambridge: Cambridge University Press.  \\nSocrates: Ironist and Moral\\r\\nPhilosopher  \\nVogt, K., 2012, , Oxford: Oxford University Press  \\nBelief and Truth: A Sceptic Reading of\\r\\nPlato  \\nWhite, N., 2002, ,\\r\\nOxford: Oxford University Press.  \\nIndividual and Conflict in Greek Ethics  \\nWolfsdorf, D., 2013, ,\\r\\nCambridge: Cambridge University Press.  \\nPleasure in Ancient Philosophy  \\nAnthologies  \\nAnagnostopoulos, G. and G. Santas (eds.), 2018, , Cham: Springer.  \\nDemocracy,\\r\\nJustice, and Equality in Ancient Greece  \\nBarney, R., Brennan, T., Brittain, C. (eds.), 2012, , Cambridge: Cambridge University Press.  \\nPlato and\\r\\nthe Divided Self  \\nBobonich, C. (ed.), 2010, , Cambridge: Cambridge University Press.  \\nPlato’s Laws. A Critical\\r\\nGuide  \\nCalvo, T. and Brisson, L. (eds.), 1995, , Sankt Augustin: Academia Verlag.  \\nInterpreting the\\r\\nTimaeus and Critias  \\nCornelli, G., Robinson, T., Bravo, F. (eds.), 2019, , Baden-Baden: Academia Verlag.  \\nPlato’s Phaedo: Selected Papers from the Eleventh Symposium\\r\\nPlatonicum  \\nDestrée, P. and Giannopoulou, Z. (eds.), 2016, ,\\r\\nCambridge: Cambridge University Press.  \\nCambridge Critical Guide to Plato’s Symposium  \\nDetel, W., Becker, A., and Scholz P. (eds.), 2003, , Stuttgart: Franz Steiner.  \\nIdeal and\\r\\nCulture of Knowledge in Plato  \\nDillon, J. and Brisson, L. (eds.), 2010, ,\\r\\nSankt Augustin: Academia Verlag.  \\nPlato’s\\r\\nPhilebus: Selected Papers from the Eighth Symposium Platonicum  \\nDöring, K., Erler, M., Schorn, S. (eds.), 2003, , Stuttgart: Franz Steiner.  \\nPseudoplatonica  \\nEbrey, D. and Kraut, R. (eds.), 2022, , 2nd edition, Cambridge: Cambridge University\\r\\nPress.  \\nThe Cambridge Companion\\r\\nto Plato  \\nErler, M. and Luc Brisson, 2007, : (International Plato Studies: Volume 25), Sankt Augustin: Academia\\r\\nVerlag.  \\nGorgias-Meno  \\nSelected papers from the Seventh Symposium Platonicum  \\nFine, G. (ed.), 1999, , , Oxford: Oxford University Press.  \\nPlato 1: Metaphysics and\\r\\nEpistemology  \\nPlato 2.: Ethics, Politics, Religion, and the\\r\\nSoul  \\n––– (ed.), 2008, , Oxford: Oxford University Press.  \\nThe Oxford Handbook of\\r\\nPlato  \\nGill, C. & McCabe, M. M. (eds.), 1996, , Oxford: Oxford University Press.  \\nForm and Argument\\r\\nin Late Plato  \\nGriswold, C. (ed.), 1988, , London: Duckworth.  \\nPlatonic Writings, Platonic\\r\\nReadings  \\nHermann, F.-G. (ed.), 2006, , Swansea:\\r\\nThe Classical Press of Wales.  \\nNew Essays on Plato  \\nIrwin, T., 1995, , Oxford: Oxford\\r\\nUniversity Press.  \\nPlato’s Ethics  \\nLisi, F. (ed.), 2001, , Sankt Augustin: Academia Verlag.  \\nPlato’s Laws and its Historical\\r\\nSignificance  \\nMcPherran, M. (ed.), 2010, , Cambridge: Cambridge University Press.  \\nPlato’s Republic, A Critical\\r\\nGuide  \\nMohr, R. and B. Sattler (eds.), 2010, Timaeus , Las Vegas:\\r\\nParmenides Publishing.  \\nOne book, the whole\\r\\nuniverse: Plato’s  \\ntoday  \\nMoravcsik, J. M. E. & Temko, P. (eds.), 1982, , Totowa, N.J.: Rowman &\\r\\nLittlefield.  \\nPlato on\\r\\nBeauty, Wisdom and the Arts  \\nMorrison, D. (ed.), 2012, , Cambridge: Cambridge University Press.  \\nThe Cambridge Companion to\\r\\nSocrates  \\nNotomi,N and Brisson, L. (eds.), 2013, , Sankt Augustin: Academia Verlag.  \\nDialogues on\\r\\nPlato’s Politeia: Selected Papers from the Ninth Symposium\\r\\nPlatonicum  \\nPappas, N. (ed.), 2013, Republic. London: Routledge.  \\nThe Routledge Guidebook to\\r\\nPlato’s  \\nPatterson, R., Karasmanis, V., Hermann, A. (eds.), 2012, , Las Vegas: Parmenides Publishing.  \\nPresocratics & Plato. Festschrift in Honor of Charles\\r\\nKahn  \\nRobinson, T. (ed.), 2000, , Sankt Augustin:\\r\\nAcademia Verlag.  \\nPlato: Euthydemus, Lysis, Charmides:\\r\\nProceedings of the Fifth Symposium Platonicum  \\nRosetti, L. (ed.), 1992, , Sankt Augustin:\\r\\nAcademia Verlag.  \\nUnderstanding the Phaedrus:\\r\\nProceedings of the Second Symposium Platonicum  \\nRowe, C. (ed.), 1995, , Sankt Augustin: Academia\\r\\nVerlag.  \\nReading the Statesman: Proceedings of\\r\\nthe Third Symposium Platonicum  \\nSantas, G. (ed.), 2006, , Malden, MA: Blackwell Publishing.  \\nThe Blackwell Guide to Plato’s\\r\\nRepublic  \\nScolnicov, S. and Brisson, L. (eds.), 2003, , Sankt\\r\\nAugustin: Academia Verlag.  \\nPlato’s\\r\\nLaws. Proceedings of the Sixth Symposium Platonicum  \\nTulli, M. and Erler, M. (eds.), 2013, , Sankt\\r\\nAugustin: Academia Verlag.  \\nPlato in Symposium:\\r\\nSelected Papers from the Tenth Symposium Platonicum  \\nVlastos, G. (ed.), 1971, (Volume 1: , Volume\\r\\n2: ),\\r\\nGarden City, NY: Doubleday Anchor.  \\nPlato: A Collection of Critical\\r\\nEssays  \\nMetaphysics and Epistemology  \\nEthics, Politics and Philosophy of Art and Religion  \\nWagner, E. (ed.), 2001, , Lanham, MD.: Lexington Books.  \\nEssays on Plato’s\\r\\nPsychology  \\nProblems of chronology  \\nAnnas, J. & Rowe, C. (eds.), 2002, , Cambridge/Mass.: Harvard University\\r\\nPress.  \\nNew Perspectives on\\r\\nPlato, Modern and Ancient  \\nBrandwood, L., 1990, , Cambridge: Cambridge University Press.  \\nThe Chronology of Plato’s\\r\\nDialogues  \\nKeyser, P., 1991, “Review of Ledger” (1989), , 2:, 422–7.  \\nBryn\\r\\nMawr Classical Review  \\n–––, 1992, “Review of Brandwood”\\r\\n(1990), , 3: 58–73.  \\nBryn Mawr Classical Review  \\nLedger, G. R., 1989, , Oxford: Clarendon Press.  \\nRecounting Plato: A Computer Analysis of\\r\\nPlato’s Style  \\nNails, P., 1992, “Platonic Chronology Reconsidered,” , 3: 314–27.  \\nBryn Mawr Classical Review  \\nRitter, C., 1888, , Stuttgart:\\r\\nKohlhammer.  \\nUntersuchungen über Platon: Die\\r\\nEchtheit und Chronologie der Platonischen Schriften  \\nRyle, G., 1966, , Cambridge:\\r\\nCambridge University Press.  \\nPlato’s Progress  \\nThessleff, H., 1982, ,\\r\\nHelsinki; Societas Scientiarum Fennica.  \\nStudies in Platonic Chronology  \\nYoung, C. M., 1994, “Plato and Computer Dating,” , 12: 227–50.  \\nOxford Studies in Ancient Philosophy  \\nStudies on Plato’s dialogues'),\n",
       " Document(metadata={'Header 1': 'Plato’s Ethics: An Overview', 'Header 4': 'The earlier dialogues'}, page_content='The earlier dialogues'),\n",
       " Document(metadata={'Header 1': 'Plato’s Ethics: An Overview', 'Header 4': 'The earlier dialogues'}, page_content='Allen, R., 1970, Euthyphro , London: Routledge & Kegan Paul.  \\nPlato’s  \\nand the\\r\\nEarlier Theory of Forms  \\nBroadie, S., 2021, , Cambridge:\\r\\nCambridge University Press.  \\nPlato’s Sunlike Good  \\nBrickhouse, T. & Smith, N., 2004, , London: Routledge.  \\nPlato and the Trial of\\r\\nSocrates  \\nEbert, T., 2018, , Berlin: De Gruyter.  \\nPlaton: Menon. Übersetzung und\\r\\nKommentar  \\nFrede, D., 1986, “The Impossibility of Perfection:\\r\\nSocrates’ Criticism of Simonides’ Poem in the ,” , 39:\\r\\n729–753.  \\nProtagoras  \\nReview of Metaphysics  \\nGeach, P. T., 1966, “Plato’s : An\\r\\nAnalysis and Commentary,” , 50:\\r\\n369–82.  \\nEuthyphro  \\nMonist  \\nIrani, T., 2019, Gorgias Phaedrus, Cambridge:\\r\\nCambridge University Press.  \\nPlato on the Value of Philosophy: The Art of\\r\\nthe Argument in the  \\nand  \\nIrwin, T. (trans.), 1979, : Gorgias, Oxford:\\r\\nClarendon Press.  \\nPlato  \\nKraut, R., 1984, , Princeton:\\r\\nPrinceton University Press.  \\nSocrates and the State  \\n–––, 1986, “Coercion and Objectivity in\\r\\nPlato’s Dialectic,” , 40: 49–74.  \\nRevue Internationale de\\r\\nPhilosophie  \\nNehamas, A., 1999a, “Socratic Intellectualism,”\\r\\nreprinted in Nehamas 1999, Ch. 2.  \\nPenner, T., 1973, “The Unity of Virtue,” , 82: 35–68.  \\nPhilosophical Review  \\nPenner, T. & Rowe, C., 2005, Lysis,\\r\\nCambridge: Cambridge University Press.  \\nPlato’s  \\nRobinson, R., 1953, ,\\r\\nOxford: Clarendon Press.  \\nPlato’s Earlier Dialectic  \\nRoochnik, D. L., 1986, “Plato’s use of the\\r\\ntechne-analogy” ,\\r\\n24: 295–310.  \\nJournal of the History of Philosophy  \\nSantas, G., 1979, , London: Routledge & Kegan Paul.  \\nSocrates: Philosophy in Plato’s Early\\r\\nDialogues  \\nScott, D., 2006, Meno. Cambridge: Cambridge\\r\\nUniversity Press.  \\nPlato’s  \\nStokes, M., 1986, , Baltimore: Johns Hopkins\\r\\nUniversity Press.  \\nPlato’s Socratic Conversations: Drama\\r\\nand Dialectic in Three Dialogues  \\n–––, 2005, Crito, Swansea: The Classical Press\\r\\nof Wales.  \\nDialectic in Action. An\\r\\nExamination of Plato’s  \\nTaylor, C. C. W. (trans.), 1976, Protagoras, Oxford: Clarendon Press, 1976.  \\nPlato’s  \\nVlastos, G., 1991, , Ithaca: Cornell University Press.  \\nSocrates, Ironist and Moral\\r\\nPhilosopher  \\n–––, 1994, , Cambridge:\\r\\nCambridge University Press.  \\nSocratic Studies  \\n–––, 1994a “The Socratic Elenchus: Method\\r\\nis All,” in Vlastos 1994, 1–28.  \\nWeiss, R., 2001, Meno, Oxford: Oxford University Press.  \\nVirtue in the Cave: moral inquiries in\\r\\nPlato’s'),\n",
       " Document(metadata={'Header 1': 'Plato’s Ethics: An Overview', 'Header 4': 'The middle dialogues'}, page_content='The middle dialogues'),\n",
       " Document(metadata={'Header 1': 'Plato’s Ethics: An Overview', 'Header 4': 'The middle dialogues'}, page_content='Annas, J., 1976, “Plato’s and\\r\\nFeminism,” , 51: 307–21.  \\nRepublic  \\nPhilosophy  \\n–––, 1981, Republic, Oxford: Clarendon Press.  \\nAn Introduction to\\r\\nPlato’s  \\nBarker, A. & Warner M. (eds.), 1992, , Edmonton: Academic Printing and Publishing.  \\nThe Language of the\\r\\nCave  \\nBarney, R., 2010, “Plato on Desire for the Good,” in , ed. Sergio Tenenbaum,\\r\\nOxford, New York: Oxford University Press.  \\nDesire, Good, and Practical Reason  \\nBrown, E., 2012, “The Unity of the Soul in Plato’s\\r\\nRepublic,” in , eds. Rachel\\r\\nBarney, Tad Brennan, and Charles Brittain, Cambridge: Cambridge\\r\\nUniversity Press: 53–73.  \\nPlato and the Divided Self  \\nBurnyeat, M. F., 2006, “The Truth of Tripartition,” , 106:\\r\\n1–22.  \\nProceedings of the Aristotelian Society  \\nCooper, J. M., 1999, , Princeton: Princeton\\r\\nUniversity Press.  \\nReason and Emotion. Essays on Ancient\\r\\nMoral Psychology and Ethical Theory  \\n–––, 1999a, “Plato’s Theory of Human\\r\\nMotivation,” in Cooper 1999, ch. 5.  \\n–––, 1999b, “The Psychology of Justice in\\r\\nPlato,” in Cooper 1999, ch. 4.  \\nCross, R. C. & Woozley, A. D., 1964, Republic: , London: Macmillan.  \\nPlato’s  \\nA Philosophical Commentary  \\nFerrari, G., 2005, Republic. Chicago: Chicago University Press.  \\nCity and Soul in Plato’s  \\n––– (ed.), 2007, , Cambridge: Cambridge University\\r\\nPress.  \\nThe Cambridge Companion to\\r\\nPlato’s Republic  \\nHunter, R., 2004, , Oxford: Oxford\\r\\nUniversity Press.  \\nPlato’s Symposium  \\nKamtekar, R., 2017, ,\\r\\nOxford: Oxford University Press.  \\nPlato’s Moral Psychology:\\r\\nIntellectualism, the Divided Soul, and the Desire for Good  \\nKlosko, G., 1986, , New York: Methuen.  \\nThe Development of Plato’s Political\\r\\nThought  \\nLesher, J. & Nails, D, and Sheffield, F. (eds.), 2006, Symposium: , Cambridge, Mass.: Harvard University Press.  \\nPlato’s  \\nissues of interpretation and\\r\\nreception  \\nMorrison, D., 2001, “The Happiness of the City and the\\r\\nHappiness of the Individual in Plato’s ,” , 21: 1–24.  \\nRepublic  \\nAncient Philosophy  \\nMoss, J., 2006, “Pleasure and Illusion in Plato,” , 72(3):\\r\\n503–35.  \\nPhilosophy and Phenomenological Research  \\nOber, J., 1998, ,\\r\\nPrinceton: Princeton University Press.  \\nPolitical Dissent in Democratic Athens  \\nReeve, D.C.D., 1988, Republic, Princeton: Princeton University\\r\\nPress.  \\nPhilosopher Kings: The Argument of\\r\\nPlato’s  \\n––– 2013, , Oxford: Oxford University\\r\\nPress.  \\nBlindness and Reorientation:\\r\\nProblems in Plato’s Republic  \\nRobinson, R., 1971, “Plato’s separation of reason and\\r\\ndesire,” , 16: 38–48.  \\nPhronesis  \\nSachs, D., 1971, “A Fallacy in Plato’s ,” repr. in Vlastos 1971 (Volume 1), ch.\\r\\n2.  \\nRepublic  \\nSantas, G., 1985, “Two theories of the good in Plato’s ,” , 57: 223–45.  \\nRepublic  \\nArchiv für Geschichte der\\r\\nPhilosophie  \\nSheffield, F., 2006, Symposium. , Oxford: Oxford University Press.  \\nPlato’s  \\nThe\\r\\nEthics of Desire  \\nSchofield, M., 1999, , London: Routledge & Kegan\\r\\nPaul.  \\nSaving the City: Philosopher-Kings and\\r\\nother Classical Paradigms  \\nSingpurwalla, R., 2019, “Plato and the Tripartition of the\\r\\nSoul,” in J. Sisko (ed.), ( , Volume 1),\\r\\nLondon: Routledge, 101–119.  \\nPhilosophy of Mind in\\r\\nAntiquity  \\nHistory of Philosophy of Mind  \\nWhite, N., 1979, ,\\r\\nIndianapolis: Hackett.  \\nA Companion to Plato’s Republic  \\nWilliams, B.A.O., 1973, “The Analogy of city and soul in\\r\\nPlato’s ,” in E.N Lee, A.P.D. Mourelatos\\r\\nand R.M. Rorty (eds.), ( , Chapter 10); reprinted in G. Fine (ed.), (Volume 2: Ethics, Politics, Religion and Soul),\\r\\nOxford: Oxford University Press, 1999.  \\nRepublic  \\nExeqesis and Argument  \\nPhronesis\\r\\nSupplementary Volume 1  \\nPlato'),\n",
       " Document(metadata={'Header 1': 'Plato’s Ethics: An Overview', 'Header 4': 'The later dialogues'}, page_content='The later dialogues'),\n",
       " Document(metadata={'Header 1': 'Plato’s Ethics: An Overview'}, page_content='Bobonich, C., 2002, , Oxford: Oxford University Press, 2002.  \\nPlato’s Utopia recast: his later\\r\\nethics and politics  \\nBroadie, S., 2012, , Cambridge: Cambridge University Press 2012  \\nNature and Divinity in Plato’s\\r\\nTimaeus  \\nBrisson, L., 1998, , Sankt Augustin:\\r\\nAcademia Verlag.  \\nLe même et l’autre dan la\\r\\nstructure ontologique du Timée de Platon  \\nCarone, G., 2005, , Cambridge: Cambridge University Press.  \\nPlato’s Cosmology and Its Ethical\\r\\nDimensions  \\nCherniss, H., 1957, “The Relation of the to\\r\\nPlato’s Later Dialogues,” , 78: 225–66.  \\nTimaeus  \\nAmerican Journal of\\r\\nPhilology  \\nCooper, J. M., 1999c, “Plato’s and\\r\\nPolitics,” in Cooper 1999, ch. 7.  \\nStatesman  \\nCornford, F. M., 1937, , London:\\r\\nRoutledge & Kegan Paul.  \\nPlato’s Cosmology  \\nDelcomminette, S., 2006, , Leiden:\\r\\nBrill  \\nLe Philèbe de Platon:\\r\\nIntroduction a L’agathologie platonicienne  \\nDorter, K., 1994, , Berkeley: University of California Press.  \\nForm and Good in Plato’s Eleatic\\r\\nDialogues  \\nFerrari, G., 1987, Phaedrus, Cambridge: Cambridge University\\r\\nPress.  \\nListening to the Cicadas: a study of\\r\\nPlato’s  \\n–––, 1992, “Platonic Love,” in Kraut\\r\\n(ed.), 1992, ch. 8.  \\nFrede, D. (trans.), 1993, (with\\r\\nintroduction and notes by the translator), Indianapolis: Hackett.  \\nPlato Philebus  \\n–––, 1992, “Disintegration and\\r\\nrestoration: Pleasure and Pain in the ,” in R.\\r\\nKraut (ed.) 1992, 425–63.  \\nPhilebus  \\n–––, 1997, , Göttingen: Vandenhoeck & Ruprecht.  \\nPlaton Philebos: Übersetzung\\r\\nund Kommentar  \\nGregory, A., 2000, ,\\r\\nLondon: Duckworth.  \\nPlato’s Philosophy of Science  \\nGriswold, C. L., 1986, Phaedrus, New Haven: Yale University Press.  \\nSelf-Knowledge in Plato’s  \\nJohansen, T., 2006, Timaeus-Critias, Cambridge: Cambridge University\\r\\nPress.  \\nPlato’s Natural Philosophy: A Study\\r\\nof the  \\nKahn, C. H., 2013, , Cambridge: Cambridge\\r\\nUniversity Press.  \\nPlato and the Post-Socratic Dialogue. The\\r\\nReturn to the Philosophy of Nature  \\nKosman, L. A., 1976, “Platonic Love,” in W.H.\\r\\nWerkmeister (ed.), 1976, 53–69.  \\nLane, M., 1998, , Cambridge: Cambridge University Press.  \\nMethod and Politics in Plato’s\\r\\nStatesman  \\nLaks, A., 2022, Laws, Princeton: Princeton University Press.  \\nPlato’s Second Republic: An Essay on\\r\\nthe  \\nLee, E. N., 1976, “Reason and Rotation: Circular Movement as\\r\\nthe Model of the Mind ( ) in the Later Plato,” in\\r\\nW.H. Werkmeister (ed.) 1976, 70–102.  \\nNous  \\nLennox, J., 1985, “Plato’s Unnatural Teleology,”\\r\\nin O’Meara (ed.) 1985, 195–218.  \\nLisi, F. (ed.), 2001, Laws , Sankt Augustin: Academia Verlag.  \\nPlato’s  \\nand its\\r\\nHistorical Significance  \\nMayhew, R., 2008, , Oxford: Oxford University Press 2008.  \\nPlato: Laws 10. Translation with\\r\\nCommentary  \\nMenn, S., 2019, “On the Digression in the Theaetetus,” , LVII (Dedicated to John\\r\\nCooper): 65–120.  \\nOxford Studies in Ancient Philosophy  \\nMeyer, S. Sauvé, 2015, (translation and commentary), Oxford: Oxford University Press.  \\nPlato, Laws I and II  \\nMohr, R., 1985, , Leiden:\\r\\nBrill.  \\nThe Platonic Cosmology  \\nMoravcsik, J. M. E., 1979, “Forms, Nature and the Good in\\r\\nthe ,” , 24:\\r\\n81–104.  \\nPhilebus  \\nPhronesis  \\n–––, 1982, “Noetic Aspiration and Artistic\\r\\nInspiration,” in J.M.E. Moravcsik & P. Tempko (eds.) 1982,\\r\\n29–46.  \\nMorrow, G. R., 1993, ,\\r\\nPrinceton: Princeton University Press.  \\nPlato’s Cretan City  \\nParry, R. D., 1991, “The Intelligible World-Animal in\\r\\nPlato’s ,” 29: 13–22.  \\nTimaeus  \\nJournal of the History of\\r\\nPhilosophy  \\nPelikan, J., 1997, Timaeus Genesis , Ann Arbor:\\r\\nUniversity of Michigan Press.  \\nWhat Has Athens to Do with Jerusalem?  \\nand  \\nin Counterpoint  \\nRowe, C. (ed.), 1995, “Reading the ”. , Sankt Augustin: Academia Verlag.  \\nStatesman  \\nProceedings of the III. Symposium\\r\\nPlatonicum  \\nSaunders, T. and L. Brisson, 2000, Laws, 3rd edition, revised and completed with an\\r\\nadditional bibliography on the by Luc Brisson, Sankt\\r\\nAugustin: Academia Verlag.  \\nBibliography on\\r\\nPlato’s  \\nEpinomis  \\nSchäfer, L., 2005, , Freiburg: Karl Alber.  \\nDas Paradigma am Himmel. Platon\\r\\nüber Natur und Staat  \\nSedley, D., 2003, Theaetetus, Oxford: Clarendon Press.  \\nThe Midwife of Platonism. Text and Subtext\\r\\nin Plato’s  \\n–––, 2007, , Berkeley: University of California Press.  \\nCreationism and Its Critics in\\r\\nAntiquity  \\nScolnicov, S. & Brisson, L., 2003, Laws: , St. Augustin: Academia Verlag.  \\nPlato’s  \\nfrom theory into practice: Proceedings of the VI. Symposium\\r\\nPlatonicum  \\nTracy, T. J., 1969, , The Hague: Mouton.  \\nPhysiological Theory and the Doctrine of\\r\\nthe Mean in Plato and Aristotle  \\nVlastos, G., 1975, , Seattle:\\r\\nUniversity of Washington Press.  \\nPlato’s Universe  \\n–––, 1988, “Elenchus and Mathematics: A\\r\\nTurning-Point in Plato’s Philosophical Development,” , 109: 362–396.  \\nAmerican Journal of Philology  \\nWhite, D. A., 1993, ‘Phaedrus’, Albany: State University of New York\\r\\nPress.  \\nRhetoric and Reality in Plato’s  \\nZeyl, D. (trans.), 2000, (with\\r\\nIntroduction and Notes), Hackett: Indianapolis 2000.  \\nPlato’s Timaeus'),\n",
       " Document(metadata={'Header 1': 'Plato’s Ethics: An Overview', 'Header 2': 'Academic Tools'}, page_content='Academic Tools'),\n",
       " Document(metadata={}, page_content='.  \\nHow to cite this entry  \\nat the .  \\nPreview the PDF version of this entry  \\nFriends of the SEP Society  \\nat the Internet Philosophy Ontology Project (InPhO).  \\nLook up topics and thinkers related to this entry  \\nat , with links to its database.  \\nEnhanced bibliography for this entry  \\nPhilPapers  \\nOther Internet Resources  \\n[Please contact the authors with suggestions.]  \\nRelated Entries  \\n| | | | | | | | | | | | | | |  \\nAnaxagoras  \\nArchytas  \\nAristotle  \\nethics: virtue  \\nhedonism  \\nHegel, Georg Wilhelm Friedrich: dialectics  \\nmetaphysics  \\nPlato  \\nPlatonism: in metaphysics  \\nPopper, Karl  \\nPresocratic Philosophy  \\nPythagoras  \\nPythagoreanism  \\nself-knowledge  \\nSimplicius  \\ntranscendentalism  \\nby Dorothea Frede\\n< > Mi-Kyoung Lee\\n< >  \\nCopyright © 2023  \\ndorothea frede uni-hamburg de  \\n.  \\n@  \\n.  \\nmitzi colorado edu  \\n@  \\n.  \\nOpen access to the SEP is made possible by a world-wide funding initiative. The Encyclopedia Now Needs Your Support Please Read How You Can Help Keep the Encyclopedia Free  \\nEnd footer menu End mirrors End site credits'),\n",
       " Document(metadata={'Header 4': 'Browse'}, page_content='Browse'),\n",
       " Document(metadata={'Header 4': 'Browse'}, page_content=\"Table of Contents  \\nWhat's New  \\nRandom Entry  \\nChronological  \\nArchives\"),\n",
       " Document(metadata={'Header 4': 'About'}, page_content='About'),\n",
       " Document(metadata={'Header 4': 'About'}, page_content='Editorial Information  \\nAbout the SEP  \\nEditorial Board  \\nHow to Cite the SEP  \\nSpecial Characters  \\nAdvanced Tools  \\nAccessibility  \\nContact'),\n",
       " Document(metadata={'Header 4': 'Support SEP'}, page_content='Support SEP'),\n",
       " Document(metadata={'Header 4': 'Support SEP'}, page_content='Support the SEP  \\nPDFs for SEP Friends  \\nMake a Donation  \\nSEPIA for Libraries'),\n",
       " Document(metadata={'Header 4': 'Mirror Sites'}, page_content='Mirror Sites'),\n",
       " Document(metadata={}, page_content=\"View this site from another server:  \\nUSA (Main Site)  \\nPhilosophy, Stanford University  \\nInfo about mirror sites  \\nThe Stanford Encyclopedia of Philosophy is by , Department of Philosophy, Stanford University  \\ncopyright © 2023  \\nThe Metaphysics Research Lab  \\nLibrary of Congress Catalog Data: ISSN 1095-5054  \\n$('.dropdown-toggle').dropdown();\")]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=\"https://plato.stanford.edu/entries/plato-ethics/\" \n",
    "\n",
    "headers_to_split_on=[(\"h1\",\"Header 1\"), \n",
    "                     (\"h2\",\"Header 2\"), \n",
    "                     (\"h3\",\"Header 3\"), \n",
    "                     (\"h4\",\"Header 4\"),] \n",
    "\n",
    "html_splitter=HTMLHeaderTextSplitter(headers_to_split_on)\n",
    "html_header_splits=html_splitter.split_text_from_url(url) \n",
    "html_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff844f42",
   "metadata": {},
   "source": [
    "### How to Split JSON Data\n",
    "\n",
    "This JSON splitter splits json data while allowing control over chunk sizes.It traverses json data depth first and builds smaller json chunks.It attempts to keep nested json objects whole but will split them if needed to keep chunks between a min_chunk_size and the max_chunk_size. \n",
    "\n",
    "If the value is not a needed json,but rather a very large string the string will not be split.If you need a hard cap on the chunk size considering composing this with a Recursive Text Splitter on those chunks.There is an optional pre-processing step to split lists,by first converting them to json(dict) and then splitting them as such. \n",
    "\n",
    "- How the text is split:JSON value\n",
    "- How the chunk size is measured:by number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8b119122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import requests \n",
    " \n",
    "json_data=requests.get(\"https://jsonplaceholder.typicode.com/users\").json() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "02e9d590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'name': 'Leanne Graham',\n",
       "  'username': 'Bret',\n",
       "  'email': 'Sincere@april.biz',\n",
       "  'address': {'street': 'Kulas Light',\n",
       "   'suite': 'Apt. 556',\n",
       "   'city': 'Gwenborough',\n",
       "   'zipcode': '92998-3874',\n",
       "   'geo': {'lat': '-37.3159', 'lng': '81.1496'}},\n",
       "  'phone': '1-770-736-8031 x56442',\n",
       "  'website': 'hildegard.org',\n",
       "  'company': {'name': 'Romaguera-Crona',\n",
       "   'catchPhrase': 'Multi-layered client-server neural-net',\n",
       "   'bs': 'harness real-time e-markets'}},\n",
       " {'id': 2,\n",
       "  'name': 'Ervin Howell',\n",
       "  'username': 'Antonette',\n",
       "  'email': 'Shanna@melissa.tv',\n",
       "  'address': {'street': 'Victor Plains',\n",
       "   'suite': 'Suite 879',\n",
       "   'city': 'Wisokyburgh',\n",
       "   'zipcode': '90566-7771',\n",
       "   'geo': {'lat': '-43.9509', 'lng': '-34.4618'}},\n",
       "  'phone': '010-692-6593 x09125',\n",
       "  'website': 'anastasia.net',\n",
       "  'company': {'name': 'Deckow-Crist',\n",
       "   'catchPhrase': 'Proactive didactic contingency',\n",
       "   'bs': 'synergize scalable supply-chains'}},\n",
       " {'id': 3,\n",
       "  'name': 'Clementine Bauch',\n",
       "  'username': 'Samantha',\n",
       "  'email': 'Nathan@yesenia.net',\n",
       "  'address': {'street': 'Douglas Extension',\n",
       "   'suite': 'Suite 847',\n",
       "   'city': 'McKenziehaven',\n",
       "   'zipcode': '59590-4157',\n",
       "   'geo': {'lat': '-68.6102', 'lng': '-47.0653'}},\n",
       "  'phone': '1-463-123-4447',\n",
       "  'website': 'ramiro.info',\n",
       "  'company': {'name': 'Romaguera-Jacobson',\n",
       "   'catchPhrase': 'Face to face bifurcated interface',\n",
       "   'bs': 'e-enable strategic applications'}},\n",
       " {'id': 4,\n",
       "  'name': 'Patricia Lebsack',\n",
       "  'username': 'Karianne',\n",
       "  'email': 'Julianne.OConner@kory.org',\n",
       "  'address': {'street': 'Hoeger Mall',\n",
       "   'suite': 'Apt. 692',\n",
       "   'city': 'South Elvis',\n",
       "   'zipcode': '53919-4257',\n",
       "   'geo': {'lat': '29.4572', 'lng': '-164.2990'}},\n",
       "  'phone': '493-170-9623 x156',\n",
       "  'website': 'kale.biz',\n",
       "  'company': {'name': 'Robel-Corkery',\n",
       "   'catchPhrase': 'Multi-tiered zero tolerance productivity',\n",
       "   'bs': 'transition cutting-edge web services'}},\n",
       " {'id': 5,\n",
       "  'name': 'Chelsey Dietrich',\n",
       "  'username': 'Kamren',\n",
       "  'email': 'Lucio_Hettinger@annie.ca',\n",
       "  'address': {'street': 'Skiles Walks',\n",
       "   'suite': 'Suite 351',\n",
       "   'city': 'Roscoeview',\n",
       "   'zipcode': '33263',\n",
       "   'geo': {'lat': '-31.8129', 'lng': '62.5342'}},\n",
       "  'phone': '(254)954-1289',\n",
       "  'website': 'demarco.info',\n",
       "  'company': {'name': 'Keebler LLC',\n",
       "   'catchPhrase': 'User-centric fault-tolerant solution',\n",
       "   'bs': 'revolutionize end-to-end systems'}},\n",
       " {'id': 6,\n",
       "  'name': 'Mrs. Dennis Schulist',\n",
       "  'username': 'Leopoldo_Corkery',\n",
       "  'email': 'Karley_Dach@jasper.info',\n",
       "  'address': {'street': 'Norberto Crossing',\n",
       "   'suite': 'Apt. 950',\n",
       "   'city': 'South Christy',\n",
       "   'zipcode': '23505-1337',\n",
       "   'geo': {'lat': '-71.4197', 'lng': '71.7478'}},\n",
       "  'phone': '1-477-935-8478 x6430',\n",
       "  'website': 'ola.org',\n",
       "  'company': {'name': 'Considine-Lockman',\n",
       "   'catchPhrase': 'Synchronised bottom-line interface',\n",
       "   'bs': 'e-enable innovative applications'}},\n",
       " {'id': 7,\n",
       "  'name': 'Kurtis Weissnat',\n",
       "  'username': 'Elwyn.Skiles',\n",
       "  'email': 'Telly.Hoeger@billy.biz',\n",
       "  'address': {'street': 'Rex Trail',\n",
       "   'suite': 'Suite 280',\n",
       "   'city': 'Howemouth',\n",
       "   'zipcode': '58804-1099',\n",
       "   'geo': {'lat': '24.8918', 'lng': '21.8984'}},\n",
       "  'phone': '210.067.6132',\n",
       "  'website': 'elvis.io',\n",
       "  'company': {'name': 'Johns Group',\n",
       "   'catchPhrase': 'Configurable multimedia task-force',\n",
       "   'bs': 'generate enterprise e-tailers'}},\n",
       " {'id': 8,\n",
       "  'name': 'Nicholas Runolfsdottir V',\n",
       "  'username': 'Maxime_Nienow',\n",
       "  'email': 'Sherwood@rosamond.me',\n",
       "  'address': {'street': 'Ellsworth Summit',\n",
       "   'suite': 'Suite 729',\n",
       "   'city': 'Aliyaview',\n",
       "   'zipcode': '45169',\n",
       "   'geo': {'lat': '-14.3990', 'lng': '-120.7677'}},\n",
       "  'phone': '586.493.6943 x140',\n",
       "  'website': 'jacynthe.com',\n",
       "  'company': {'name': 'Abernathy Group',\n",
       "   'catchPhrase': 'Implemented secondary concept',\n",
       "   'bs': 'e-enable extensible e-tailers'}},\n",
       " {'id': 9,\n",
       "  'name': 'Glenna Reichert',\n",
       "  'username': 'Delphine',\n",
       "  'email': 'Chaim_McDermott@dana.io',\n",
       "  'address': {'street': 'Dayna Park',\n",
       "   'suite': 'Suite 449',\n",
       "   'city': 'Bartholomebury',\n",
       "   'zipcode': '76495-3109',\n",
       "   'geo': {'lat': '24.6463', 'lng': '-168.8889'}},\n",
       "  'phone': '(775)976-6794 x41206',\n",
       "  'website': 'conrad.com',\n",
       "  'company': {'name': 'Yost and Sons',\n",
       "   'catchPhrase': 'Switchable contextually-based project',\n",
       "   'bs': 'aggregate real-time technologies'}},\n",
       " {'id': 10,\n",
       "  'name': 'Clementina DuBuque',\n",
       "  'username': 'Moriah.Stanton',\n",
       "  'email': 'Rey.Padberg@karina.biz',\n",
       "  'address': {'street': 'Kattie Turnpike',\n",
       "   'suite': 'Suite 198',\n",
       "   'city': 'Lebsackbury',\n",
       "   'zipcode': '31428-2261',\n",
       "   'geo': {'lat': '-38.2386', 'lng': '57.2232'}},\n",
       "  'phone': '024-648-3804',\n",
       "  'website': 'ambrose.net',\n",
       "  'company': {'name': 'Hoeger LLC',\n",
       "   'catchPhrase': 'Centralized empowering task-force',\n",
       "   'bs': 'target end-to-end models'}}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "011dc9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveJsonSplitter\n",
    "\n",
    "json_splitter=RecursiveJsonSplitter(max_chunk_size=300) \n",
    "json_chunks = json_splitter.split_json({\"data\": json_data})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "939a3715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'data': [{'id': 1,\n",
       "    'name': 'Leanne Graham',\n",
       "    'username': 'Bret',\n",
       "    'email': 'Sincere@april.biz',\n",
       "    'address': {'street': 'Kulas Light',\n",
       "     'suite': 'Apt. 556',\n",
       "     'city': 'Gwenborough',\n",
       "     'zipcode': '92998-3874',\n",
       "     'geo': {'lat': '-37.3159', 'lng': '81.1496'}},\n",
       "    'phone': '1-770-736-8031 x56442',\n",
       "    'website': 'hildegard.org',\n",
       "    'company': {'name': 'Romaguera-Crona',\n",
       "     'catchPhrase': 'Multi-layered client-server neural-net',\n",
       "     'bs': 'harness real-time e-markets'}},\n",
       "   {'id': 2,\n",
       "    'name': 'Ervin Howell',\n",
       "    'username': 'Antonette',\n",
       "    'email': 'Shanna@melissa.tv',\n",
       "    'address': {'street': 'Victor Plains',\n",
       "     'suite': 'Suite 879',\n",
       "     'city': 'Wisokyburgh',\n",
       "     'zipcode': '90566-7771',\n",
       "     'geo': {'lat': '-43.9509', 'lng': '-34.4618'}},\n",
       "    'phone': '010-692-6593 x09125',\n",
       "    'website': 'anastasia.net',\n",
       "    'company': {'name': 'Deckow-Crist',\n",
       "     'catchPhrase': 'Proactive didactic contingency',\n",
       "     'bs': 'synergize scalable supply-chains'}},\n",
       "   {'id': 3,\n",
       "    'name': 'Clementine Bauch',\n",
       "    'username': 'Samantha',\n",
       "    'email': 'Nathan@yesenia.net',\n",
       "    'address': {'street': 'Douglas Extension',\n",
       "     'suite': 'Suite 847',\n",
       "     'city': 'McKenziehaven',\n",
       "     'zipcode': '59590-4157',\n",
       "     'geo': {'lat': '-68.6102', 'lng': '-47.0653'}},\n",
       "    'phone': '1-463-123-4447',\n",
       "    'website': 'ramiro.info',\n",
       "    'company': {'name': 'Romaguera-Jacobson',\n",
       "     'catchPhrase': 'Face to face bifurcated interface',\n",
       "     'bs': 'e-enable strategic applications'}},\n",
       "   {'id': 4,\n",
       "    'name': 'Patricia Lebsack',\n",
       "    'username': 'Karianne',\n",
       "    'email': 'Julianne.OConner@kory.org',\n",
       "    'address': {'street': 'Hoeger Mall',\n",
       "     'suite': 'Apt. 692',\n",
       "     'city': 'South Elvis',\n",
       "     'zipcode': '53919-4257',\n",
       "     'geo': {'lat': '29.4572', 'lng': '-164.2990'}},\n",
       "    'phone': '493-170-9623 x156',\n",
       "    'website': 'kale.biz',\n",
       "    'company': {'name': 'Robel-Corkery',\n",
       "     'catchPhrase': 'Multi-tiered zero tolerance productivity',\n",
       "     'bs': 'transition cutting-edge web services'}},\n",
       "   {'id': 5,\n",
       "    'name': 'Chelsey Dietrich',\n",
       "    'username': 'Kamren',\n",
       "    'email': 'Lucio_Hettinger@annie.ca',\n",
       "    'address': {'street': 'Skiles Walks',\n",
       "     'suite': 'Suite 351',\n",
       "     'city': 'Roscoeview',\n",
       "     'zipcode': '33263',\n",
       "     'geo': {'lat': '-31.8129', 'lng': '62.5342'}},\n",
       "    'phone': '(254)954-1289',\n",
       "    'website': 'demarco.info',\n",
       "    'company': {'name': 'Keebler LLC',\n",
       "     'catchPhrase': 'User-centric fault-tolerant solution',\n",
       "     'bs': 'revolutionize end-to-end systems'}},\n",
       "   {'id': 6,\n",
       "    'name': 'Mrs. Dennis Schulist',\n",
       "    'username': 'Leopoldo_Corkery',\n",
       "    'email': 'Karley_Dach@jasper.info',\n",
       "    'address': {'street': 'Norberto Crossing',\n",
       "     'suite': 'Apt. 950',\n",
       "     'city': 'South Christy',\n",
       "     'zipcode': '23505-1337',\n",
       "     'geo': {'lat': '-71.4197', 'lng': '71.7478'}},\n",
       "    'phone': '1-477-935-8478 x6430',\n",
       "    'website': 'ola.org',\n",
       "    'company': {'name': 'Considine-Lockman',\n",
       "     'catchPhrase': 'Synchronised bottom-line interface',\n",
       "     'bs': 'e-enable innovative applications'}},\n",
       "   {'id': 7,\n",
       "    'name': 'Kurtis Weissnat',\n",
       "    'username': 'Elwyn.Skiles',\n",
       "    'email': 'Telly.Hoeger@billy.biz',\n",
       "    'address': {'street': 'Rex Trail',\n",
       "     'suite': 'Suite 280',\n",
       "     'city': 'Howemouth',\n",
       "     'zipcode': '58804-1099',\n",
       "     'geo': {'lat': '24.8918', 'lng': '21.8984'}},\n",
       "    'phone': '210.067.6132',\n",
       "    'website': 'elvis.io',\n",
       "    'company': {'name': 'Johns Group',\n",
       "     'catchPhrase': 'Configurable multimedia task-force',\n",
       "     'bs': 'generate enterprise e-tailers'}},\n",
       "   {'id': 8,\n",
       "    'name': 'Nicholas Runolfsdottir V',\n",
       "    'username': 'Maxime_Nienow',\n",
       "    'email': 'Sherwood@rosamond.me',\n",
       "    'address': {'street': 'Ellsworth Summit',\n",
       "     'suite': 'Suite 729',\n",
       "     'city': 'Aliyaview',\n",
       "     'zipcode': '45169',\n",
       "     'geo': {'lat': '-14.3990', 'lng': '-120.7677'}},\n",
       "    'phone': '586.493.6943 x140',\n",
       "    'website': 'jacynthe.com',\n",
       "    'company': {'name': 'Abernathy Group',\n",
       "     'catchPhrase': 'Implemented secondary concept',\n",
       "     'bs': 'e-enable extensible e-tailers'}},\n",
       "   {'id': 9,\n",
       "    'name': 'Glenna Reichert',\n",
       "    'username': 'Delphine',\n",
       "    'email': 'Chaim_McDermott@dana.io',\n",
       "    'address': {'street': 'Dayna Park',\n",
       "     'suite': 'Suite 449',\n",
       "     'city': 'Bartholomebury',\n",
       "     'zipcode': '76495-3109',\n",
       "     'geo': {'lat': '24.6463', 'lng': '-168.8889'}},\n",
       "    'phone': '(775)976-6794 x41206',\n",
       "    'website': 'conrad.com',\n",
       "    'company': {'name': 'Yost and Sons',\n",
       "     'catchPhrase': 'Switchable contextually-based project',\n",
       "     'bs': 'aggregate real-time technologies'}},\n",
       "   {'id': 10,\n",
       "    'name': 'Clementina DuBuque',\n",
       "    'username': 'Moriah.Stanton',\n",
       "    'email': 'Rey.Padberg@karina.biz',\n",
       "    'address': {'street': 'Kattie Turnpike',\n",
       "     'suite': 'Suite 198',\n",
       "     'city': 'Lebsackbury',\n",
       "     'zipcode': '31428-2261',\n",
       "     'geo': {'lat': '-38.2386', 'lng': '57.2232'}},\n",
       "    'phone': '024-648-3804',\n",
       "    'website': 'ambrose.net',\n",
       "    'company': {'name': 'Hoeger LLC',\n",
       "     'catchPhrase': 'Centralized empowering task-force',\n",
       "     'bs': 'target end-to-end models'}}]}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7aa44a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'id': 1, 'name': 'Leanne Graham', 'username': 'Bret', 'email': 'Sincere@april.biz', 'address': {'street': 'Kulas Light', 'suite': 'Apt. 556', 'city': 'Gwenborough', 'zipcode': '92998-3874', 'geo': {'lat': '-37.3159', 'lng': '81.1496'}}, 'phone': '1-770-736-8031 x56442', 'website': 'hildegard.org', 'company': {'name': 'Romaguera-Crona', 'catchPhrase': 'Multi-layered client-server neural-net', 'bs': 'harness real-time e-markets'}}, {'id': 2, 'name': 'Ervin Howell', 'username': 'Antonette', 'email': 'Shanna@melissa.tv', 'address': {'street': 'Victor Plains', 'suite': 'Suite 879', 'city': 'Wisokyburgh', 'zipcode': '90566-7771', 'geo': {'lat': '-43.9509', 'lng': '-34.4618'}}, 'phone': '010-692-6593 x09125', 'website': 'anastasia.net', 'company': {'name': 'Deckow-Crist', 'catchPhrase': 'Proactive didactic contingency', 'bs': 'synergize scalable supply-chains'}}, {'id': 3, 'name': 'Clementine Bauch', 'username': 'Samantha', 'email': 'Nathan@yesenia.net', 'address': {'street': 'Douglas Extension', 'suite': 'Suite 847', 'city': 'McKenziehaven', 'zipcode': '59590-4157', 'geo': {'lat': '-68.6102', 'lng': '-47.0653'}}, 'phone': '1-463-123-4447', 'website': 'ramiro.info', 'company': {'name': 'Romaguera-Jacobson', 'catchPhrase': 'Face to face bifurcated interface', 'bs': 'e-enable strategic applications'}}, {'id': 4, 'name': 'Patricia Lebsack', 'username': 'Karianne', 'email': 'Julianne.OConner@kory.org', 'address': {'street': 'Hoeger Mall', 'suite': 'Apt. 692', 'city': 'South Elvis', 'zipcode': '53919-4257', 'geo': {'lat': '29.4572', 'lng': '-164.2990'}}, 'phone': '493-170-9623 x156', 'website': 'kale.biz', 'company': {'name': 'Robel-Corkery', 'catchPhrase': 'Multi-tiered zero tolerance productivity', 'bs': 'transition cutting-edge web services'}}, {'id': 5, 'name': 'Chelsey Dietrich', 'username': 'Kamren', 'email': 'Lucio_Hettinger@annie.ca', 'address': {'street': 'Skiles Walks', 'suite': 'Suite 351', 'city': 'Roscoeview', 'zipcode': '33263', 'geo': {'lat': '-31.8129', 'lng': '62.5342'}}, 'phone': '(254)954-1289', 'website': 'demarco.info', 'company': {'name': 'Keebler LLC', 'catchPhrase': 'User-centric fault-tolerant solution', 'bs': 'revolutionize end-to-end systems'}}, {'id': 6, 'name': 'Mrs. Dennis Schulist', 'username': 'Leopoldo_Corkery', 'email': 'Karley_Dach@jasper.info', 'address': {'street': 'Norberto Crossing', 'suite': 'Apt. 950', 'city': 'South Christy', 'zipcode': '23505-1337', 'geo': {'lat': '-71.4197', 'lng': '71.7478'}}, 'phone': '1-477-935-8478 x6430', 'website': 'ola.org', 'company': {'name': 'Considine-Lockman', 'catchPhrase': 'Synchronised bottom-line interface', 'bs': 'e-enable innovative applications'}}, {'id': 7, 'name': 'Kurtis Weissnat', 'username': 'Elwyn.Skiles', 'email': 'Telly.Hoeger@billy.biz', 'address': {'street': 'Rex Trail', 'suite': 'Suite 280', 'city': 'Howemouth', 'zipcode': '58804-1099', 'geo': {'lat': '24.8918', 'lng': '21.8984'}}, 'phone': '210.067.6132', 'website': 'elvis.io', 'company': {'name': 'Johns Group', 'catchPhrase': 'Configurable multimedia task-force', 'bs': 'generate enterprise e-tailers'}}, {'id': 8, 'name': 'Nicholas Runolfsdottir V', 'username': 'Maxime_Nienow', 'email': 'Sherwood@rosamond.me', 'address': {'street': 'Ellsworth Summit', 'suite': 'Suite 729', 'city': 'Aliyaview', 'zipcode': '45169', 'geo': {'lat': '-14.3990', 'lng': '-120.7677'}}, 'phone': '586.493.6943 x140', 'website': 'jacynthe.com', 'company': {'name': 'Abernathy Group', 'catchPhrase': 'Implemented secondary concept', 'bs': 'e-enable extensible e-tailers'}}, {'id': 9, 'name': 'Glenna Reichert', 'username': 'Delphine', 'email': 'Chaim_McDermott@dana.io', 'address': {'street': 'Dayna Park', 'suite': 'Suite 449', 'city': 'Bartholomebury', 'zipcode': '76495-3109', 'geo': {'lat': '24.6463', 'lng': '-168.8889'}}, 'phone': '(775)976-6794 x41206', 'website': 'conrad.com', 'company': {'name': 'Yost and Sons', 'catchPhrase': 'Switchable contextually-based project', 'bs': 'aggregate real-time technologies'}}, {'id': 10, 'name': 'Clementina DuBuque', 'username': 'Moriah.Stanton', 'email': 'Rey.Padberg@karina.biz', 'address': {'street': 'Kattie Turnpike', 'suite': 'Suite 198', 'city': 'Lebsackbury', 'zipcode': '31428-2261', 'geo': {'lat': '-38.2386', 'lng': '57.2232'}}, 'phone': '024-648-3804', 'website': 'ambrose.net', 'company': {'name': 'Hoeger LLC', 'catchPhrase': 'Centralized empowering task-force', 'bs': 'target end-to-end models'}}]}\n"
     ]
    }
   ],
   "source": [
    "for chunk in json_chunks[:3]: \n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4939d302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='{\"data\": [{\"id\": 1, \"name\": \"Leanne Graham\", \"username\": \"Bret\", \"email\": \"Sincere@april.biz\", \"address\": {\"street\": \"Kulas Light\", \"suite\": \"Apt. 556\", \"city\": \"Gwenborough\", \"zipcode\": \"92998-3874\", \"geo\": {\"lat\": \"-37.3159\", \"lng\": \"81.1496\"}}, \"phone\": \"1-770-736-8031 x56442\", \"website\": \"hildegard.org\", \"company\": {\"name\": \"Romaguera-Crona\", \"catchPhrase\": \"Multi-layered client-server neural-net\", \"bs\": \"harness real-time e-markets\"}}, {\"id\": 2, \"name\": \"Ervin Howell\", \"username\": \"Antonette\", \"email\": \"Shanna@melissa.tv\", \"address\": {\"street\": \"Victor Plains\", \"suite\": \"Suite 879\", \"city\": \"Wisokyburgh\", \"zipcode\": \"90566-7771\", \"geo\": {\"lat\": \"-43.9509\", \"lng\": \"-34.4618\"}}, \"phone\": \"010-692-6593 x09125\", \"website\": \"anastasia.net\", \"company\": {\"name\": \"Deckow-Crist\", \"catchPhrase\": \"Proactive didactic contingency\", \"bs\": \"synergize scalable supply-chains\"}}, {\"id\": 3, \"name\": \"Clementine Bauch\", \"username\": \"Samantha\", \"email\": \"Nathan@yesenia.net\", \"address\": {\"street\": \"Douglas Extension\", \"suite\": \"Suite 847\", \"city\": \"McKenziehaven\", \"zipcode\": \"59590-4157\", \"geo\": {\"lat\": \"-68.6102\", \"lng\": \"-47.0653\"}}, \"phone\": \"1-463-123-4447\", \"website\": \"ramiro.info\", \"company\": {\"name\": \"Romaguera-Jacobson\", \"catchPhrase\": \"Face to face bifurcated interface\", \"bs\": \"e-enable strategic applications\"}}, {\"id\": 4, \"name\": \"Patricia Lebsack\", \"username\": \"Karianne\", \"email\": \"Julianne.OConner@kory.org\", \"address\": {\"street\": \"Hoeger Mall\", \"suite\": \"Apt. 692\", \"city\": \"South Elvis\", \"zipcode\": \"53919-4257\", \"geo\": {\"lat\": \"29.4572\", \"lng\": \"-164.2990\"}}, \"phone\": \"493-170-9623 x156\", \"website\": \"kale.biz\", \"company\": {\"name\": \"Robel-Corkery\", \"catchPhrase\": \"Multi-tiered zero tolerance productivity\", \"bs\": \"transition cutting-edge web services\"}}, {\"id\": 5, \"name\": \"Chelsey Dietrich\", \"username\": \"Kamren\", \"email\": \"Lucio_Hettinger@annie.ca\", \"address\": {\"street\": \"Skiles Walks\", \"suite\": \"Suite 351\", \"city\": \"Roscoeview\", \"zipcode\": \"33263\", \"geo\": {\"lat\": \"-31.8129\", \"lng\": \"62.5342\"}}, \"phone\": \"(254)954-1289\", \"website\": \"demarco.info\", \"company\": {\"name\": \"Keebler LLC\", \"catchPhrase\": \"User-centric fault-tolerant solution\", \"bs\": \"revolutionize end-to-end systems\"}}, {\"id\": 6, \"name\": \"Mrs. Dennis Schulist\", \"username\": \"Leopoldo_Corkery\", \"email\": \"Karley_Dach@jasper.info\", \"address\": {\"street\": \"Norberto Crossing\", \"suite\": \"Apt. 950\", \"city\": \"South Christy\", \"zipcode\": \"23505-1337\", \"geo\": {\"lat\": \"-71.4197\", \"lng\": \"71.7478\"}}, \"phone\": \"1-477-935-8478 x6430\", \"website\": \"ola.org\", \"company\": {\"name\": \"Considine-Lockman\", \"catchPhrase\": \"Synchronised bottom-line interface\", \"bs\": \"e-enable innovative applications\"}}, {\"id\": 7, \"name\": \"Kurtis Weissnat\", \"username\": \"Elwyn.Skiles\", \"email\": \"Telly.Hoeger@billy.biz\", \"address\": {\"street\": \"Rex Trail\", \"suite\": \"Suite 280\", \"city\": \"Howemouth\", \"zipcode\": \"58804-1099\", \"geo\": {\"lat\": \"24.8918\", \"lng\": \"21.8984\"}}, \"phone\": \"210.067.6132\", \"website\": \"elvis.io\", \"company\": {\"name\": \"Johns Group\", \"catchPhrase\": \"Configurable multimedia task-force\", \"bs\": \"generate enterprise e-tailers\"}}, {\"id\": 8, \"name\": \"Nicholas Runolfsdottir V\", \"username\": \"Maxime_Nienow\", \"email\": \"Sherwood@rosamond.me\", \"address\": {\"street\": \"Ellsworth Summit\", \"suite\": \"Suite 729\", \"city\": \"Aliyaview\", \"zipcode\": \"45169\", \"geo\": {\"lat\": \"-14.3990\", \"lng\": \"-120.7677\"}}, \"phone\": \"586.493.6943 x140\", \"website\": \"jacynthe.com\", \"company\": {\"name\": \"Abernathy Group\", \"catchPhrase\": \"Implemented secondary concept\", \"bs\": \"e-enable extensible e-tailers\"}}, {\"id\": 9, \"name\": \"Glenna Reichert\", \"username\": \"Delphine\", \"email\": \"Chaim_McDermott@dana.io\", \"address\": {\"street\": \"Dayna Park\", \"suite\": \"Suite 449\", \"city\": \"Bartholomebury\", \"zipcode\": \"76495-3109\", \"geo\": {\"lat\": \"24.6463\", \"lng\": \"-168.8889\"}}, \"phone\": \"(775)976-6794 x41206\", \"website\": \"conrad.com\", \"company\": {\"name\": \"Yost and Sons\", \"catchPhrase\": \"Switchable contextually-based project\", \"bs\": \"aggregate real-time technologies\"}}, {\"id\": 10, \"name\": \"Clementina DuBuque\", \"username\": \"Moriah.Stanton\", \"email\": \"Rey.Padberg@karina.biz\", \"address\": {\"street\": \"Kattie Turnpike\", \"suite\": \"Suite 198\", \"city\": \"Lebsackbury\", \"zipcode\": \"31428-2261\", \"geo\": {\"lat\": \"-38.2386\", \"lng\": \"57.2232\"}}, \"phone\": \"024-648-3804\", \"website\": \"ambrose.net\", \"company\": {\"name\": \"Hoeger LLC\", \"catchPhrase\": \"Centralized empowering task-force\", \"bs\": \"target end-to-end models\"}}]}'\n"
     ]
    }
   ],
   "source": [
    "## The splitter can also output documents\n",
    "\n",
    "docs=json_splitter.create_documents(texts=[{\"data\": json_data}]) \n",
    "for doc in docs[:3]: \n",
    "    print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdb7696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
